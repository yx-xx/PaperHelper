=== PDF文件: ASTRID A Robotic Tutor for Nurse Training to Reduce Healthcare-Associated Infections.pdf ===
=== 时间: 2025-07-21 14:03:02.383098 ===

请从以下论文内容中，按如下JSON格式严格输出（所有字段都要有，关键词字段请只输出一个中文关键词，要中文关键词）：
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：to Reduce Healthcare-Associated Infections
Peizhu Qian, Filip Bajraktari, Carlos Quintero-Pea, Qingxi Meng,
Shannan Hamlin, Lydia Kavraki, and Vaibhav Unhelkar
Department of Computer Science, Rice University, Houston, Texas USA
pqianrice.edu, filip.bajraktaririce.edu, carlosqrice.edu, qm15rice.edu
Center for Nursing Research, Education and Practice, Houston Methodist, Houston, Texas USA
shamlinhoustonmethodist.org
Ken Kennedy Institute, Rice University, Houston, Texas USA
kavrakirice.edu, unhelkarrice.edu
AbstractThe central line dressing change is a life-critical
procedure performed by nurses to provide patients with rapid
infusion of fluids, such as blood and medications. Due to their
complexity and the heavy workloads nurses face, dressing changes
are prone to preventable errors that can result in central line-
associated bloodstream infections (CLABSIs), leading to serious
health complications or, in the worst cases, patient death. In the
post-COVID-19 era, CLABSI rates have increased, partly due to
the heightened nursing workload caused by shortages of both
registered nurses and nurse educators. To address this challenge,
healthcare facilities are seeking innovative nurse training solutions
to complement expert nurse educators.
In response, we present the design, development and evaluation
of a robotic tutoring system, ASTRID: the Automated Sterile
Technique Review and Instruction Device. ASTRID, which is the
outcome of a two-year participatory design process, is designed
to aid in the training of nursing skills essential for CLABSI
prevention. First, we describe insights gained from interviews
with nurse educators and nurses, which revealed the gaps of
current training methods and requirements for new training tools.
Based on these findings, we outline the development of our robotic
interventions and summary feedback to support skill acquisition.
perceived usefulness, conducted in a simulated clinical setting with
nurse participants. These evaluations demonstrate the potential
of our robotic tutor in nursing education. Our work highlights
the importance of participatory design for robotics systems, and
motivates new avenues for foundational research in robotics.
Index TermsRobotics
I. INTRODUCTION
As the largest sector of healthcare, nurses play a critical
role in delivering high-quality patient care and maintaining the
stability of the entire healthcare system. However, this stability
is now at risk due to a significant global shortage of nursing
professionals [90, 115, 54]. Among other challenges to patient
health outcomes, this shortage is placing an increased burden
on nursing educators to train a new generation of professionals,
while hospitals are tasked with recruiting and onboarding a
substantial number of new nurses each year.
Beyond formal education in nursing schools, hospitals
allocate substantial resources to train new nurses in hospital-
specific practices . With the increasing complexity of
Artificial rendering of the training environment and ASTRID, which
is composed of the Stretch robot, a depth camera, and a computer screen.
patient care, nursing staff must be regularly upskilled. For
thousand nurses each year. This process includes instruction
from nursing educators, followed by skill refinement under
the supervision of an experienced nurse mentor. Sustaining
the traditional nurse-to-nurse training model is increasingly
challenging [47, 101, 63].
As a result, healthcare facilities are actively exploring
innovative solutions to enhance and support nursing edu-
cation [107, 37, 38, 1, 42, 113]. We posit that robotic tutors
can help address this urgent need for nursing education.
practice critical skills when expert nurses are unavailable, com-
plementing nurse-to-nurse training. Examining this hypothesis,
we present ASTRID: a robotic tutor for nursing education.
ASTRID is designed to help nurses acquire necessary skills
to reduce the chances of healthcare-associated infections .
Healthcare-associated infections, which refer to infections that
occur while the patient is receiving care, can lead to serious
complications including death [130, 140, 26, 48]. The rates of
these infections have exacerbated post-COVID-19, in part due
to the nursing shortage. These infections, however, are largely
preventable through meticulous care, adherence to protocols,
and regular training  currently delivered through a nurse-to-
Nurses practicing dressing change procedures with ASTRID in a training environment (also referred to as simulation lab in the clinical community).
ASTRID offers (left) real-time guidance, (middle) physical interventions, and (right) post-practice feedback to help nurses master principles of sterile
technique for preventing healthcare-associated infections.
nurse model [84, 25, 96]. ASTRID aims to complement this
training by enabling nursing students, nursing residents, and
early-career nurses (collectively referred to as nursing students
in this paper) to practice and improve their skills, even without
the presence of an expert nurse.
patory design process. First, through exploratory brainstorm
sessions and requirement capture (Sec. III), we identified system
requirements including necessary perception, manipulation,
As depicted in Fig. 1, ASTRID is realized using the Stretch
mobile manipulator , an off-board depth camera , and
a computer. Using its perception, ASTRID monitors students as
they practice dressing changes on simulated patients (Fig. 2-
left), providing real-time feedback when actions that could lead
to infections are detected. Using its mobile manipulation, the
robot simulates scenarios (Fig. 2-middle) that are associated
with increased likelihood of human errors, such as interruptions.
After each training session, ASTRID provides a summary report
via the computer monitor (Fig. 2-right), enabling students to
review their performance and identify areas for improvement.
These features aim to complement the training provided by
expert nurses, who may not always be available.
We evaluated ASTRID in a human-subject feasibility study
with nine nurses (Sec. V). Results demonstrate that ASTRID
can detect student errors almost as accurately as a nursing
find the system useful. Finally, the evaluations suggest several
promising directions for both foundational research in robotics
and their practical applications in nursing education.
II. RELATED WORK
We review relevant literature on nursing, robotic tutors, and
participatory design that informs our research. Figs. 3 and 4
summarizes the prior work in the area of robots in nursing and
robotic tutoring systems, and illustrates the unique contribution
of our work.
Physical
Assistance
Cognitive
Assistance
Nursing Education
Nursing Care
Assistance with
Decision Making
Assistance with
Physical Tasks
Our Work
Prior work in robotics for nursing focuses on providing nurses with
assistance in decision making and physical tasks in nursing care. In contrast,
this paper focuses on robotic assistance in nursing education.
A. Robotics for Nursing
In response to nursing shortages and growing workloads,
robotics for nursing has become a vibrant research area [72,
nurses in homes and hospitals, with little work on robotics for
nursing education.
1) Nursing Care: Robotic assistants, including commer-
cially available products, are being developed to support nurses
[50, 121, 124]. Pilot studies have shown success in using
robots for tasks such as fetching supplies and disinfecting
rooms [83, 4, 133]. As illustrated in Figure 3, existing systems
provide a mix of cognitive and physical assistance, primarily
focusing on nursing care. In contrast, our work centers on
nursing education. While our focus differs, our approach is
informed by robots designed for nursing care.
2) Nursing Education: Nursing research highlights the
growing need for technology in nursing education [63, 107,
pandemic. This shift has seen increased use of videos [43, 8,
humanoid robot-patients  and telepresence robots are being
explored to make nursing education more accessible .
nursing remains untapped and ASTRID is the first-of-its-kind
robotic tutor for nursing.
Physical
Intervention
Cognitive
Intervention
Cognitive Skills
Physical Skills
Tutors Using
Cognitive Intervention
Our Work
Tutors Using
Physical Intervention
Prior work on robotic tutors primarily focuses on cognitive skill
training. In contrast, we explore the role of robotic tutors in physical skill
physical skill execution.
B. Robotic Tutors
Intelligent tutoring systems have been developed for various
learning environments, including K-12 education, corporate
benefits such as enhanced student interaction, improved learning
and interaction capabilities.These systems allow students to
practice and learn even when teachers are unavailable, aiming
to enhance personalization and accessibility of instruction.
Most robotic tutors, as illustrated in Figure 4, rely primarily
on conversational instructions and lack mobile manipulation
capabilities. Research in human-robot interaction (HRI) has
looked using a physical intervention to improve human
learners cognitive skills such as problem solving  and
knowledge in circuit design . In contrast, our work uses
a robots perception and mobile manipulation capabilities to
assess and enhance students physical skill execution.
C. Participatory Design
Participatory design is a collaborative process that involves
users in the process of designing a new service or technology.
It combines the knowledge of the users with the skills of
system designers, ensuring the inclusion of user needs in
the design process [56, 21]. A participatory design process
usually starts with reciprocal learning in which users and
designers learn about each others roles: designers learn about
work practices from users and users learn about technical
constraints from designers . While many participatory
design methods exist [116, 93], the most widely used methods
testing [70, 91]. Participatory design has found success in
design of robots, including those designed for healthcare and
tutoring [16, 78, 122, 132]. Informed by these works, we utilize
a combination of participatory design methods to capture
nurses needs, develop prototypes collaboratively with nurses,
and evaluate our prototype through a human-subject study.
III. REQUIREMENT CAPTURE
To design the robotic tutor, we adopted a three-step partici-
patory design process: requirement capture, prototype design,
and feasibility study. This section focuses on the first step,
aimed at first identifying which nursing skills would benefit
most from robotic tutors and then determining the design
requirements for the robotic tutor. We achieve these aims
through an exploratory phase, which are followed by focused
interviews with stakeholders.
A. Exploratory Phase
We believe robotic tutors have the potential to assist in a
variety of nursing education settings. To identify the most
suitable setting for the first such tutor, our cross-disciplinary
team began with internal brainstorming sessions. These sessions
were also crucial for aligning the team. Roboticists attended
nurse training sessions to learn about clinical practices and
build rapport with nursing professionalsan essential step
for this interdisciplinary effort. Two early tutor prototypes
were developed, which helped refine the research questions
and assess feasibility. Through this exploration, the central
line dressing change (CLDC) emerged as a key focus due to
it being a frequently-performed procedure, need for periodic
training due to occurence of preventable human errors, and
potential for robotic assistance.
CLDC is a crucial step in maintaining the sterility and
preventing infection of a central venous catheter or central
nutrition directly into a large vein. Maintenance of the central
line is complex and life-critical, protecting patient against
infections [51, 58]. One devastating complication during CLDC
is the central line-associated bloodstream infection (CLABSI),
which accounts for 17 of the almost one million healthcare-
associated infections per year . Fortunately, CLABSIs are
preventable with meticulous nursing care and adherence to
established protocols [84, 25, 96]. These safety protocols,
referred to as the principles of sterile technique, outline
essential rules for maintaining sterility during dressing changes.
In this paper, we focus on nursing skills corresponding to four
key rules which are illustrated in Fig. 5.
B. Focused Interviews
Having identified a suitable nursing setting, we turned to
defining the design requirements for the robotic tutor. We
conducted focused interviews with three stakeholder groups:
nursing students, experienced nurses, and nurse educators.
Further details about the participant recruitment methodology
are provided in the Appendix.
1) Methodology: The interview protocol was approved
by Rice University IRB and structured in three parts, each
addressing a specific goal. The first part focused on un-
derstanding participants experiences with CLDC and the
challenges they face in adhering to the sterile technique. The
second part explored current training methods, asking if the
challenges identified were addressed and what participants
liked or disliked about existing methods. The third part
Hands below
waistline
Reaching across
sterile field
Turning back
on sterile field
Touching
one-inch border
Four prohibited behaviors during a sterile procedure, such as the central line dressing change. Once a sterile field is established (the area shown in
blue), nurses need to maintain sterility by avoiding potential contamination. In particular, a nurse must keep hands above their waistline and the sterile field
within vision at all times. Hands, with sterile gloves on, must not touch anything non-sterile such as the 1-inch border of the sterile field.
brainstormed potential solutions, starting with open-ended
discussions about new training aids and then focusing on
robotic tutors. Participants were shown a video of an early
prototype of the tutoring system and asked for feedback on its
usefulness and improvements. This prototype included human
pose estimation (via MediaPipe) and provided visual alerts as
on-screen text. The Appendix includes the list of interview
questions and a link to the video of the prototype.
2) Participants: Ten participants were interviewed, includ-
ing three nursing students, three bedside nurses, and four nurse
educators. Participants ages ranged from 20 to 49 years. The
experienced nurses and nurse educators had between 6 and 16
years of experience as nurses, with an average of 11.3 years.
3) Results: The focused interviews led to three findings
All participants rated CLDC to be highly important;
nursing students found maintaining the sterile field chal-
lenging. When asked to rate how challenging CLDC was
in their experience, four out the ten participants, including
all nursing student participants, rated the procedure as
challenging (> 4 on a scale of 1 7); three rated it
as neutral ( 4); and three rated it as not challenging
(< 4). However, all participants pointed out that CLDC
could become extremely complex when compounded with
accompanying real-world factors such as disruptions and
interruptions resulting from unexpected movements from
the patients, other patients calling the nurse, or family
members asking questions during the procedure.
Current training methods do not emphasize real-world
factors. Nursing students first learn about CLDC and ster-
ile technique in nursing school. However, they typically do
not receive hands-on practice until they come to hospitals
for internships, usually in their final year of undergraduate
study. During the classroom learning (nursing schools,
the basics of CLDC (i.e., the step-by-step procedure), and
do not emphasize the accompanying real-world factors
that introduce complexity to CLDC.
New training aids, with specific features, can assist in
acquisiting of nursing skills. We asked the participants to
brainstorm new training aids that could help nurses learn
and practice the skills required for CLDC. Fig. 6 summa-
rizes the features brainstormed by the participants, labeled
with the number of groups (out of 3) that mentioned
the feature. All groups supported a system that monitors
Practice for Different Lvls.
Real-time Feedback
Skill Checklist
Imperfect Scenarios
Simulation of Patients Reaction
Step-by-step Refresher
List of Supplies Needed for the Procedure
Number of Groups
Log Sheet of Errors
Features suggested by the participants for new training aids.
nurses and provides feedback on medical errors. However,
preferences for warnings and feedback varied. For real-
time feedback, participants debated audio vs. visual alerts
and ultimately agreed on both to accommodate different
preferences. They emphasized clear, specific explanations
of errors over generic beeping sounds to avoid alarm
fatigue. For post-practice feedback, students preferred
a log sheet with timestamps and nurse actions, while
educators suggested a checklist tracking rule violations.
Participants also recommended training aids that simulate
real-world disruptions and interruptions. Students and
bedside nurses further proposed different training levels
based on experience. Lastly, participants had no specific
preferences regarding the robotic tutors appearance.
C. System Requirements
Based on the findings of the exploratory phase and focused
that assists in CLABSI-prevention training. It needs to:
R1. detect compliance with the sterile technique;
R2. provide task-time guidance to facilitate skill acquisition;
R3. provide summary feedback for efficient training review;
R4. simulate scenarios that increase the risk of violations;
R5. be perceived as useful by nursing students; and
R6. be perceived as engaging by nursing students.
RGB  Depth
Camera Data
Student Pose
Estimation
Sterile Technique
Compliance Detection
Real-time
Feedback
Rule-based Module
ML-based Module
Overview of ASTRIDs system architecture for providing real-time guidance regarding the sterile technique to nursing students.
IV. PROTOTYPE DESIGN
Guided by the system requirements, we design ASTRID:
the Automated Sterile Technique Review and Instruction
Device shown in Fig. 2. It is intended for use in training
environments. In this section, we detail its key features and
their implementation.
A. System Overview
We begin by translating stakeholder requirements into the
core capabilities the robotic tutor must possess:
To detect nurses compliance with sterile technique (R1):
the robotic tutor requires cameras and computer vision
algorithms to track nurses, perceive the environment,
and assess compliance in real time. The perception and
reasoning modules must operate with low latency to
provide immediate feedback.
To provide guidance during and after the task (R2, R3):
the robot must generate nursing-specific feedback and
communicate it effectively through audiovisual channels.
The guidance must be both accurate and engaging to meet
R5 and R6, respectively.
To simulate risk-inducing scenarios (R4): The system
needs conversational and mobile manipulation capabilities
to generate both verbal and physical interventions, such
as interruptions and distractions.
These capabilities necessitate a robot with vision-based per-
realize ASTRID, we build upon the Stretch mobile manipulator
due to its human-safe design, onboard camera, and established
use in healthcare robotics . During requirement capture,
a prototype demonstration using Stretch received positive
feedback on nurses comfort with the platform. To realize
remaining capabilities, we augmented Stretch with additional
hardware (an off-board depth camera  and a computer) and
software modules for perception, reasoning, and interaction.
Through the architecture in Fig. 7, ASTRID monitors nursing
students as they practice central line dressing change, provides
real-time feedback on sterile technique compliance, simulates
error-prone scenarios, and generates a summary report for
performance review.
B. Detecting Student Compliance with the Sterile Technique
Illustrated in Fig. 5, ASTRID considers four key principles of
sterile technique once the sterile field is established. As nursing
students practice the CLDC procedure, ASTRID monitors them
and detects compliance with these principles as detailed next.
1) Sterile Field Detection: Each training session begins with
ASTRID detecting the sterile field, which corresponds to the
sterile drape, visible as the blue area on the table in Fig. 2. The
drape is often uneven, irregularly shaped, and contains supplies
inside pouches, making detection complex. To ensure robust
image of the training setup on a monitor and marks the four
corners of the sterile drape using a mouse. This process takes
less than 10 seconds to complete. Our geometry-based software,
developed in-house using OpenCV2  and MediaPipe ,
then uses the pixel positions and corresponding depth values
to identify the edges of the sterile field and construct a 3D
model of it. Since the sterile field remains static during the
(Sec. V), the experiment proctor performs this calibration.
2) Student Pose Estimation: During a training session,
ASTRID monitors the nursing student using its camera to
estimate their pose. The pose estimation module is built using
MediaPipe . In particular, pose estimation is achieved using
a series of pre-trained models, where the first stage detects
human bodies in an RGB frame, and the second stage locates
key landmarks on the hands and body. The hand estimation
model identifies 21 landmarks, while the pose estimation model
tracks 33, with the most relevant for our application being the
locates the key landmarks, it returns the pixel coordinates of the
landmarks. We then create a 3D environment reconstruction
by projecting the landmarks back to the 3D space. This is
to integrate the sterile field information with human pose
estimation to enable compliance detection, described next.
One unique challenge of our use case is that the nurse wears
face masks, hairnets, and gloves, which obscure parts of the
making pose estimation challenging. To tackle this, we set the
visibility (a hyperparameter of MediaPipe) of these landmarks
to 0 to enhance robustness of this automated pose estimation.
3) Sterile Technique Compliance Detection: Next, ASTRID
uses the sensed landmarks of the students pose and the sterile
drape to determine compliance with the four principles of sterile
technique. This compliance detection is achieved through a
geometric rule-based module. The rule-based module partitions
the 3D space into sterile and non-sterile regions, it calculates
1We also explored methods that do not require manual calibration. However,
we found that they were reliable only when the drape was flat and free
of items. Future work could explore improving automated detection of the
sterile drape via interactive machine learning.
two key planes based on the sterile drape: the bottom plane,
fitted along the drape, and the front plane, defined perpendicular
to the bottom plane at the front-most edge (relative to the
student). Finally, it applies the following geometry-based rules
to check for four non-compliant behaviors:
hands below waistline: if wrist-landmarks are below the
sterile drape (i.e., the bottom plane).
reaching across the sterile field: if any human landmark
is ahead of the the sterile drape (i.e., the front plane).
turning back to the sterile field: if the vector from the
left to right shoulder faces away from the sterile drape.
touching the one-inch border: if the fingertip-landmarks
are within one-inch of the boundary of the sterile drape.
C. Providing Feedback to Students
Along with detecting sterile technique compliance, ASTRID
offers feedback both during and after the training session.
1) Task-Time Feedback: Guided by the focused interviews,
ASTRID uses both visual and audio channels to provide task-
time feedback. As shown in Fig. 2-middle, during the training
screen with real-time skeletal tracking. Fig. 2-left provides a
snapshot of this screen. If ASTRID detects a non-compliant
the screen and aurally via pre-recorded audio. The visual
and audio alerts have the same message, Warning: <specific
non-compliant behavior> (e.g., hands below waistline).
2) Post-Practice Feedback: At the end of the training
quickly review their practice using its screen (Fig. 2-right).
right or wrong. Second, if the nurse prefers not to review
the entire recording, ASTRID saves key frames when non-
compliant behaviors are detected. Lastly, ASTRID generates
a PDF report summarizing how many times each rule was
and associated warnings.
D. Simulating Challenging Nursing Scenarios
Guided by the findings of focused interviews, we design
ASTRID to offer three levels of training  novice, intermediate,
and advanced  which increase in complexity, simulating
challenging real-world scenarios that nurses may encounter
during dressing change procedures. A video demo of these
scenarios is available at
1) Novice: At this level, nurses practice the central line
dressing change without distractions or interruptions, with all
feedback features enabled. It is ideal for nursing students and
nurses unfamiliar with the procedure.
2) Intermediate: This level additionally introduces distrac-
interrupted by patients, family members, or other medical staff.
Distractions are created by the robot, which moves around the
feedback You are doing great! Keep going!" to the nurse.
ASTRID leverages mobile manipulation to create simulations of
real-life scenarios.
The robots paths are pre-designed giving considerations of
nurses safety and proxemics. During the feasibility study, the
robot moves autonomously. The motion is programmed using
3) Advanced: In the advanced level, ASTRID uses its mobile
manipulation capability to simulate critical scenarios that
require the nurse to apply their experience and judgment
to determine the appropriate course of action. Currently, our
prototype offers two such scenarios which were co-designed
with nursing experts:
(Scenario 1) ASTRID alerts the nurse, Your patients
blood sugar is dropping below 54 mgdL (milligrams
per deciliter). I am bringing glucose. and brings a 50
dextrose (glucose) injection near the bedside tables (Fig. 8-
top). Once the robot has reached the table, it alerts the
three times. If and when the nurse takes the dextrose
sterile field. This represents a life-critical scenario where
the patients blood sugar is dangerously low and could
continue dropping, requiring the nurse to act quickly.
(Scenario 2) ASTRID approaches the table and knocks
over the patients water bottle off the table, and alerts,
pick up the water bottle and put it back. This scenario
represents a non-emergency but common interruptions,
e.g., where a patient drops something and asks the nurse
to pick it up (Fig. 8-bottom). In such cases, experienced
nurses would typically inform the patient that they will
retrieve the item after the procedure.
The choice of these physical interventions was informed
by challenges described by stakeholders during the focused
sions with nursing educators. These scenarios were refined to
ensure they aligned with professional nursing practices, met
our design goals, and were technically feasible to implement on
a robot, resulting in the specific interventions described above.
In both scenarios, the nurse must carefully reason through
their actions. Following the robots suggestion may lead to
a violation of sterile technique, but in some cases (e.g., the
first scenario) it may be necessary to prioritize patient health.
Similar to the implementation in the Intermediate level, all
robots verbal and physical interactions are pre-programmed
using the software package stretchbody, enabling the robot
to behave autonomously during training sessions.
V. FEASIBILITY STUDY
We conducted a feasibility study to evaluate ASTRID.2 This
IRB-approved study involved nine participants  seven recent
graduates or nurses with two years or less of experience and two
experienced nurses from the requirement capture interviews.
The experiment was held in the training environment shown
in Fig. 2, an artificial rendering of which is depicted in Fig. 1.
A. Materials
The experiment site was set up to mimic CLDC scenarios,
with the same level of fidelity typically used in nursing
education. The setup included a simulated patient, ASTRID, a
table for performing the dressing change, medical supplies,
and a GoPro camera. The depth camera and monitor were
placed on a table in front of the nurse. The GoPro was used
to record the experiments and was not part of ASTRID. One
of the authors served as the experiment proctor.
B. Procedure
The experiment consisted of three parts: an introduction,
dressing change procedures, and a post-experiment review.
1) Introduction: The session began with a greeting, followed
by an explanation of the studys purpose, procedure, participant
informed consent and completed a demographic survey on-site.
2) Central Line Dressing Change Procedures: Participants
were asked to perform CLDC on the simulated patient four
times (referred to as tests), each with a different setup and
purpose.
Test 0 (Pre-test) involved participants performing a CLDC
without warnings or interventions from ASTRID. This
allowed them to familiarize themselves with the setup
and enabled necessary calibration.
Test 1 implemented the intermediate level of ASTRID.
Participants received real-time audio-visual warnings, in
cases when ASTRID detected non-compliant behaviors.
moved around the room and said pre-scripted statements.
2We refer the reader to the supplementary material for video snippets and
resources to support the reproducibility of this study.
Test 2 implemented the advanced level of ASTRID. The
participants continued to receive real-time warnings.
scenarios described in Sec. IV-D3.
Test 3 implemented the novice level of ASTRID and
involved the proctor instructing participants to deliberately
perform non-compliant behaviors (e.g., dropping hands
below the waistline). This test was included to evaluate
ASTRIDs detection capability, in case non-compliant
behaviors were not observed in earlier tests.
After each test, the participants reviewed the summary report
generated by ASTRID. The summary consists of the video
recording of the test, snapshots of each detected non-compliant
times the participant broke each of the four rules along with
the images of the mistakes.
3) Post-Experiment Review: After the participant completed
all four tests, they were asked to complete a post-experiment
survey administered on an on-site computer. Upon completing
the survey, the experiment proctor conducted a brief interview
to better understand the participants experience and solicit
suggestions for ASTRIDs future iterations and usage.
C. Measures
The feasibility study assessed whether ASTRID met the
design requirements (R1R6) using a combination of objective
and subjective measures. The post-experiment review also
gathered participatory design feedback for future robotic tutors.
1) Measures for R1: To evaluate ASTRIDs ability to detect
student compliance with sterile technique, we compared its
performance to that of a nurse educator. A nurse educator with
20 years of experience reviewed and annotated the video
recordings of the training sessions to establish the ground
truth for non-compliant behaviors. Annotations were made
using the Behavioral Observation Research Interactive Software
(BORIS) , with the experiment proctor assisting in data
entry. For analysis, we sampled the training sessions at 1Hz,
treating each second as an instance for evaluation. Each instance
was categorized as true positive (TP), false positive (FP), true
negative (TN), or false negative (FN), based on ASTRIDs
detection compared to the expert annotations. For example,
an instance was marked as FP if ASTRID detected a violation
but the expert did not. Fig. 9 provides additional examples.
2) Measures for R2R4: To evaluate R2R4, the post-
experiment survey included seven statements evaluating the
usefulness of ASTRIDs seven features (Fig. 10). Participants
rated each feature on a 5-point discrete visual analog scale
(DVAS), from not useful at all (1) to extremely useful (5).
3) Measures for R5R6:
The post-experiment survey
included two established surveys, adapted for the experimental
and user engagement . The list of survey questions is
provided in the appendix. The perceived usefulness survey
included statements such as Practicing with [technology]
would enhance my overall job performance. Participants rated
these statements on a 5-point discrete visual analog scale,
Examples of ASTRIDs compliance detection from the feasibility study: (True Positive) ASTRID correctly detects the nurse turning their back to the
sterile field; (False Positive) ASTRID mistakenly identifies the hands as below the waistline due to occlusion; (False Negative) ASTRID misses the left hand
below the waistline as it is hidden behind the back; and (Outlier) the tables higher height makes it challenging to detect the sterile field and compliance.
Calculation
Accuracy
(TPTN)  (TPTNFPFN)
Precision
TP  (TPFP)
TP  (TPFN)
F1 Score
2RecallPrecision  (RecallPrecision)
ranging from extremely unlikely (1) to extremely likely (5).
The user engagement survey included statements such as My
experience was rewarding. This scale also utilized a 5-point
discrete visual analog scale: strongly disagree (1) to strongly
agree (5).
D. Findings
Nine nurses participated in the feasibility study. Data from
one participant (P2) was excluded as an outlier due to issues
with the table height. Although we had opted for a height-
adjustable table to accommodate participants of different height,
the highest-level of the table was still below the participants
waistline. Of the remaining eight participants, each performed
four tests, yielding 32 total tests. Two tests were not recorded
properly due to data storage limitations. Additionally, two
tests (pre-test and Test 1 of P6) were excluded because we
noticed when the table was at its highest level, it was at the
same level of the camera, making perception difficult. Though
this was resolved when they performed Test 2 and Test 3.
In total, we collected data from 28 effective tests, amounting
to 5, 719 seconds (95.3 minutes) of video recordings.
Finding 1: ASTRID demonstrates the potential to accurately
detect students compliance with the sterile technique. Among
the 5719 instances of data, 343 are found to be TP, 16 FP, 5376
and an F1 score of 0.89. An F1 score above 0.9 is considered
good. Table I summarizes key metrics, demonstrating ASTRIDs
high accuracy in detecting both positives and negatives. While
true positives are crucial for robotic tutoring, we wish to
highlight that true negatives are equally important. They
validate ASTRIDs perception modules and (as indicated in
the open-ended feedback) nursing students felt encouraged
when they knew they did not make any mistakes. Together
these results indicate that ASTRID satisfies requirement R1.
Finding 2: Participants perceive ASTRID as highly useful for
nursing education. Through the perceived usefulness survey,
detailed in the appendix, participants reported a mean score
of M  4.70 (out of a maximum of 5) and SD  0.41 on
the systems perceived usefulness. This result highlights the
potential of ASTRID as a helpful tutoring system to improve
nurses skills and job performance in the future. Fig. 10
provides a granular view of ASTRIDs perceived usefulness,
highlighting participants feedback on its individual features.
While some features were rated more useful than others, both
real-time and post-practice feedback were consistently rated
as extremely useful.
Finding 3: Participants perceive ASTRID as engaging
and supportive. Through the user engagement survey, also
detailed in the appendix, participants reported a mean score
M  4.84 (out of 5) and SD  0.30, indicating that the
participants found ASTRID engaging and supportive. In the
post-experiment interview, we asked participants whether
practicing with ASTRID would improve nursing students
confidence in complying with the sterile technique. All
participants unanimously answered yes. One participant,
who recently graduated from nursing school said
I always feel very anxious because I am new to the
job. But practicing with the robot has already made
me feel better about my skills because now I know I
did not make any mistakes... I also like the real-life
scenarios. We did not see those in nursing school.
In addition to helping nursing students improve and gain
confidence in their skills, participants noted that ASTRID could
offer other benefits, such as being more readily available
than experienced nurses, providing objective assessments and
fear of judgment. These results and comments are especially
through initial interviews and validate our participatory design
efforts to create a nurse-friendly robotic tutor.
E. Limitations
While our work involved a rigorous co-design process,
iterative development, and human-subject evaluations, it also
has limitations. Here, we acknowledge these to contextualize
our contributions, highlight the challenges of systems research,
and guide future work. First, while we engaged stakeholders
from the outset, our evaluations were limited to nine nurses.
This sample size aligns with user-centered design research,
Snapshots
Real-time Audio Warning
Real-life Scenarios
Video Recording
Real-time Visual Warning
Skeleton Visualization
Fig. 10.
Perceived usefulness of ASTRIDs individual features: the number
of participants (out of 8) that rated a feature to be extremely useful. While
all features are perceived as useful, snapshots of contamination occurrences
receive the highest ranking and skeleton visualization the lowest.
which suggests that 810 participants can uncover up to 80 of
usability issues , including in healthcare technologies .
results should be considered proof-of-concept. A key challenge
was recruiting novice nurses, whose demanding schedules made
research participation difficult. Second, our user evaluations
relied on established scales for perceived usefulness and user
nursing education. These modifications were not separately
validated. Lastly, while the robot operated autonomously,
its functionality was constrained to the controlled training
environment. For instance, the system was tested against a
specific background. In real-world settings, the robot will need
to adapt to a wider range of environments and users, requiring
enhanced autonomy. As discussed in the next section, this
underscores the need for foundational robotics research driven
by real-world applications in nursing.
VI. CONCLUSION
We conclude by discussing the implications of our findings
for both nursing education and foundational robotics research.
A. Implications for Nursing Education
1) Key Contributions: Our work introduces a novel tech-
nological aid for nursing education: robotic tutors. Through
participatory design, we developed ASTRID, a robotic tutor
for CLABSI-prevention training. ASTRID monitors student
compliance with the sterile technique, providing real-time
feedback and tools for performance review and improvement. It
also offers multiple training levels and can simulate challenging
scenarios which may be overlooked in nursing schools. In
a feasibility study with 9 nurses, ASTRID reliably detected
compliance with four key sterile technique principles and was
perceived as useful and engaging. These results suggest that
ASTRID can help provide new nurses with opportunities to
practice their skills and receive immediate feedback, especially
as current nursing shortages challenge the sustainability of
the traditional nurse-to-nurse training model [47, 101, 63].
nurses early on during the design and development of new
technology.
2) Directions for Future Work: While ASTRID shows
We list suggest future directions for nursing research:
ASTRID addresses four principles of the sterile technique;
96]. The system also focuses on a specific part of the
dressing change procedure  after the nurse has already
opened the dressing change kit and set up the sterile field.
Early steps like opening the sterile packet and putting on
gloves are not covered and should be addressed in future
work. Participants also suggested expanding the tutor to
other tasks like Foley catheter insertion , and high-
sterility environments like operating rooms (OR) [118,
While ASTRID reliably detects sterile technique violations,
it is not immune to errors. A risk is students becoming
overconfident due to false negatives. While technological
improvements can enhance detection accuracy, we believe
integrating input from nursing instructors is crucial to
address this challenge. Participants also emphasized the
importance of human instruction, especially for those
who began their education during COVID-19. Thus,
ASTRID should complement broader nursing education
frameworks rather than function as a standalone tool.
It is important to highlight that ASTRID is designed
to augment traditional nursing training and intended for
use alongside instructors. Future work should evaluate
ASTRID through formal AB comparison against a control
condition where nurses practiced without robotic support.
evaluation. Future work should explore the instructor-
student-robot triad to understand how robots can best
support existing teaching methods.
B. Implications for Robotics
1) Key Contributions: Within robotics, our work makes
three key contributions:
Introducing nursing education as a new robotics domain:
We identify nursing education as a field in need of
transformative solutions and demonstrate the potential of
robotics in this space through the design, development,
and evaluation of ASTRID. Our work serves as an initial
testbed for evaluating robotics technologies in nursing
education and reveals new research directions in task
and motion planning, perception-aware motion planning,
conversational robots, and robotic tutors.
Advancing robotic tutoring with a focus on physical
nitive learning through conversational interactions (e.g.,
math tutoring), ASTRID is designed for physical skill
acquisition. This shift necessitates perception-driven
performance evaluation and physical interventions via
mobile manipulation. We see this as a small but important
step toward expanding robotic tutoring beyond screen-
based or purely conversational approaches.
Reaffirming the value of participatory design in robotics:
Our work reinforces the importance of participatory design
in developing robotics systems. By actively involving
stakeholders throughout the process, we ensure that the
technology is aligned with real-world needs, further
supporting user-centered approaches in robotics research.
2) Directions for Future Work: Our systems-driven inves-
tigation also reveals directions for foundational research in
Rule-Based Detection and Alternatives: The rule-based
perception pipeline of ASTRID offers simplicity and relia-
bility (advantages that are valuable in early-stage research)
but limits generalizability. Future work should focus on
enhancing detection using more robust pose estimation,
object detection, and action recognition techniques. In
ongoing work, we are evaluating alternatives to MediaPipe
for improved pose estimation, and plan to integrate object
detection models (e.g., YOLO , SSD ) and action
recognition models (e.g., I3D  and SlowFast ) to
enhance generalizability.
Perception-aware Robot Planning: During evaluations,
ASTRID struggled with taller participants, partly due to the
use of a static off-board camera. Raising the camera reduces
visibility of the lower body, while lowering it obstructs
key areas like the far side of the sterile field. Future work
should consider development of more robust perception
systems for detecting nursing activities, by leveraging
advances in vision [34, 52, 119, 60, 127, 89] and mobile
perception [45, 64, 137, 126]. Although there is a vast
literature on perception-aware motion generation and active
prevent the seamless application of existing methods, such
as the generation of robot motion for object manipulation
that maximizes the nurse monitoring, especially for high
degree-of-freedom robots. These constraints also extend to
task planning and motivate the need for novel methods for
perception-aware task and motion planning.
Multimodal Human-(Robotic Tutor) Interaction: Several
nurses attempted to converse with ASTRID when it greeted
them or issued verbal warnings, but ASTRID relies on
pre-scripted language and lacks the ability for free-form,
turn-taking conversations. Adding such features could
enhance the tutoring. However, if generative or large
language models are used, their limitations must be care-
fully considered [17, 97, 138, 22, 71, 129]. Combining
multiple intervention types also offers exciting potential;
our work takes a step in this direction by incorporating
physical interventions, though limited to pre-defined tasks.
Tighter integration of perception, mobile manipulation,
and conversation could significantly enhance future robotic
tutors across domains.
Calibrating Trust in Robotic Tutors: As robotic tutors
become more capable, trust calibration is a critical concern
to prevent students from over-relying on these systems [40,
robotic tutors, as their teaching role may lead students to
inherent trust them more than robotic assistants or peers [19,
explaining the robots capabilities and limitations to students
and involving instructors in the process [57, 12, 76, 13,
100]. Indeed, our participatory design findings suggest that
allowing educators to customize robotic tutors through
end-user programming will be essential for their real-world
effectiveness [33, 7, 139, 88, 68].
We conclude by emphasizing the need for cross-disciplinary
collaboration in use-inspired robotics systems research. Our
research reaffirms that developing robotics systems requires
inputs from domain experts, use of participatory design
approach is key to developing safe and responsible human-
centered robotics.
VII. ETHICAL IMPACT STATEMENT
This work presents ASTRID, a robotic tutor designed to
support nursing education and reduce preventable infections
through improved training. Developed through a participatory
design process with nursing professionals, ASTRID aims to
complement human instruction. While it offers real-time and
post-practice feedback, we caution against overreliance due to
potential perception errors. All user studies were conducted
under IRB approval, with informed consent and attention to data
privacy. Broader deployment should ensure equitable access,
human instructors oversight, and mechanisms to calibrate user
trust in the robotic tutor.
VIII. SUMMARY OF SUPPLEMENTARY MATERIAL
Please see the Appendix for further details on:
Methodology for recruiting participants;
Questions used during the focused interviews;
Statements used during the feasibility study to measure
ASTRIDs perceived usefulness; and
Statements used during the feasibility study to measure
user engagement during the experiment.
ACKNOWLEDGMENTS
This research was supported by the National Science
Foundation through Award 2326390 and Rice University funds.
We acknowledge the inputs of nursing students, nurses, and
nursing instructors, who were critical to this participatory
design effort. Lastly, we thank the anonymous reviewers for
their thoughtful feedback and constructive suggestions.
REFERENCES
Alham Abuatiq, Robin Brown, Christina Plemmons,
Beth Walstrom, Cassy Hultman, Danielle Currier, Marie
Mennenga. Nursing faculty and students satisfaction
with telepresence robots during the covid-19 pandemic.
Nurse Educator, 47(2):E39E42, 2022.
Mohd Abuazizeh, Thomas Kirste, and Kristina Yor-
danova. Computational state space model for intelligent
tutoring of students in nursing subjects. In Proceedings
of the 13th ACM International Conference on PErvasive
Technologies Related to Assistive Environments, pages
Mohd Abuazizeh, Kristina Yordanova, and Thomas
Kirste. Affect-aware conversational agent for intelligent
tutoring of students in nursing subjects. In Alexandra I.
Cristea and Christos Troussas, editors, Intelligent Tu-
toring Systems, pages 497502, Cham, 2021. Springer
International Publishing. ISBN 978-3-030-80421-3.
Shamsudeen Abubakar, Sumit K Das, Chris Robinson,
Mohammed N Saadatzi, M Cynthia Logsdon, Heather
service robot for nursing assistance: System overview
and user acceptability. In 2020 IEEE 16th International
Conference on Automation Science and Engineering
(CASE), pages 14081414. IEEE, 2020.
E Ackerman. Diligent robotics bringing autonomous
mobile manipulation to hospitals. IEEE Spectrum, 2018.
E Ackerman.
Akara robotics turns turtlebot into
autonomous uv disinfecting robot.
IEEE Spectrum,
Gopika Ajaykumar, Maureen Steele, and Chien-Ming
Huang. A survey on end-user robot programming. ACM
Computing Surveys (CSUR), 54(8):136, 2021.
Naseem Saeed Ali and Bindu John. Examining the effi-
cacy of online self-paced interactive video-recordings in
nursing skill competency learning: seeking preliminary
evidence through an action research. Medical Science
Patrcia Alves-Oliveira, Srinivasan Janarthanam, Ana
Ana Paiva, and Ruth Aylett.
Towards dialogue di-
mensions for a robotic tutor in collaborative learning
scenarios. In The 23rd IEEE International Symposium
on Robot and Human Interactive Communication, pages
Patrcia Alves-Oliveira, Tiago Ribeiro, Sofia Petisca,
Eugenio Di Tullio, Francisco S Melo, and Ana Paiva. An
empathic robotic tutor for school classrooms: Consider-
ing expectation and satisfaction of children as end-users.
In Social Robotics: 7th International Conference, ICSR
Patrcia Alves-Oliveira, Pedro Sequeira, and Ana Paiva.
The role that an educational robot plays. In 2016 25th
IEEE International symposium on robot and human
interactive communication (RO-MAN), pages 817822.
Dan Amir and Ofra Amir. Highlights: Summarizing
agent behavior to people. In Proceedings of the 17th
international conference on autonomous agents and
multiagent systems, pages 11681176, 2018.
Ofra Amir, Finale Doshi-Velez, and David Sarne. Sum-
marizing agent strategies.
Autonomous Agents and
Multi-Agent Systems, 33:628644, 2019.
Sule Anjomshoae, Amro Najjar, Davide Calvaresi, and
Kary Frmling. Explainable agents and robots: Results
from a systematic literature review. In 18th International
Conference on Autonomous Agents and Multiagent
Systems (AAMAS 2019), Montreal, Canada, May 1317,
Autonomous Agents and Multiagent Systems, 2019.
Wilma A Bainbridge, Justin W Hart, Elizabeth S Kim,
and Brian Scassellati. The benefits of interactions with
physically present robots over video-displayed agents.
International Journal of Social Robotics, 3:4152, 2011.
Tony Belpaeme, Paul Vogt, Rianne Van den Berghe,
Kirsten Bergmann, Tilbe Gksun, Mirjam De Haas,
Junko Kanero, James Kennedy, Aylin C Kntay, Ora
robots as second language tutors. International Journal
of Social Robotics, 10:325341, 2018.
Emily M Bender, Timnit Gebru, Angelina McMillan-
stochastic parrots: Can language models be too big? In
Proceedings of the 2021 ACM conference on fairness,
Alexa Bianchi, Stephen W Leslie, and Gregory T
Chesnut.
Difficult foley catheterization.
StatPearls
[Internet], 2023.
Chris Birmingham, Zijian Hu, Kartik Mahajan, Eli Reber,
and Maja J Mataric. Can i trust you? a user study of
robot mediation of a support group. In 2020 IEEE
International Conference on Robotics and Automation
(ICRA), pages 80198026. IEEE, 2020.
Richard Bloss. Mobile hospital robots cure numerous
logistic needs.
Industrial Robot: An International
Susanne Bdker, Christian Dindler, Ole S. Iversen, and
Rachel C. Smith. What Is Participatory Design?, pages
513. Springer International Publishing, 2022.
neurorehabilitation at home. In Proceedings of the 2024
ACMIEEE International Conference on Human-Robot
G. Bradski. The OpenCV Library. Dr. Dobbs Journal
of Software Tools, 2000.
Kimberly A Brink and Henry M Wellman.
teachers for children? young children trust robots
depending on their perceived accuracy and agency.
Developmental Psychology, 56(7):1268, 2020.
Niccol Buetti, Jonas Marschall, Marci Drees, Mo-
hamad G. Fakih, Lynn Hadaway, Lisa L. Maragakis, Eliz-
abeth Monsees, Shannon Novosad, Naomi P OGrady,
Mark E. Rupp, Joshua Wolf, Deborah Yokoe, and
Leonard A. Mermel.
Strategies to prevent central
line-associated bloodstream infections in acute-care
Tyler Bysshe, Yue Gao, Krysta Heaney-Huls, Jason
the additional hospital inpatient cost and mortality
associated with selected hospital-acquired conditions.
Technical report, Agency for Healthcare Research and
Davide Calvaresi, Amro Najjar, Andrea Omicini, Reyhan
and Kary Frmling.
Explainable and transparent
ai and multi-agent systems.
LECTURE NOTES IN
COMPUTER SCIENCE, 14127:1281, 2023.
Erran Carmel, Randall D. Whitaker, and Joey F. George.
Pd and joint application design: a transatlantic com-
parison.
Commun. ACM, 36:4048, 1993.
Joo Carreira and Andrew Zisserman. Quo vadis, action
recognition? a new model and the kinetics dataset. In
2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pages 47244733, 2017.
Ginevra Castellano, Ana Paiva, Arvid Kappas, Ruth
robotic tutors. In Artificial Intelligence in Education:
16th International Conference, AIED 2013, Memphis,
736. Springer, 2013.
Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreed-
Explicability? legibility? predictability? transparency?
privacy? security? the emerging landscape of inter-
pretable agent behavior. In Proceedings of the interna-
tional conference on automated planning and scheduling,
volume 29, pages 8696, 2019.
Jie Chen, Jian Yang, Fen Hu, Si-Hong Yu, Bing-Xiang
Standardised
simulation-based emergency and intensive care nursing
curriculum to improve nursing students performance
during simulated resuscitation: a quasi-experimental
study. Intensive and Critical Care Nursing, 46:5156,
Sonia Chernova and Andrea L Thomaz. Robot learning
from human teachers. Synthesis lectures on artificial
intelligence and machine learning, 8(3):1121, 2014.
Wongun Choi, Caroline Pantofaru, and Silvio Savarese.
Detecting and tracking people using an rgb-d camera
via multiple detector fusion. In 2011 IEEE interna-
tional conference on computer vision workshops (ICCV
workshops), pages 10761083. IEEE, 2011.
Yeu-Hui Chuang, Fu-Chih Lai, Chia-Chi Chang, and
Hsu-Tien Wan. Effects of a skill demonstration video
delivered by smartphone on facilitating nursing students
skill competencies and self-confidence: A randomized
controlled trial study. Nurse education today, 66:6368,
Cristina Conati, Oswald Barral, Vanessa Putnam, and
Lea Rieger. Toward personalized xai: A case study in
intelligent tutoring systems. Artificial intelligence, 298:
Angelo Dante, Alessia Marcotullio, Vittorio Masotta,
Valeria Caponnetto, Carmen La Cerra, Luca Bertocchi,
Cristina Petrucci, and Celeste M Alfes. From high-
fidelity patient simulators to robotics and artificial intelli-
learning in nursing education. In Methodologies and
Intelligent Systems for Technology Enhanced Learning,
10th International Conference. Workshops: Volume 2,
pages 111118. Springer, 2021.
Angelo Dante, Carmen La Cerra, Vittorio Masotta,
Valeria Caponnetto, Luca Bertocchi, Alessia Marcotullio,
Fabio Ferraiuolo, Celeste M Alfes, and Cristina Petrucci.
The use of robotics to enhance learning in nursing
Intelligent Systems for Technology Enhanced Learning,
11th International Conference 11, pages 217226.
Fred Davis. Perceived usefulness, perceived ease of use,
and user acceptance of information technology. MIS
Munjal Desai, Poornima Kaniarasu, Mikhail Medvedev,
Aaron Steinfeld, and Holly Yanco. Impact of robot
failures and feedback on real-time trust. In 2013 8th
ACMIEEE International Conference on Human-Robot
Interaction (HRI), pages 251258. IEEE, 2013.
Barkha Devi, Bidita Khandelwal, and Mridula Das.
Comparison of the effectiveness of video-assisted
teaching program and traditional demonstration on
nursing students learning skills of performing obstetrical
palpation. Iranian journal of nursing and midwifery
Jonathan
simulation to adapt nursing education to times of crisis:
A scoping review during covid-19 pandemic. Teaching
and Learning in Nursing, 2024.
Georgia Ann Dinndorf-Hogenson, Carrie Hoover,
Jodi Lisbeth Berndt, Bethany Tollefson, Jennifer Pe-
classroom model to psychomotor skill acquisition in
nursing. Nursing education perspectives, 40(2):99101,
Melissa Donnermann, Philipp Schaper, and Birgit Lugrin.
Social robots in applied settings: A long-term study on
adaptive robotic tutors in higher education. Frontiers in
Robotics and AI, 9:831633, 2022.
Davide Falanga, Philipp Foehn, Peng Lu, and Davide
Scaramuzza. Pampc: Perception-aware model predictive
control for quadrotors. In 2018 IEEERSJ International
Conference on Intelligent Robots and Systems (IROS),
pages 18. IEEE, 2018.
Haoqi Fan, Yanghao Li, Bo Xiong, Wan-Yen Lo, and
Christoph Feichtenhofer. Pyslowfast.
Julie Fitzwater, Jeanette McNeill, Diane Monsivais,
and Franchesca Nunez. Using simulation to facilitate
transition to the nurse educator role: An integrative
review. Nurse educator, 2021.
Joseph D Forrester, Paul M Maggio, and Lakshika
Tennakoon. Cost of health care-associated infections in
the united states. Journal of patient safety, 2022.
Olivier Pierre Friard, Marco Gamba, et al. Behavioral
observation research interactive software (boris). 2016.
Matthew Gombolay, Xi Jessie Yang, Bradley Hayes,
Nicole Seo, Zixi Liu, Samir Wadhwania, Tania Yu, Neel
in the coordination of patient care. The International
Journal of Robotics Research, 37(10):13001316, 2018.
Lisa A Gorski, Lynn Hadaway, Mary E Hagle, Daphne
Barb Nickel, Stephen Rowley, Elizabeth Sharpe, and
Mary Alexander. Infusion therapy standards of practice,
8th edition. Journal of infusion nursing: the official
publication of the Infusion Nurses Society, 2021.
Chunhui Gu, Chen Sun, David A Ross, Carl Vondrick,
Caroline Pantofaru, Yeqing Li, Sudheendra Vijaya-
temporally localized atomic visual actions. In Proceed-
ings of the IEEE conference on computer vision and
pattern recognition, pages 60476056, 2018.
Yaohui Guo and X Jessie Yang. Modeling and predicting
trust dynamics in humanrobot teaming: A bayesian
inference approach. International Journal of Social
Lisa M Haddad, Pavan Annamaraju, and Tammy J
Toney-Butler. Nursing shortage. StatPearls [Internet],
Zhao Han, Daniel Giger, Jordan Allspaw, Michael S
the foundation of robot explanation generation using
behavior trees. ACM Transactions on Human-Robot
Interaction (THRI), 10(3):131, 2021.
Rex Hartson and Partha S. Pyla. The UX Book. Elsevier,
Bradley Hayes and Julie A Shah.
Improving robot
controller transparency through autonomous policy
explanation. In Proceedings of the 2017 ACMIEEE
international conference on human-robot interaction,
Matthew A Hicks, Patrycja Popowicz, and Peter P Lopez.
Central line management.
In StatPearls [Internet].
StatPearls Publishing, 2023.
Marjan Hospers, Erna Kroezen, Anton Nijholt, Rieks
op den Akker, and Dirk Heylen. An agent-based intelli-
gent tutoring system for nurse education. Applications of
Software Agent Technology in the Health Care Domain,
Ming Hu, Lin Wang, Siyuan Yan, Don Ma, Qingli Ren,
Peng Xia, Wei Feng, Peibo Duan, Lie Ju, and Zongyuan
Ge. Nurvid: A large expert-level video database for
nursing procedure activity understanding. Advances in
Neural Information Processing Systems, 36, 2024.
Sandy H. Huang, David Held, Pieter Abbeel, and
Anca D. Dragan.
Enabling robots to communicate
their objectives. Autonomous Robots, 43(2), February
Ronda G Hughes(ed.).
Patient Safety and Quality:
An Evidence-Based Handbook for Nurses. Agency for
Healthcare Research and Quality (AHRQ), 2008.
Kathleen M Huun and James E Slaven. Robotic telepres-
ence and face-to-face collaborative nursing simulation: A
in Nursing, 90:101525, 2024.
Brian Ichter, Benoit Landry, Edward Schmerling, and
Marco Pavone. Perception-aware motion planning via
multiobjective search on gpus. In Robotics Research:
The 18th International Symposium ISRR, pages 895912.
realsense
architecture-and-technologyrealsense-overview.html.
Minako Ito, Haruhiko Mitsunaga, and Toshiko Ibe.
Survey of onboarding programs of hospitals for newly
hired experienced nurses. Journal of St. Lukes Society
for Nursing Research (SLNR), 24, 2021.
Mari Kangasniemi, Suyen Karki, Noriyo Colley, and
Ari Voutilainen. The use of robots and other automated
devices in nurses work: An integrative review. In-
ternational journal of nursing practice, 25(4):e12739,
Ulas Berk Karli, Juo-Tung Chen, Victor Nikhil Antony,
and Chien-Ming Huang. Alchemist: Llm-aided end-
user development of robot applications. In Proceedings
of the 2024 ACMIEEE International Conference on
Human-Robot Interaction, pages 361370, 2024.
Charles C Kemp, Aaron Edsinger, Henry M Clever,
and Blaine Matulevich.
The design of stretch: A
human environments. In 2022 International Conference
on Robotics and Automation (ICRA), pages 31503157.
Finn Kensing, Jesper Simonsen, and Keld Bodker. Must:
A method for participatory design. HumanComputer
Callie Y Kim, Christine P Lee, and Bilge Mutlu.
Understanding large-language model (llm)-powered
human-robot interaction. In Proceedings of the 2024
ACMIEEE International Conference on Human-Robot
Thomas E Kirschling, Steve S Rough, and Brad C
Ludwig. Determining the feasibility of robotic courier
medication delivery in a hospital setting. American
Journal of Health-System Pharmacy, 66(19):17541762,
Bing Cai Kok and Harold Soh.
Trust in robots:
Challenges and opportunities. Current Robotics Reports,
C Koutsojannis, J Prentzas, and I Hatzilygeroudis. A
web-based intelligent tutoring system teaching nursing
students fundamental aspects of biomedical technology.
In 2001 Conference Proceedings of the 23rd Annual
International Conference of the IEEE Engineering in
Medicine and Biology Society, volume 4, pages 4024
Andre W Kushniruk and Vimla L Patel.
Cognitive
and usability engineering methods for the evaluation
of clinical information systems. Journal of biomedical
Minae Kwon, Sandy H Huang, and Anca D Dragan.
Expressing robot incapability. In Proceedings of the
2018 ACMIEEE International Conference on Human-
Robot Interaction, pages 8795, 2018.
Isaac Lage, Daphna Lifschitz, Finale Doshi-Velez, and
Ofra Amir. Exploring computational user models for
agent policy summarization. In IJCAI: proceedings
of the conference, volume 28, page 1401. NIH Public
Hee Rin Lee, Selma abanovic, Wan-Ling Chang,
Shinichi Nagata, Jennifer Piatt, Casey Bennett, and
David Hakken. Steps toward participatory design of
social robots: Mutual learning with older adults with
depression. In Proceedings of the 2017 ACMIEEE
International Conference on Human-Robot Interaction,
HRI 17, page 244253. Association for Computing
James R Lewis. Sample sizes for usability studies:
Additional considerations. Human factors, 36(2):368
Michael Lewis, Katia Sycara, and Phillip Walker. The
role of trust in human-robot interaction. Foundations of
trusted autonomy, pages 135159, 2018.
Daniel Leyzberg, Samuel Spaulding, Mariya Toneva,
and Brian Scassellati. The physical presence of a robot
tutor increases cognitive learning gains. In Proceedings
of the annual meeting of the cognitive science society,
volume 34, 2012.
Daniel Leyzberg, Aditi Ramachandran, and Brian Scas-
sellati. The effect of personalization in longer-term
robot tutoring. ACM Transactions on Human-Robot
Interaction (THRI), 7(3):119, 2018.
Zhi Li, Peter Moran, Qingyuan Dong, Ryan J Shaw,
and Kris Hauser. Development of a tele-nursing mobile
manipulator for remote care-giving in quarantine areas.
In 2017 IEEE International Conference on Robotics
and Automation (ICRA), pages 35813586. IEEE, 2017.
Terri Link. Guideline implementation: sterile technique.
AORN journal, 110(4):415425, 2019.
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian
Berg. Ssd: Single shot multibox detector. In Bastian
Computer Vision  ECCV 2016, pages 2137, Cham,
2016. Springer International Publishing. ISBN 978-3-
Yu Lu, Deliang Wang, Penghe Chen, and Zhi Zhang.
Design and evaluation of trustworthy knowledge tracing
model for intelligent tutoring system. IEEE Transactions
on Learning Technologies, 2024.
Camillo Lugaresi, Jiuqiang Tang, Hadon Nash, Chris
Chuo-Ling Chang, Ming Guang Yong, Juhyun Lee, Wan-
Teh Chang, Wei Hua, Manfred Georg, and Matthias
Grundmann.
perception pipelines. ArXiv, 2019.
Karthik Mahadevan, Jonathan Chien, Noah Brown,
Zhuo Xu, Carolina Parada, Fei Xia, Andy Zeng, Leila
robot behaviors using large language models.
Proceedings of the 2024 ACMIEEE International
Conference on Human-Robot Interaction, pages 482
Abrar Majeedi, Ryan M McAdams, Ravneet Kaur,
Shubham Gupta, Harpreet Singh, and Yin Li. Deep
learning to quantify care manipulation activities in
neonatal intensive care units. npj Digital Medicine,
M Marc, A Bartosiewicz, J Burzynska, Z Chmiel, and
P Januszewicz. A nursing shortagea prospect of global
and local policies. International nursing review, 66(1):
Sneha Mehta. Top 6 participatory design methods for
your project, 2024. URL
participatory-design-methods.
Stephanie Milani, Nicholay Topin, Manuela Veloso, and
Fei Fang. Explainable reinforcement learning: A survey
and comparative review. ACM Computing Surveys, 56
Michael J Muller and Sarah Kuhn. Participatory design.
Communications of the ACM, 36(6):2428, 1993.
Laurentiu-Marian
Intelligent tutoring systems for psychomotor traininga
systematic literature review. In International Confer-
ence on Intelligent Tutoring Systems, pages 335341.
Heather OBrien, Paul Cairns, and Mark Hall. A practical
approach to measuring user engagement with the refined
user engagement scale (ues) and new ues short form.
International Journal of Human-Computer Studies, 112,
Naomi P OGrady. Prevention of central line-associated
bloodstream infections. The New England journal of
Joon Sung Park, Joseph OBrien, Carrie Jun Cai,
Meredith Ringel Morris, Percy Liang, and Michael S
Bernstein. Generative agents: Interactive simulacra of
human behavior. In Proceedings of the 36th annual acm
symposium on user interface software and technology,
pages 122, 2023.
Andr Pereira, Carlos Martinho, Iolanda Leite, and Ana
Paiva. Icat, the chess player: The influence of embod-
iment in the enjoyment of a game. In International
Joint Conference on Autonomous Agents and Multiagent
2008. International Foundation for Autonomous Agents
and Multiagent Systems. ISBN 9780981738123.
Peizhu Qian and Vaibhav Unhelkar. Evaluating the
role of interactivity on improving transparency in
autonomous agents. In Proceedings of the 21st Interna-
tional Conference on Autonomous Agents and Multiagent
Foundation for Autonomous Agents and Multiagent
Peizhu Qian and Vaibhav Vasant Unhelkar. Interactively
explaining robot policies to humans in integrated virtual
and physical training environments.
In Companion
of the 2024 ACMIEEE International Conference on
Human-Robot Interaction, pages 847851, 2024.
Carlos Quintero-Pena, Peizhu Qian, Nicole M Fontenot,
Hsin-Mei Chen, Shannan K Hamlin, Lydia E Kavraki,
and Vaibhav Unhelkar. Robotic tutors for nurse training:
Opportunities for hri researchers.
In 2023 32nd
IEEE International Conference on Robot and Human
Interactive Communication (RO-MAN), pages 220225.
Aditi Ramachandran, Chien-Ming Huang, Edward Gart-
Thinking aloud with a
tutoring robot to enhance learning.
In Proceedings
of the 2018 ACMIEEE international conference on
human-robot interaction, pages 5968, 2018.
Aditi Ramachandran, Sarah Strohkorb Sebo, and Brian
Scassellati.
Personalized robot tutoring using the
assistive tutor POMDP (AT-POMDP). In Proceedings
of the AAAI Conference on Artificial Intelligence,
volume 33, pages 80508057, 2019.
Ramya Ramakrishnan, Vaibhav Unhelkar, Ece Kamar,
and Julie Shah. A bayesian approach to identifying rep-
resentational errors. arXiv preprint arXiv:2103.15171,
Joseph Redmon, Santosh Divvala, Ross Girshick, and
Ali Farhadi. You only look once: Unified, real-time
object detection. In 2016 IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), pages 779788,
Elijah W Riddle, Divya Kewalramani, Mayur Narayan,
Daniel B Jones, and Benjamin F Rush.
Surgical
Current Problems in Surgery, page 101625, 2024.
A Romero, J De La Hoz, and JD Gonzlez. Robots in
nursing education: a bibliometric analysis. In Journal of
IOP Publishing, 2019.
Yao Rong, Tobias Leemann, Thai-Trang Nguyen, Lisa
Gjergji Kasneci, and Enkelejda Kasneci.
human-centered explainable ai: A survey of user studies
for model explanations. IEEE transactions on pattern
analysis and machine intelligence, 2023.
Fatai Sado, Chu Kiong Loo, Wei Shiung Liew, Matthias
agents and robots-a comprehensive review.
Computing Surveys, 55(10):141, 2023.
Nicole Salomons and Brian Scassellati. Time-dependant
bayesian knowledge tracing - robots that model user
skills over time. Frontiers in robotics and AI, 2024.
Nicole Salomons, Kaitlynn Taylor Pineda, Adrnk
Adults with low prior domain knowledge learn more
from a peer robot than a tutor robot. In 2022 17th
ACMIEEE International Conference on Human-Robot
Interaction (HRI), pages 176184. IEEE, 2022.
Sangwon Seo, Lauren R Kennedy-Metz, Marco A
Unhelkar. Towards an ai coach to infer team mental
model alignment in healthcare. In 2021 IEEE Conference
on Cognitive and Computational Aspects of Situation
Management (CogSIMA), pages 3944. IEEE, 2021.
S Shiny and D Venkatachalam. An analysis on the
integration of ai to assist staff nurses and patients in
intensive care units. In 2024 3rd International Confer-
ence on Applied Artificial Intelligence and Computing
(ICAAIC), pages 7983. IEEE, 2024.
Matthijs Smakman and Elly A Konijn. Robot tutors:
Welcome or ethically questionable?
In Robotics in
376386. Springer, 2020.
Richard A Smiley, Clark Ruttinger, Carrie M Oliveira,
Laura R Hudson, Richard Allgeyer, Kyrani A Reneau,
Josephine H Silvestre, and Maryann Alexander. The
2020 national nursing workforce survey. Journal of
Nursing Regulation, 12(1):S1S96, 2021.
Clay Spinuzzi. The methodology of participatory design.
Technical communication, 52(2):163174, 2005.
Sarath Sreedharan, Tathagata Chakraborti, and Subbarao
Kambhampati. Foundations of explanations as model
reconciliation. Artificial Intelligence, 301:103558, 2021.
James W Suliburk, Quentin M Buck, Chris J Pirko,
Nader N Massarweh, Neal R Barshes, Hardeep Singh,
and Todd K Rosengart. Analysis of human performance
deficiencies associated with surgical adverse events.
JAMA network open, 2(7):e198067e198067, 2019.
Arie Rachmad Syulistyo, Yuichiro Tanaka, and Hakaru
Tamukoh. Recognizing nursing activities in endotracheal
and large language models. International Journal of
Activity and Behavior Computing, 2024(2):122, 2024.
Aaquib Tabrez, Shivendra Agrawal, and Bradley Hayes.
Explanation-based reward coaching to improve human
performance via reinforcement learning. In 2019 14th
ACMIEEE International Conference on Human-Robot
Interaction (HRI), pages 249257, 2019. doi: 10.1109
Angelique Taylor, Hee Rin Lee, Alyssa Kubota, and
Laurel D Riek.
Coordinating clinical teams: Using
robots to empower nurses to stop the line. Proceedings
of the ACM on Human-Computer Interaction, 3(CSCW):
Angelique Taylor, Tauhid Tanjim, Huajie Cao, and
Hee Rin Lee. Towards collaborative crash cart robots
that support clinical teamwork. In Proceedings of the
2024 ACMIEEE International Conference on Human-
Robot Interaction, pages 715724, 2024.
Sam Thellman and Tom Ziemke. The perceptual belief
social robotics. ACM Transactions on Human-Robot
Interaction (THRI), 10(3):115, 2021.
Andrea Thomaz. Robots in real life: Putting hri to work.
In Proceedings of the 2023 ACMIEEE International
Conference on Human-Robot Interaction, pages 33,
Eylem Topbas, Banu Terzi, znur Grgen, and Glay
Effects of different education methods in
peritoneal dialysis application training on psychomotor
skills and self-efficacy of nursing students. Technology
and Health Care, 27(2):175182, 2019.
Jesus Tordesillas and Jonathan P How.
Perception-aware trajectory planner in dynamic envi-
ronments. IEEE Access, 10:2266222677, 2022.
Matthias Tschpe, Stefan Gerd Fritsch, David Habusch,
Vitor Fortes Rey, Agnes Grnerbl, and Paul Lukowicz.
Evaluating deep learning models for posture and move-
ment recognition during the abcde protocol in nurse
education. In 2024 International Conference on Activity
and Behavior Computing (ABC), pages 110. IEEE,
Chris Varghese, Ewen M Harrison, Greg OGrady, and
Eric J Topol. Artificial intelligence in surgery. Nature
Mudit Verma, Siddhant Bhambri, and Subbarao Kamb-
hampati. Theory of mind abilities of large language
models in human-robot interaction: An illusion? In Com-
panion of the 2024 ACMIEEE International Conference
on Human-Robot Interaction, pages 3645, 2024.
David K Warren, Wasim W Quadir, Christopher S
Victoria J Fraser. Attributable cost of catheter-associated
bloodstream infections among intensive care patients in
a nonteaching hospital. Critical care medicine, 2006.
Olivia Watkins, Sandy Huang, Julius Frost, Kush Bha-
robot policies. Applied AI Letters, 2(4):e52, 2021.
Katie Winkle, Emmanuel Senft, and Sverin Lemaignan.
of autonomous social robots. Frontiers in Robotics and
H Worlikar, V Vyas Vadhiraj, Aoife Murray, J OConnell,
C Connolly, JC Walsh, and DT OKeeffe. Is it feasible
to use a humanoid robot to promote hand hygiene
adherence in a hospital setting? Infection Prevention in
Holly A Yanco, Munjal Desai, Jill L Drury, and Aaron
Steinfeld.
Methods for developing trust models for
intelligent systems. Robust intelligence and trust in
autonomous systems, pages 219254, 2016.
X Jessie Yang, Vaibhav V Unhelkar, Kevin Li, and
Julie A Shah. Evaluating effects of user experience
and system transparency on trust in automation. In
Proceedings of the 2017 ACMIEEE international
conference on human-robot interaction, pages 408416,
Tuba Yilmazer and Melih Elcin. The effect of high
and medium fidelity simulator in cardiopulmonary
resuscitation training on nursing students knowledge
and performances.
International Journal of Caring
Rui Zeng, Yuhui Wen, Wang Zhao, and Yong-Jin Liu.
View planning in robot active vision: A survey of
Visual Media, 6:225245, 2020.
Bowen Zhang and Harold Soh. Large language models
as zero-shot human models for human-robot interaction.
In 2023 IEEERSJ International Conference on Intel-
ligent Robots and Systems (IROS), pages 79617968.
Jesse Zhang, Jiahui Zhang, Karl Pertsch, Ziyi Liu, Xiang
Bootstrap your own skills: Learning to solve new tasks
with large language model guidance. In Conference on
Robot Learning, pages 302325. PMLR, 2023.
Matthew J Ziegler, Daniela C Pellegrini, and Nasia
Safdar. Attributable mortality of central line associated
bloodstream infection: systematic review and meta-
analysis. Infection, 43:2936, 2015.
