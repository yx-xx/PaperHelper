=== PDF文件: ASTRID A Robotic Tutor for Nurse Training to Reduce Healthcare-Associated Infections.pdf ===
=== 时间: 2025-07-19 18:15:03.732378 ===

请从以下论文内容中，按如下JSON格式严格输出（所有字段都要有，关键词字段请只输出一个中文关键词，要中文关键词）：
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：A : A Robotic Tutor for Nurse Training
STRID
to Reduce Healthcare-Associated Infections
Peizhu Qian∗, Filip Bajraktari∗, Carlos Quintero-Peña∗, Qingxi Meng∗,
Shannan Hamlin†, Lydia Kavraki‡, and Vaibhav Unhelkar‡
∗Department of Computer Science, Rice University, Houston, Texas USA
pqian@rice.edu, filip.bajraktari@rice.edu, carlosq@rice.edu, qm15@rice.edu
†Center for Nursing Research, Education and Practice, Houston Methodist, Houston, Texas USA
shamlin@houstonmethodist.org
‡Ken Kennedy Institute, Rice University, Houston, Texas USA
kavraki@rice.edu, unhelkar@rice.edu
Abstract—The central line dressing change is a life-critical
procedure performed by nurses to provide patients with rapid
infusion of fluids, such as blood and medications. Due to their
complexityandtheheavyworkloadsnursesface,dressingchanges
are prone to preventable errors that can result in central line-
associated bloodstream infections (CLABSIs), leading to serious
health complications or, in the worst cases, patient death. In the
post-COVID-19 era, CLABSI rates have increased, partly due to
the heightened nursing workload caused by shortages of both
registered nurses and nurse educators. To address this challenge,
healthcarefacilitiesareseekinginnovativenursetrainingsolutions
to complement expert nurse educators.
Inresponse,wepresentthedesign,developmentandevaluation
of a robotic tutoring system, ASTRID: the Automated Sterile
Technique Review and Instruction Device. ASTRID, which is the
outcome of a two-year participatory design process, is designed
Fig.1. ArtificialrenderingofthetrainingenvironmentandASTRID,which
iscomposedoftheStretchrobot,adepthcamera,andacomputerscreen.
to aid in the training of nursing skills essential for CLABSI
prevention. First, we describe insights gained from interviews
with nurse educators and nurses, which revealed the gaps of
currenttrainingmethodsandrequirementsfornewtrainingtools. patient care, nursing staff must be regularly upskilled. For
Basedonthesefindings,weoutlinethedevelopmentofourrobotic example, the Houston Methodist hospital system trains over a
tutor, which interacts with nursing students, providing real-time
thousand nurses each year. This process includes instruction
interventions and summary feedback to support skill acquisition.
from nursing educators, followed by skill refinement under
Finally, we present evaluations of the system’s performance and
perceivedusefulness,conductedinasimulatedclinicalsettingwith the supervision of an experienced nurse mentor. Sustaining
nurse participants. These evaluations demonstrate the potential the traditional nurse-to-nurse training model is increasingly
of our robotic tutor in nursing education. Our work highlights challenging [47, 101, 63].
the importance of participatory design for robotics systems, and
As a result, healthcare facilities are actively exploring
motivates new avenues for foundational research in robotics.
innovative solutions to enhance and support nursing edu-
Index Terms—Robotics in Healthcare, Human-Centered
Robotics, Intelligent Tutors, Participatory Design cation [107, 37, 38, 1, 42, 113]. We posit that robotic tutors
can help address this urgent need for nursing education.
I. INTRODUCTION Specifically, robotic tutors can allow nursing students to
As the largest sector of healthcare, nurses play a critical practicecriticalskillswhenexpertnursesareunavailable,com-
role in delivering high-quality patient care and maintaining the plementing nurse-to-nurse training. Examining this hypothesis,
stabilityofthe entire healthcare system. However,this stability we present ASTRID: a robotic tutor for nursing education.
is now at risk due to a significant global shortage of nursing ASTRID is designed to help nurses acquire necessary skills
professionals [90, 115, 54]. Among other challenges to patient to reduce the chances of healthcare-associated infections .
health outcomes, this shortage is placing an increased burden Healthcare-associated infections, which refer to infections that
onnursingeducatorstotrainanewgenerationofprofessionals, occur while the patient is receiving care, can lead to serious
while hospitals are tasked with recruiting and onboarding a complications including death [130, 140, 26, 48]. The rates of
substantial number of new nurses each year. these infections have exacerbated post-COVID-19, in part due
Beyond formal education in nursing schools, hospitals to the nursing shortage. These infections, however, are largely
allocate substantial resources to train new nurses in hospital- preventable through meticulous care, adherence to protocols,
specific practices . With the increasing complexity of and regular training — currently delivered through a nurse-to-
Fig.2. NursespracticingdressingchangeprocedureswithASTRIDinatrainingenvironment(alsoreferredtoassimulationlabintheclinicalcommunity).
ASTRID offers (left) real-time guidance,(middle) physicalinterventions,and(right) post-practice feedbackto help nurses master“principles ofsterile
technique”forpreventinghealthcare-associatedinfections.
nurse model [84, 25, 96]. ASTRID aims to complement this Nursing Care
training by enabling nursing students, nursing residents, and
early-career nurses (collectively referred to as nursing students Assistance with Assistance with
Decision Making Physical Tasks
in this paper) to practice andimprove theirskills,even without
[20, 47, 116] [4-6, 69, 119]
the presence of an expert nurse. Cognitive Physical
Assistance Assistance
We, a cross-disciplinary team of roboticists and nursing
professionals, designed ASTRID through a two-year partici- Our Work
patory design process. First, through exploratory brainstorm
sessionsandrequirementcapture(Sec.III),weidentifiedsystem
requirements including necessary perception, manipulation,
Nursing Education
interaction, and tutoring capabilities. Guided by these require-
ments,weengagediniterativeprototypedevelopment(Sec.IV).
As depicted in Fig. 1, ASTRID is realized using the Stretch Fig.3. Priorworkinroboticsfornursingfocusesonprovidingnurseswith
mobile manipulator , an off-board depth camera , and assistanceindecisionmakingandphysicaltasksinnursingcare.Incontrast,
thispaperfocusesonroboticassistanceinnursingeducation.
acomputer. Usingitsperception,ASTRID monitorsstudentsas
they practice dressing changes on simulated patients (Fig. 2-
left),providingreal-timefeedbackwhenactionsthatcouldlead
A. Robotics for Nursing
to infections are detected. Using its mobile manipulation, the
robot simulates scenarios (Fig. 2-middle) that are associated In response to nursing shortages and growing workloads,
withincreasedlikelihoodofhumanerrors,suchasinterruptions. “robotics for nursing” has become a vibrant research area [72,
Aftereachtrainingsession,ASTRIDprovidesasummaryreport 20,5,67,6].Mostofthisworkhasfocusedonrobotsthatassist
via the computer monitor (Fig. 2-right), enabling students to nurses in homes and hospitals, with little work on robotics for
review their performance and identify areas for improvement. nursing education.
These features aim to complement the training provided by 1) Nursing Care: Robotic assistants, including commer-
expert nurses, who may not always be available. ciallyavailableproducts,arebeingdevelopedtosupportnurses
We evaluated ASTRID in a human-subject feasibility study [50, 121, 124]. Pilot studies have shown success in using
with nine nurses (Sec. V). Results demonstrate that ASTRID robots for tasks such as fetching supplies and disinfecting
can detect student errors almost as accurately as a nursing rooms [83, 4, 133]. As illustratedin Figure 3,existing systems
instructor, indicating its potential as an effective tutor. Ad- provide a mix of cognitive and physical assistance, primarily
ditionally, subjective questionnaires reveal that participants focusing on nursing care. In contrast, our work centers on
find the system useful. Finally, the evaluations suggest several nursing education. While our focus differs, our approach is
promising directions for both foundational research in robotics informed by robots designed for nursing care.
and their practical applications in nursing education. 2) Nursing Education: Nursing research highlights the
growing need for technology in nursing education [63, 107,
37, 38], with its role evolving rapidly since the COVID-19
II. RELATEDWORK pandemic. This shift has seen increased use of videos [43, 8,
35, 41] and simulations [32, 125, 136]. Closer to our focus,
We review relevant literature on nursing, robotic tutors, and humanoidrobot-patientsandtelepresencerobotsarebeing
participatory design that informs our research. Figs. 3 and 4 explored to make nursing education more accessible .
summarizes the priorworkin the area ofrobots in nursing and However, to our knowledge, the potential of robotic tutors in
robotictutoringsystems,andillustratestheuniquecontribution nursing remains untapped and ASTRID is the first-of-its-kind
of our work. robotic tutor for nursing.
Physical Skills III. REQUIREMENTCAPTURE
To design the robotic tutor, we adopted a three-step partici-
patory design process: requirement capture, prototype design,
Our Work
and feasibility study. This section focuses on the first step,
Cognitive Physical aimed at first identifying which nursing skills would benefit
Intervention Intervention
most from robotic tutors and then determining the design
Tutors Using Tutors Using
Cognitive Intervention Physical Intervention requirements for the robotic tutor. We achieve these aims
[9-11, 15, 28, 42, 78, 79, 98] [110, 120]
through an exploratory phase, which are followed by focused
interviews with stakeholders.
Cognitive Skills
A. Exploratory Phase
We believe robotic tutors have the potential to assist in a
Fig.4. Priorworkonrobotictutorsprimarilyfocusesoncognitiveskill
variety of nursing education settings. To identify the most
training.Incontrast,weexploretheroleofrobotictutorsinphysicalskill
training, integrating both cognitive and physical interventions to enhance suitable setting for the first such tutor, our cross-disciplinary
physicalskillexecution. teambeganwithinternalbrainstormingsessions.Thesesessions
were also crucial for aligning the team. Roboticists attended
nurse training sessions to learn about clinical practices and
B. Robotic Tutors
build rapport with nursing professionals—an essential step
Intelligent tutoring systems have been developed for various for this interdisciplinary effort. Two early tutor prototypes
learning environments, including K-12 education, corporate were developed, which helped refine the research questions
training, and medicine [103, 104, 94, 74, 59, 2, 3]. More and assess feasibility. Through this exploration, the central
recently, robotic tutors have emerged that offer additional line dressing change (CLDC) emerged as a key focus due to
benefitssuchasenhancedstudentinteraction,improvedlearning it being a frequently-performed procedure, need for periodic
outcomes,and increased trust and engagement [81, 15, 98, 10, training due to occurence of preventable human errors, and
30, 9, 11, 44, 102, 82], by leveraging their physical presence potential for robotic assistance.
and interaction capabilities.These systems allow students to CLDC is a crucial step in maintaining the sterility and
practice and learn even when teachers are unavailable, aiming preventing infection of a central venous catheter or central
to enhance personalization and accessibility of instruction. line, a medical device used to deliver fluids, medications, or
Most robotic tutors, as illustrated in Figure 4, rely primarily nutrition directly into a large vein. Maintenance of the central
on conversational instructions and lack mobile manipulation line is complex and life-critical, protecting patient against
capabilities. Research in human-robot interaction (HRI) has infections[51,58].OnedevastatingcomplicationduringCLDC
looked using a physical intervention to improve human is the central line-associated bloodstream infection (CLABSI),
learners’ cognitive skills such as problem solving  and which accounts for 17% of the almost one million healthcare-
knowledge in circuit design . In contrast, our work uses associated infections per year . Fortunately, CLABSIs are
a robot’s perception and mobile manipulation capabilities to preventable with meticulous nursing care and adherence to
assess and enhance students’ physical skill execution. established protocols [84, 25, 96]. These safety protocols,
referred to as the “principles of sterile technique,” outline
C. Participatory Design
essentialrulesformaintainingsterilityduringdressingchanges.
Participatory design is a collaborative process that involves In this paper, we focus on nursing skills corresponding to four
users in the process of designing a new service or technology. key rules which are illustrated in Fig. 5.
It combines the knowledge of the users with the skills of
B. Focused Interviews
system designers, ensuring the inclusion of user needs in
the design process [56, 21]. A participatory design process Having identified a suitable nursing setting, we turned to
usually starts with reciprocal learning in which users and defining the design requirements for the robotic tutor. We
designers learn about each others’ roles: designers learn about conducted focused interviews with three stakeholder groups:
work practices from users and users learn about technical nursing students, experienced nurses, and nurse educators.
constraints from designers . While many participatory Further details about the participant recruitment methodology
design methods exist [116, 93], the most widely used methods are provided in the Appendix.
include: participatory design workshops, collaborative focus 1) Methodology: The interview protocol was approved
groups, prototyping, visits to other institutions, and usability by Rice University IRB and structured in three parts, each
testing [70, 91]. Participatory design has found success in addressing a specific goal. The first part focused on un-
design of robots, including those designed for healthcare and derstanding participants’ experiences with CLDC and the
tutoring[16,78,122,132].Informedbytheseworks,weutilize challenges they face in adhering to the sterile technique. The
a combination of participatory design methods to capture second part explored current training methods, asking if the
nurses’ needs, develop prototypes collaboratively with nurses, challenges identified were addressed and what participants
and evaluate our prototype through a human-subject study. liked or disliked about existing methods. The third part
Hands below Turning back Reaching across Touching
waistline on sterile field sterile field one-inch border
Fig.5. Fourprohibitedbehaviorsduringasterileprocedure,suchasthecentrallinedressingchange.Onceasterilefieldisestablished(theareashownin
blue),nursesneedtomaintainsterilitybyavoidingpotentialcontamination.Inparticular,anursemustkeephandsabovetheirwaistlineandthesterilefield
withinvisionatalltimes.Hands,withsterilegloveson,mustnottouchanythingnon-sterilesuchasthe1-inchborderofthesterilefield.
brainstormed potential solutions, starting with open-ended Number of Groups
discussions about new training aids and then focusing on 0 1 2 3
robotic tutors. Participants were shown a video of an early Real-time Feedback
prototype of the tutoring system and asked for feedback on its
Skill Checklist
usefulness and improvements. This prototype included human
pose estimation (via MediaPipe) and provided visual alerts as
Imperfect Scenarios
on-screen text. The Appendix includes the list of interview
questions and a link to the video of the prototype. Practice for Different Lvls.
2) Participants: Ten participants were interviewed, includ-
Log Sheet of Errors
ingthreenursingstudents,threebedsidenurses,andfournurse
educators. Participants’ ages ranged from 20 to 49 years. The Simulation of Patient’s Reaction
experienced nurses and nurse educators had between 6 and 16
Step-by-step Refresher
years of experience as nurses, with an average of 11.3 years.
3) Results: The focused interviews led to three findings List of Supplies Needed for the Procedure
• All participants rated CLDC to be highly important;
nursing students found maintaining the sterile field chal-
Fig.6. Featuressuggestedbytheparticipantsfornewtrainingaids.
lenging. When asked to rate how challenging CLDC was
intheirexperience,fouroutthetenparticipants,including
all nursing student participants, rated the procedure as
nursesandprovidesfeedbackonmedicalerrors.However,
challenging (> 4 on a scale of 1−7); three rated it
preferences for warnings and feedback varied. For real-
as neutral (= 4); and three rated it as not challenging
time feedback, participants debated audio vs. visual alerts
(<4). However, all participants pointed out that CLDC
and ultimately agreed on both to accommodate different
couldbecomeextremelycomplexwhencompoundedwith
preferences. They emphasized clear, specific explanations
accompanying real-world factors such as disruptions and
of errors over generic beeping sounds to avoid alarm
interruptions resulting from unexpected movements from
fatigue. For post-practice feedback, students preferred
the patients, other patients calling the nurse, or family
a log sheet with timestamps and nurse actions, while
members asking questions during the procedure.
educators suggested a checklist tracking rule violations.
• Current training methods do not emphasize real-world Participants also recommended training aids that simulate
factors.Nursingstudentsfirstlearn aboutCLDCandster-
real-world disruptions and interruptions. Students and
iletechniqueinnursingschool.However,theytypicallydo
bedside nurses further proposed different training levels
not receive hands-on practice until they come to hospitals
based on experience. Lastly, participants had no specific
forinternships,usuallyintheirfinalyearofundergraduate
preferences regarding the robotic tutor’s appearance.
study. During the classroom learning (nursing schools,
orientations, and training sessions), instructors focus on
C. System Requirements
the basics of CLDC (i.e.,the step-by-step procedure),and
do not emphasize the accompanying real-world factors Based on the findings of the exploratory phase and focused
that introduce complexity to CLDC. interviews,we distilledsix key requirements (Rx) fora system
• New training aids, with specific features, can assist in that assists in CLABSI-prevention training. It needs to:
acquisiting of nursing skills. We asked the participants to R1. detect compliance with the sterile technique;
brainstorm new training aids that could help nurses learn R2. providetask-timeguidancetofacilitateskillacquisition;
and practice the skills required for CLDC. Fig. 6 summa- R3. provide summary feedback forefficient training review;
rizesthefeaturesbrainstormedbytheparticipants,labeled R4. simulate scenarios that increase the risk of violations;
with the number of groups (out of 3) that mentioned R5. be perceived as useful by nursing students; and
the feature. All groups supported a system that monitors R6. be perceived as engaging by nursing students.
RGB + Depth Student Pose Sterile Technique Real-time
Camera Data Estimation Compliance Detection Feedback
ML-based Module Rule-based Module
Fig.7. OverviewofASTRID’ssystemarchitectureforprovidingreal-timeguidanceregardingthesteriletechniquetonursingstudents.
IV. PROTOTYPEDESIGN 1) SterileFieldDetection: Eachtrainingsessionbeginswith
ASTRID detecting the sterile field, which corresponds to the
Guided by the system requirements, we design ASTRID:
steriledrape,visibleastheblueareaonthetableinFig.2.The
the Automated Sterile Technique Review and Instruction
drapeisoftenuneven,irregularlyshaped,andcontainssupplies
Device shown in Fig. 2. It is intended for use in training
inside pouches, making detection complex. To ensure robust
environments. In this section, we detail its key features and
detection, ASTRID utilizes a manual calibration method.1 In
their implementation.
particular,before training begins,the user is shown a real-time
image of the training setup on a monitor and marks the four
A. System Overview
corners of the sterile drape using a mouse. This process takes
We begin by translating stakeholder requirements into the
lessthan10secondstocomplete.Ourgeometry-basedsoftware,
core capabilities the robotic tutor must possess:
developed in-house using OpenCV2  and MediaPipe ,
• To detect nurses’ compliance with sterile technique (R1): then uses the pixel positions and corresponding depth values
the robotic tutor requires cameras and computer vision to identify the edges of the sterile field and construct a 3D
algorithms to track nurses, perceive the environment, model of it. Since the sterile field remains static during the
and assess compliance in real time. The perception and procedure,calibration is required only once. In ourevaluations
reasoning modules must operate with low latency to (Sec. V), the experiment proctor performs this calibration.
provide immediate feedback. 2) Student Pose Estimation: During a training session,
• To provide guidance during and after the task (R2, R3): ASTRID monitors the nursing student using its camera to
the robot must generate nursing-specific feedback and
estimate their pose. The pose estimation module is built using
communicate it effectively through audiovisual channels.
MediaPipe.Inparticular,poseestimationisachievedusing
Theguidancemustbebothaccurateandengagingtomeet
a series of pre-trained models, where the first stage detects
R5 and R6, respectively.
human bodies in an RGB frame, and the second stage locates
• To simulate risk-inducing scenarios (R4): The system key landmarks on the hands and body. The hand estimation
needsconversationalandmobilemanipulationcapabilities modelidentifies21landmarks,whiletheposeestimationmodel
to generate both verbal and physical interventions, such tracks 33, with the most relevant for our application being the
as interruptions and distractions.
shoulders, elbows, wrists, and hips. After the pose estimation
These capabilities necessitate a robot with vision-based per- locatesthekeylandmarks,itreturnsthepixelcoordinatesofthe
ception,mobile manipulation,andverbalinteraction. Hence,to landmarks. We then create a 3D environment reconstruction
realize ASTRID,we build upon the Stretch mobile manipulator by projecting the landmarks back to the 3D space. This is
due to its human-safe design, onboard camera, and established to integrate the sterile field information with human pose
use in healthcare robotics . During requirement capture, estimation to enable compliance detection, described next.
a prototype demonstration using Stretch received positive One unique challenge of our use case is that the nurse wears
feedback on nurses’ comfort with the platform. To realize face masks, hairnets, and gloves, which obscure parts of the
remaining capabilities, we augmented Stretch with additional body, and often stands behind tables, limiting visibility and
hardware(anoff-boarddepthcameraandacomputer)and making pose estimation challenging. To tackle this, we set the
software modules for perception, reasoning, and interaction. visibility (a hyperparameter of MediaPipe) of these landmarks
Through the architecture in Fig. 7, ASTRID monitors nursing to 0 to enhance robustness of this automated pose estimation.
students as they practice central line dressing change,provides 3) Sterile Technique Compliance Detection: Next, ASTRID
real-time feedback on sterile technique compliance, simulates uses the sensed landmarks of the student’s pose and the sterile
error-prone scenarios, and generates a summary report for drapetodeterminecompliancewiththefourprinciplesofsterile
performance review. technique. This compliance detection is achieved through a
geometricrule-basedmodule.Therule-basedmodulepartitions
B. Detecting Student Compliance with the Sterile Technique
the 3D space into sterile and non-sterile regions, it calculates
IllustratedinFig.5,ASTRIDconsidersfourkeyprinciplesof
steriletechniqueoncethesterilefieldisestablished.Asnursing 1Wealsoexploredmethodsthatdonotrequiremanualcalibration.However,
we found that they were reliable only when the drape was flat and free
students practice the CLDC procedure, ASTRID monitors them
ofitems.Futureworkcouldexploreimprovingautomateddetectionofthe
and detects compliance with these principles as detailed next. steriledrapeviainteractivemachinelearning.
two key planes based on the sterile drape: the bottom plane,
fittedalongthedrape,andthefrontplane,definedperpendicular
to the bottom plane at the front-most edge (relative to the
student). Finally, it applies the following geometry-based rules
to check for four non-compliant behaviors:
• hands below waistline: if wrist-landmarks are below the
sterile drape (i.e., the bottom plane).
• reaching across the sterile field: if any human landmark
is ahead of the the sterile drape (i.e., the front plane).
• turning back to the sterile field: if the vector from the
left to right shoulder faces away from the sterile drape.
• touching the one-inch border: if the fingertip-landmarks
are within one-inch of the boundary of the sterile drape.
C. Providing Feedback to Students
Along with detecting sterile technique compliance, ASTRID
offers feedback both during and after the training session.
1) Task-Time Feedback: Guided by the focused interviews,
ASTRID uses both visual and audio channels to provide task-
time feedback. As shown in Fig. 2-middle, during the training
session,thenursingstudentcan seetheirposeon thecomputer
screen with real-time skeletal tracking. Fig. 2-left provides a
snapshot of this screen. If ASTRID detects a non-compliant
behavior, it alerts the nurse both visually with red text on Fig. 8. ASTRID leverages mobile manipulation to create simulations of
real-lifescenarios.
the screen and aurally via pre-recorded audio. The visual
and audio alerts have the same message, “Warning: <specific
The robot’s paths are pre-designed giving considerations of
non-compliant behavior> (e.g., hands below waistline).”
nurse’s safety and proxemics. During the feasibility study, the
2) Post-Practice Feedback: At the end of the training
robot moves autonomously. The motion is programmed using
session, ASTRID provides the nursing student with tools to
stretch_body, a python API for Stretch.
quickly review their practice using its screen (Fig. 2-right).
First, each session is recorded with skeletal tracking, date, 3) Advanced: Intheadvancedlevel,ASTRIDusesitsmobile
time, and warnings, allowing the nurse to see what they did manipulation capability to simulate critical scenarios that
right or wrong. Second, if the nurse prefers not to review require the nurse to apply their experience and judgment
the entire recording, ASTRID saves key frames when non- to determine the appropriate course of action. Currently, our
compliant behaviors are detected. Lastly, ASTRID generates prototype offers two such scenarios which were co-designed
a PDF report summarizing how many times each rule was with nursing experts:
broken, along with the screenshots of non-compliant behavior • (Scenario #1) ASTRID alerts the nurse, “Your patient’s
and associated warnings. blood sugar is dropping below 54 mg/dL (milligrams
per deciliter). I am bringing glucose.” and brings a 50%
D. Simulating Challenging Nursing Scenarios
dextrose(glucose)injectionnearthebedsidetables(Fig.8-
Guided by the findings of focused interviews, we design top). Once the robot has reached the table, it alerts the
ASTRID toofferthree levelsoftraining– novice,intermediate, nurse, “please take the glucose and give it to the patient.”
and advanced – which increase in complexity, simulating three times. If and when the nurse takes the dextrose
challenging real-world scenarios that nurses may encounter injection, they reach across the sterile field, breaking the
during dressing change procedures. A video demo of these sterile field. This represents a life-critical scenario where
scenarios is available at  the patient’s blood sugar is dangerously low and could
1) Novice: At this level, nurses practice the central line continue dropping, requiring the nurse to act quickly.
dressing change without distractions or interruptions, with all • (Scenario #2) ASTRID approaches the table and knocks
feedback features enabled. It is ideal for nursing students and over the patient’s water bottle off the table, and alerts,
nurses unfamiliar with the procedure. “Oops, the patient water bottle fell on the floor, please
2) Intermediate: This level additionally introduces distrac- pick up the water bottle and put it back.” This scenario
tions, simulating real-world scenarios where nurses may be represents a non-emergency but common interruptions,
interruptedbypatients,familymembers,orothermedicalstaff. e.g., where a patient drops something and asks the nurse
Distractions are created by the robot, which moves around the to pick it up (Fig. 8-bottom). In such cases, experienced
environment, says pre-scripted greetings, and provides positive nurses would typically inform the patient that they will
feedback “You are doing great! Keep going!" to the nurse. retrieve the item after the procedure.
The choice of these physical interventions was informed • Test 2 implemented the advanced level of ASTRID. The
by challenges described by stakeholders during the focused participants continued to receive real-time warnings.
interviews, direct observations on hospital floors, and discus- Additionally, they had to respond to the two interruption
sions with nursing educators. These scenarios were refined to scenarios described in Sec. IV-D3.
ensure they aligned with professional nursing practices, met • Test 3 implemented the novice level of ASTRID and
ourdesigngoals,andweretechnicallyfeasibletoimplementon involvedtheproctorinstructingparticipantstodeliberately
a robot, resulting in the specific interventions described above. perform non-compliant behaviors (e.g., dropping hands
In both scenarios, the nurse must carefully reason through below the waistline). This test was included to evaluate
their actions. Following the robot’s suggestion may lead to ASTRID’s detection capability, in case non-compliant
a violation of sterile technique, but in some cases (e.g., the behaviors were not observed in earlier tests.
first scenario) it may be necessary to prioritize patient health. After each test, the participants reviewed the summary report
Similar to the implementation in the Intermediate level, all generated by ASTRID. The summary consists of the video
robot’s verbal and physical interactions are pre-programmed recordingofthetest,snapshotsofeachdetectednon-compliant
using the software package stretch_body, enabling the robot behavior, and a PDF report with a summary of how many
to behave autonomously during training sessions. times the participant broke each of the four rules along with
the images of the mistakes.
V. FEASIBILITYSTUDY
3) Post-ExperimentReview: Aftertheparticipantcompleted
We conducted a feasibility study to evaluate ASTRID.2 This all four tests, they were asked to complete a post-experiment
IRB-approved study involved nine participants – seven recent survey administered on an on-site computer. Upon completing
graduatesornurseswithtwoyearsorlessofexperienceandtwo the survey, the experiment proctor conducted a brief interview
experienced nurses from the requirement capture interviews. to better understand the participant’s experience and solicit
The experiment was held in the training environment shown suggestions for ASTRID’s future iterations and usage.
in Fig. 2, an artificial rendering of which is depicted in Fig. 1.
C. Measures
A. Materials
The feasibility study assessed whether ASTRID met the
The experiment site was set up to mimic CLDC scenarios, designrequirements(R1–R6)usingacombinationofobjective
with the same level of fidelity typically used in nursing
and subjective measures. The post-experiment review also
education. The setup included a simulated patient, ASTRID, a
gatheredparticipatorydesignfeedbackforfuturerobotictutors.
table for performing the dressing change, medical supplies,
1) Measures for R1: To evaluate ASTRID’s ability to detect
and a GoPro camera. The depth camera and monitor were
student compliance with sterile technique, we compared its
placed on a table in front of the nurse. The GoPro was used
performance to thatofa nurse educator. A nurse educatorwith
to record the experiments and was not part of ASTRID. One
20+ years of experience reviewed and annotated the video
of the authors served as the experiment proctor.
recordings of the training sessions to establish the ground
truth for non-compliant behaviors. Annotations were made
B. Procedure
usingtheBehavioralObservationResearchInteractiveSoftware
The experiment consisted of three parts: an introduction,
(BORIS) , with the experiment proctor assisting in data
dressing change procedures, and a post-experiment review.
entry. For analysis, we sampled the training sessions at 1Hz,
1) Introduction: Thesessionbeganwithagreeting,followed
treatingeachsecondasaninstanceforevaluation.Eachinstance
byanexplanationofthestudy’spurpose,procedure,participant
was categorized as true positive (TP), false positive (FP), true
rights, and potential risks and benefits. Participants provided
negative (TN), or false negative (FN), based on ASTRID’s
informedconsentandcompletedademographicsurveyon-site.
detection compared to the expert annotations. For example,
2) Central Line Dressing Change Procedures: Participants
an instance was marked as FP if ASTRID detected a violation
were asked to perform CLDC on the simulated patient four
but the expert did not. Fig. 9 provides additional examples.
times (referred to as tests), each with a different setup and
2) Measures for R2–R4: To evaluate R2–R4, the post-
purpose.
experiment survey included seven statements evaluating the
• Test0(Pre-test)involvedparticipantsperformingaCLDC usefulness of ASTRID’s seven features (Fig. 10). Participants
without warnings or interventions from ASTRID. This
rated each feature on a 5-point discrete visual analog scale
allowed them to familiarize themselves with the setup
(DVAS), from not useful at all (1) to extremely useful (5).
and enabled necessary calibration.
3) Measures for R5–R6: The post-experiment survey
• Test 1 implemented the intermediate level of ASTRID.
included two established surveys, adapted for the experimental
Participants received real-time audio-visual warnings, in
context, to assess the ASTRID’s perceived usefulness 
cases when ASTRID detected non-compliant behaviors.
and user engagement . The list of survey questions is
Additionally, to simulate real-life distractions, the robot
provided in the appendix. The perceived usefulness survey
moved around the room and said pre-scripted statements.
included statements such as “Practicing with [technology]
wouldenhance my overalljobperformance.” Participants rated
2Wereferthereadertothesupplementarymaterialforvideosnippetsand
resourcestosupportthereproducibilityofthisstudy. these statements on a 5-point discrete visual analog scale,
Fig.9. ExamplesofASTRID’scompliancedetectionfromthefeasibilitystudy:(TruePositive)ASTRIDcorrectlydetectsthenurseturningtheirbacktothe
sterilefield;(FalsePositive)ASTRIDmistakenlyidentifiesthehandsasbelowthewaistlineduetoocclusion;(FalseNegative)ASTRIDmissesthelefthand
belowthewaistlineasitishiddenbehindtheback;and(Outlier)thetable’shigherheightmakesitchallengingtodetectthesterilefieldandcompliance.
TABLEI
PERFORMANCE:STERILETECHNIQUECOMPLIANCEDETECTION
Finding2:ParticipantsperceiveASTRIDashighlyusefulfor
nursing education. Through the perceived usefulness survey,
detailed in the appendix, participants reported a mean score
Metrics Results Calculation of M = 4.70 (out of a maximum of 5) and SD = 0.41 on
Accuracy 98.6% (TP+TN)/(TP+TN+FP+FN) the system’s perceived usefulness. This result highlights the
Precision 95.5% TP/(TP+FP)
potential of ASTRID as a helpful tutoring system to improve
Recall 83.5% TP/(TP+FN)
F1Score 0.89 2×Recall×Precision/(Recall+Precision) nurses’ skills and job performance in the future. Fig. 10
provides a granular view of ASTRID’s perceived usefulness,
highlighting participants’ feedback on its individual features.
While some features were rated more useful than others, both
ranging from extremely unlikely (1) to extremely likely (5). real-time and post-practice feedback were consistently rated
The user engagement survey included statements such as “My as extremely useful.
experience was rewarding.” This scale also utilized a 5-point Finding 3: Participants perceive ASTRID as engaging
discrete visual analog scale: strongly disagree (1) to strongly and supportive. Through the user engagement survey, also
agree (5). detailed in the appendix, participants reported a mean score
M = 4.84 (out of 5) and SD = 0.30, indicating that the
D. Findings
participants found ASTRID engaging and supportive. In the
Nine nurses participated in the feasibility study. Data from post-experiment interview, we asked participants whether
one participant (P2) was excluded as an outlier due to issues practicing with ASTRID would improve nursing students’
with the table height. Although we had opted for a height- confidence in complying with the sterile technique. All
adjustabletabletoaccommodateparticipantsofdifferentheight, participants unanimously answered “yes.” One participant,
the highest-level of the table was still below the participant’s who recently graduated from nursing school said
waistline. Of the remaining eight participants, each performed I always feel very anxious because I am new to the
four tests, yielding 32 total tests. Two tests were not recorded job. But practicing with the robot has already made
properly due to data storage limitations. Additionally, two me feel better about my skills because now I know I
tests (pre-test and Test #1 of P6) were excluded because we did not make any mistakes... I also like the real-life
noticed when the table was at its highest level, it was at the scenarios. We did not see those in nursing school.
same level of the camera, making perception difficult. Though In addition to helping nursing students improve and gain
this was resolved when they performed Test #2 and Test #3. confidenceintheirskills,participantsnotedthat ASTRID could
In total, we collected data from 28 effective tests, amounting offer other benefits, such as being more readily available
to 5,719 seconds (95.3 minutes) of video recordings. than experienced nurses, providing objective assessments and
Finding 1: ASTRID demonstrates the potential to accurately feedback, and allowing nurses to practice their skills without
detect student’s compliance with the sterile technique. Among fear of judgment. These results and comments are especially
the5719instancesofdata,343arefoundtobeTP,16FP,5376 encouraging, as they align with the requirements identified
TN, and 68 FN. This corresponds to an accuracy of 98.6% through initial interviews and validate our participatory design
andanF1scoreof0.89. AnF1scoreabove0.9isconsidered efforts to create a nurse-friendly robotic tutor.
excellent, and an F1 score between 0.8 and 0.9 is considered
E. Limitations
good.TableIsummarizeskeymetrics,demonstratingASTRID’s
high accuracy in detecting both positives and negatives. While While our work involved a rigorous co-design process,
true positives are crucial for robotic tutoring, we wish to iterative development, and human-subject evaluations, it also
highlight that true negatives are equally important. They has limitations. Here, we acknowledge these to contextualize
validate ASTRID’s perception modules and (as indicated in ourcontributions,highlightthe challenges ofsystems research,
the open-ended feedback) nursing students felt encouraged and guide future work. First, while we engaged stakeholders
when they knew they did not make any mistakes. Together from the outset, our evaluations were limited to nine nurses.
these results indicate that ASTRID satisfies requirement R1. This sample size aligns with user-centered design research,
Snapshots 8 2) Directions for Future Work: While ASTRID shows
Summary 7 promise, we emphasize that it is a proof-of-concept system.
Real-time Audio Warning 7 We list suggest future directions for nursing research:
Real-life Scenarios 6 • ASTRID addresses fourprinciples ofthe sterile technique;
Video Recording 6 however, this technique is more comprehensive [84, 25,
Real-time Visual Warning 5 96]. The system also focuses on a specific part of the
Skeleton Visualization 4 dressing change procedure – after the nurse has already
Count openedthedressingchangekitandsetupthesterilefield.
Early steps like opening the sterile packet and putting on
gloves are not covered and should be addressed in future
Fig.10. PerceivedusefulnessofASTRID’sindividualfeatures:thenumber work. Participants also suggested expanding the tutor to
ofparticipants(outof8)thatratedafeaturetobeextremelyuseful.While
other tasks like Foley catheter insertion , and high-
allfeaturesareperceivedasuseful,snapshotsofcontaminationoccurrences
receivethehighestrankingandskeletonvisualizationthelowest. sterility environments like operating rooms (OR) [118,
112, 106, 128].
• WhileASTRIDreliablydetectssteriletechniqueviolations,
whichsuggeststhat8–10participantscanuncoverupto80%of it is not immune to errors. A risk is students becoming
usability issues ,including in healthcare technologies . overconfident due to false negatives. While technological
However, the small cohort can limit generalizability and our improvementscan enhancedetection accuracy,webelieve
resultsshouldbeconsideredproof-of-concept. Akeychallenge integrating input from nursing instructors is crucial to
wasrecruitingnovicenurses,whosedemandingschedulesmade address this challenge. Participants also emphasized the
research participation difficult. Second, our user evaluations importance of human instruction, especially for those
relied on established scales for perceived usefulness and user who began their education during COVID-19. Thus,
engagement, but we adapted them to the specific context of ASTRID should complement broader nursing education
nursing education. These modifications were not separately frameworks rather than function as a standalone tool.
validated. Lastly, while the robot operated autonomously, It is important to highlight that ASTRID is designed
its functionality was constrained to the controlled training to augment traditional nursing training and intended for
environment. For instance, the system was tested against a use alongside instructors. Future work should evaluate
specific background. In real-world settings,the robot will need ASTRID throughformalA/Bcomparisonagainstacontrol
to adapt to a wider range of environments and users, requiring condition where nurses practiced without robotic support.
enhanced autonomy. As discussed in the next section, this Additionally, our current work focused on student-robot
underscores the need for foundational robotics research driven interactions,withinstructorinputlimitedtoitsdesign and
by real-world applications in nursing. evaluation. Future work should explore the instructor-
student-robot triad to understand how robots can best
VI. CONCLUSION
support existing teaching methods.
We conclude by discussing the implications of our findings
B. Implications for Robotics
for both nursing education and foundational robotics research.
1) Key Contributions: Within robotics, our work makes
A. Implications for Nursing Education
three key contributions:
1) Key Contributions: Our work introduces a novel tech- • Introducing nursing education as a new robotics domain:
nological aid for nursing education: robotic tutors. Through We identify nursing education as a field in need of
participatory design, we developed ASTRID, a robotic tutor transformative solutions and demonstrate the potential of
for CLABSI-prevention training. ASTRID monitors student robotics in this space through the design, development,
compliance with the sterile technique, providing real-time and evaluation of ASTRID. Our work serves as an initial
feedbackandtoolsforperformancereviewandimprovement.It testbed for evaluating robotics technologies in nursing
alsooffersmultipletraininglevelsandcansimulatechallenging education and reveals new research directions in task
scenarios which may be overlooked in nursing schools. In and motion planning, perception-aware motion planning,
a feasibility study with 9 nurses, ASTRID reliably detected conversational robots, and robotic tutors.
compliance with four key sterile technique principles and was • Advancing robotic tutoring with a focus on physical
perceived as useful and engaging. These results suggest that skills: Unlike most robotic tutors, which focus on cog-
ASTRID can help provide new nurses with opportunities to nitive learning through conversational interactions (e.g.,
practice theirskills andreceive immediate feedback,especially math tutoring), ASTRID is designed for physical skill
as current nursing shortages challenge the sustainability of acquisition. This shift necessitates perception-driven
the traditional nurse-to-nurse training model [47, 101, 63]. performance evaluation and physical interventions via
Further, our approach reaffirms the importance of involving mobilemanipulation. Weseethisasasmallbutimportant
nurses early on during the design and development of new step toward expanding robotic tutoring beyond screen-
technology. based or purely conversational approaches.
• Reaffirming the value of participatory design in robotics: inherenttrustthemmorethanroboticassistantsorpeers[19,
Ourworkreinforcestheimportanceofparticipatorydesign 24, 114, 36, 86, 111]. One way to address this is by
in developing robotics systems. By actively involving explainingtherobot’scapabilitiesandlimitationstostudents
stakeholders throughout the process, we ensure that the and involving instructors in the process [57, 12, 76, 13,
technology is aligned with real-world needs, further 14, 31, 77, 55, 61, 117, 123, 131, 99, 27, 108, 109, 92,
supporting user-centered approaches in robotics research. 100]. Indeed, our participatory design findings suggest that
2) Directions for Future Work: Our systems-driven inves- allowing educators to customize robotic tutors through
tigation also reveals directions for foundational research in end-user programming will be essential fortheirreal-world
robotics, which have implications beyond nursing: effectiveness [33, 7, 139, 88, 68].
• Rule-Based Detection and Alternatives: The rule-based We conclude by emphasizing the need for cross-disciplinary
perception pipeline of ASTRID offers simplicity and relia- collaboration in use-inspired robotics systems research. Our
bility (advantages that are valuable in early-stage research) research reaffirms that developing robotics systems requires
but limits generalizability. Future work should focus on inputs from domain experts, use of participatory design
enhancing detection using more robust pose estimation, methods, and expertise from robot developers. This integrated
object detection, and action recognition techniques. In approach is key to developing safe and responsible human-
ongoing work, we are evaluating alternatives to MediaPipe centered robotics.
for improved pose estimation, and plan to integrate object
detection models (e.g., YOLO , SSD ) and action
VII. ETHICALIMPACTSTATEMENT
recognition models (e.g., I3D  and SlowFast ) to This work presents ASTRID, a robotic tutor designed to
enhance generalizability. support nursing education and reduce preventable infections
• Perception-aware Robot Planning: During evaluations, through improved training. Developed through a participatory
ASTRID struggled with taller participants, partly due to the design process with nursing professionals, ASTRID aims to
useofastaticoff-boardcamera.Raisingthecamerareduces complement human instruction. While it offers real-time and
visibility of the lower body, while lowering it obstructs post-practice feedback, we caution against overreliance due to
key areas like the far side of the sterile field. Future work potential perception errors. All user studies were conducted
should consider development of more robust perception underIRBapproval,withinformedconsentandattentiontodata
systems for detecting nursing activities, by leveraging privacy. Broader deployment should ensure equitable access,
advances in vision [34, 52, 119, 60, 127, 89] and mobile human instructor’s oversight,andmechanisms to calibrate user
perception [45, 64, 137, 126]. Although there is a vast trust in the robotic tutor.
literatureonperception-awaremotiongenerationandactive
perception, we have identified additional constraints that
VIII. SUMMARYOFSUPPLEMENTARYMATERIAL
prevent the seamless application of existing methods, such Please see the Appendix for further details on:
as the generation of robot motion for object manipulation • Methodology for recruiting participants;
that maximizes the nurse monitoring, especially for high • Questions used during the focused interviews;
degree-of-freedom robots. These constraints also extend to • Statements used during the feasibility study to measure
task planning and motivate the need for novel methods for ASTRID’s perceived usefulness; and
perception-aware task and motion planning. • Statements used during the feasibility study to measure
• Multimodal Human-(Robotic Tutor) Interaction: Several user engagement during the experiment.
nurses attempted to converse with ASTRID when it greeted Additionally, a video demonstration of ASTRID is available
them or issued verbal warnings, but ASTRID relies on at 
pre-scripted language and lacks the ability for free-form,
turn-taking conversations. Adding such features could
ACKNOWLEDGMENTS
enhance the tutoring. However, if generative or large This research was supported by the National Science
language models are used, their limitations must be care- FoundationthroughAward2326390andRiceUniversityfunds.
fully considered [17, 97, 138, 22, 71, 129]. Combining We acknowledge the inputs of nursing students, nurses, and
multiple intervention types also offers exciting potential; nursing instructors, who were critical to this participatory
our work takes a step in this direction by incorporating design effort. Lastly, we thank the anonymous reviewers for
physical interventions, though limited to pre-defined tasks. their thoughtful feedback and constructive suggestions.
Tighter integration of perception, mobile manipulation,
and conversation could significantly enhance future robotic
REFERENCES
tutors across domains.  Alham Abuatiq, Robin Brown, Christina Plemmons,
• Calibrating Trust in Robotic Tutors: As robotic tutors Beth Walstrom,Cassy Hultman, Danielle Currier, Marie
become more capable, trust calibration is a critical concern Schmit, Valborg Kvigne, Leann Horsley, and Heidi
to preventstudents from over-relying on these systems [40, Mennenga. Nursing faculty and students’ satisfaction
134, 135, 80, 73, 53]. This is especially important for with telepresence robots during the covid-19 pandemic.
robotic tutors, as their teaching role may lead students to Nurse Educator, 47(2):E39–E42, 2022.
 Moh’d Abuazizeh, Thomas Kirste, and Kristina Yor- marizing agent strategies. Autonomous Agents and
danova. Computational state space model for intelligent Multi-Agent Systems, 33:628–644, 2019.
tutoring of students in nursing subjects. In Proceedings  Sule Anjomshoae, Amro Najjar, Davide Calvaresi, and
ofthe13thACMInternationalConferenceonPErvasive Kary Främling. Explainable agents and robots: Results
Technologies Related to Assistive Environments, pages fromasystematicliteraturereview. In18thInternational
1–7, 2020. Conference on Autonomous Agents and Multiagent
 Moh’d Abuazizeh, Kristina Yordanova, and Thomas Systems (AAMAS 2019),Montreal,Canada,May13–17,
Kirste. Affect-aware conversational agent for intelligent 2019, pages 1078–1088. International Foundation for
tutoring of students in nursing subjects. In Alexandra I. Autonomous Agents and Multiagent Systems, 2019.
Cristea and Christos Troussas, editors, Intelligent Tu-  Wilma A Bainbridge, Justin W Hart, Elizabeth S Kim,
toring Systems, pages 497–502, Cham, 2021. Springer and Brian Scassellati. The benefits of interactions with
International Publishing. ISBN 978-3-030-80421-3. physically present robots over video-displayed agents.
 Shamsudeen Abubakar, Sumit K Das, Chris Robinson, InternationalJournalofSocialRobotics,3:41–52,2011.
Mohammed N Saadatzi, M Cynthia Logsdon, Heather  Tony Belpaeme, Paul Vogt, Rianne Van den Berghe,
Mitchell, Diane Chlebowy, and Dan O Popa. Arna, a Kirsten Bergmann, Tilbe Göksun, Mirjam De Haas,
service robot for nursing assistance: System overview Junko Kanero, James Kennedy, Aylin C Küntay, Ora
and user acceptability. In 2020 IEEE 16th International Oudgenoeg-Paz, et al. Guidelines for designing social
Conference on Automation Science and Engineering robots as second language tutors. International Journal
(CASE), pages 1408–1414. IEEE, 2020. of Social Robotics, 10:325–341, 2018.
 E Ackerman. Diligent robotics bringing autonomous  Emily M Bender, Timnit Gebru, Angelina McMillan-
mobilemanipulationtohospitals. IEEESpectrum,2018. Major, and Shmargaret Shmitchell. On the dangers of
 E Ackerman. Akara robotics turns turtlebot into stochastic parrots: Can language models be too big? In
autonomous uv disinfecting robot. IEEE Spectrum, Proceedings of the 2021 ACM conference on fairness,
2020. accountability, and transparency, pages 610–623, 2021.
 Gopika Ajaykumar, Maureen Steele, and Chien-Ming  Alexa Bianchi, Stephen W Leslie, and Gregory T
Huang. Asurveyonend-userrobotprogramming. ACM Chesnut. Difficult foley catheterization. StatPearls
Computing Surveys (CSUR), 54(8):1–36, 2021. [Internet], 2023.
 Naseem Saeed Ali and Bindu John. Examining the effi-  ChrisBirmingham,ZijianHu,KartikMahajan,EliReber,
cacy of online self-paced interactive video-recordings in and Maja J Mataric´. Can i trust you? a user study of
nursing skill competency learning: seeking preliminary robot mediation of a support group. In 2020 IEEE
evidence through an action research. Medical Science International Conference on Robotics and Automation
Educator, 29:463–473, 2019. (ICRA), pages 8019–8026. IEEE, 2020.
 Patrícia Alves-Oliveira, Srinivasan Janarthanam, Ana  Richard Bloss. Mobile hospital robots cure numerous
Candeias,AmolDeshmukh,TiagoRibeiro,HelenHastie, logistic needs. Industrial Robot: An International
Ana Paiva, and Ruth Aylett. Towards dialogue di- Journal, 2011.
mensions for a robotic tutor in collaborative learning  Susanne Bødker, Christian Dindler, Ole S. Iversen, and
scenarios. In The 23rd IEEE International Symposium Rachel C. Smith. What Is Participatory Design?, pages
on RobotandHuman Interactive Communication,pages 5–13. Springer International Publishing, 2022.
862–867. IEEE, 2014.  Anya Bouzida, Alyssa Kubota, Dagoberto Cruz-
 Patrícia Alves-Oliveira, Tiago Ribeiro, Sofia Petisca, Sandoval, Elizabeth W Twamley, and Laurel D Riek.
EugenioDiTullio,FranciscoSMelo,andAnaPaiva. An Carmen: A cognitively assistive robot for personalized
empathic robotic tutor for school classrooms: Consider- neurorehabilitation at home. In Proceedings of the 2024
ingexpectationandsatisfactionofchildrenasend-users. ACM/IEEE International Conference on Human-Robot
In Social Robotics: 7th International Conference, ICSR Interaction, pages 55–64, 2024.
2015, Paris, France, October 26-30, 2015, Proceedings  G. Bradski. The OpenCV Library. Dr. Dobb’s Journal
7, pages 21–30. Springer, 2015. of Software Tools, 2000.
 Patrícia Alves-Oliveira, Pedro Sequeira, and Ana Paiva.  Kimberly A Brink and Henry M Wellman. Robot
The role that an educational robot plays. In 2016 25th teachers for children? young children trust robots
IEEE International symposium on robot and human depending on their perceived accuracy and agency.
interactive communication (RO-MAN), pages 817–822. Developmental Psychology, 56(7):1268, 2020.
IEEE, 2016.  Niccolò Buetti, Jonas Marschall, Marci Drees, Mo-
 Dan Amir and Ofra Amir. Highlights: Summarizing hamadG.Fakih,LynnHadaway,LisaL.Maragakis,Eliz-
agent behavior to people. In Proceedings of the 17th abeth Monsees, Shannon Novosad, Naomi P O’Grady,
international conference on autonomous agents and Mark E. Rupp, Joshua Wolf, Deborah Yokoe, and
multiagent systems, pages 1168–1176, 2018. Leonard A. Mermel. Strategies to prevent central
 Ofra Amir, Finale Doshi-Velez, and David Sarne. Sum- line-associated bloodstream infections in acute-care
hospitals: 2022 update. Infection control and hospital controlled trial study. Nurse education today, 66:63–68,
epidemiology, 2022. 2018.
 Tyler Bysshe, Yue Gao, Krysta Heaney-Huls, Jason  Cristina Conati, Oswald Barral, Vanessa Putnam, and
Hockenberry, Lauren Hovey, Alison M. Laffan, Suhna Lea Rieger. Toward personalized xai: A case study in
Lee, David J. Murphy, and Elizabeth Watts. Estimating intelligent tutoring systems. Artificial intelligence, 298:
the additional hospital inpatient cost and mortality 103503, 2021.
associated with selected hospital-acquired conditions.  Angelo Dante, Alessia Marcotullio, Vittorio Masotta,
Technical report, Agency for Healthcare Research and Valeria Caponnetto, Carmen La Cerra, Luca Bertocchi,
Quality, 2017. Cristina Petrucci, and Celeste M Alfes. From high-
 DavideCalvaresi,AmroNajjar,AndreaOmicini,Reyhan fidelitypatientsimulatorstoroboticsandartificialintelli-
Aydogan,RacheleCarli,GiovanniCiatto,YazanMualla, gence:Adiscussionpaperonnewchallengestoenhance
and Kary Främling. Explainable and transparent learning in nursing education. In Methodologies and
ai and multi-agent systems. LECTURE NOTES IN Intelligent Systems for Technology Enhanced Learning,
COMPUTER SCIENCE, 14127:1–281, 2023. 10th International Conference. Workshops: Volume 2,
 ErranCarmel,RandallD. Whitaker,andJoeyF. George. pages 111–118. Springer, 2021.
Pd and joint application design: a transatlantic com-  Angelo Dante, Carmen La Cerra, Vittorio Masotta,
parison. Commun. ACM, 36:40–48, 1993. URL ValeriaCaponnetto,LucaBertocchi,AlessiaMarcotullio,
 FabioFerraiuolo,CelesteMAlfes,andCristinaPetrucci.
 João Carreira andAndrewZisserman. Quo vadis,action The use of robotics to enhance learning in nursing
recognition? a new model and the kinetics dataset. In education: a scoping review. In Methodologies and
2017 IEEE Conference on Computer Vision and Pattern Intelligent Systems for Technology Enhanced Learning,
Recognition (CVPR), pages 4724–4733, 2017. doi: 11th International Conference 11, pages 217–226.
10.1109/CVPR.2017.502. Springer, 2022.
 Ginevra Castellano, Ana Paiva, Arvid Kappas, Ruth  FredDavis. Perceivedusefulness,perceivedease ofuse,
Aylett, Helen Hastie, Wolmet Barendregt, Fernando and user acceptance of information technology. MIS
Nabais, and Susan Bull. Towards empathic virtual and Quarterly, 13:319–, 09 1989. doi: 10.2307/249008.
robotic tutors. In Artificial Intelligence in Education:  Munjal Desai, Poornima Kaniarasu, Mikhail Medvedev,
16th International Conference, AIED 2013, Memphis, Aaron Steinfeld, and Holly Yanco. Impact of robot
TN, USA, July 9-13, 2013. Proceedings 16, pages 733– failures and feedback on real-time trust. In 2013 8th
736. Springer, 2013. ACM/IEEE International Conference on Human-Robot
 Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreed- Interaction (HRI), pages 251–258. IEEE, 2013.
haran, David E Smith, and Subbarao Kambhampati.  Barkha Devi, Bidita Khandelwal, and Mridula Das.
Explicability? legibility? predictability? transparency? Comparison of the effectiveness of video-assisted
privacy? security? the emerging landscape of inter- teaching program and traditional demonstration on
pretable agent behavior. In Proceedings of the interna- nursingstudentslearningskillsofperformingobstetrical
tionalconferenceonautomatedplanningandscheduling, palpation. Iranian journal of nursing and midwifery
volume 29, pages 86–96, 2019. research, 24(2):118, 2019.
 Jie Chen, Jian Yang, Fen Hu, Si-Hong Yu, Bing-Xiang  Jonathan Dhaussy, Lucie Kemken, Marie-Thérèse
Yang, Qian Liu, and Xiao-Ping Zhu. Standardised Pugliese, Aline Forestier, and Sylvain Boloré. Using
simulation-based emergency and intensive care nursing simulation to adapt nursing education to times of crisis:
curriculum to improve nursing students’ performance A scoping review during covid-19 pandemic. Teaching
during simulated resuscitation: a quasi-experimental and Learning in Nursing, 2024.
study. Intensive and Critical Care Nursing, 46:51–56,  Georgia Ann Dinndorf-Hogenson, Carrie Hoover,
2018. Jodi Lisbeth Berndt, Bethany Tollefson, Jennifer Pe-
 Sonia Chernova and Andrea L Thomaz. Robot learning terson, and Nichole Laudenbach. Applying the flipped
from human teachers. Synthesis lectures on artificial classroom model to psychomotor skill acquisition in
intelligence and machine learning, 8(3):1–121, 2014. nursing. Nursing education perspectives, 40(2):99–101,
 Wongun Choi, Caroline Pantofaru, and Silvio Savarese. 2019.
Detecting and tracking people using an rgb-d camera  MelissaDonnermann,PhilippSchaper,andBirgitLugrin.
via multiple detector fusion. In 2011 IEEE interna- Social robots in applied settings: A long-term study on
tional conference on computer vision workshops (ICCV adaptive robotic tutors in higher education. Frontiers in
workshops), pages 1076–1083. IEEE, 2011. Robotics and AI, 9:831633, 2022.
 Yeu-Hui Chuang, Fu-Chih Lai, Chia-Chi Chang, and  Davide Falanga, Philipp Foehn, Peng Lu, and Davide
Hsu-Tien Wan. Effects of a skill demonstration video Scaramuzza. Pampc: Perception-aware model predictive
deliveredbysmartphoneonfacilitatingnursingstudents’ control for quadrotors. In 2018 IEEE/RSJ International
skill competencies and self-confidence: A randomized Conference on Intelligent Robots and Systems (IROS),
pages 1–8. IEEE, 2018. Software Agent Technology in the Health Care Domain,
 Haoqi Fan, Yanghao Li, Bo Xiong, Wan-Yen Lo, and pages 143–159, 2003.
ChristophFeichtenhofer. Pyslowfast.   Ming Hu, Lin Wang, Siyuan Yan, Don Ma, Qingli Ren,
facebookresearch/slowfast, 2020. Peng Xia,Wei Feng,Peibo Duan,Lie Ju,andZongyuan
 Julie Fitzwater, Jeanette McNeill, Diane Monsivais, Ge. Nurvid: A large expert-level video database for
and Franchesca Nunez. Using simulation to facilitate nursing procedure activity understanding. Advances in
transition to the nurse educator role: An integrative Neural Information Processing Systems, 36, 2024.
review. Nurse educator, 2021.  Sandy H. Huang, David Held, Pieter Abbeel, and
 Joseph D Forrester, Paul M Maggio, and Lakshika Anca D. Dragan. Enabling robots to communicate
Tennakoon. Cost of health care-associated infections in their objectives. Autonomous Robots, 43(2), February
the united states. Journal of patient safety, 2022. 2019.
 Olivier Pierre Friard, Marco Gamba, et al. Behavioral  Ronda G Hughes(ed.). Patient Safety and Quality:
observation research interactive software (boris). 2016. An Evidence-Based Handbook for Nurses. Agency for
 Matthew Gombolay, Xi Jessie Yang, Bradley Hayes, Healthcare Research and Quality (AHRQ), 2008.
Nicole Seo,Zixi Liu,SamirWadhwania,Tania Yu,Neel  KathleenMHuunandJamesESlaven. Robotictelepres-
Shah, Toni Golen, and Julie Shah. Robotic assistance enceandface-to-facecollaborativenursingsimulation:A
in the coordination of patient care. The International correlational, cross-sectional study. Clinical Simulation
Journal of Robotics Research, 37(10):1300–1316, 2018. in Nursing, 90:101525, 2024.
 Lisa A Gorski, Lynn Hadaway, Mary E Hagle, Daphne  Brian Ichter, Benoit Landry, Edward Schmerling, and
Broadhurst,SimonClare,TriciaKleidon,BrittMMeyer, Marco Pavone. Perception-aware motion planning via
Barb Nickel, Stephen Rowley, Elizabeth Sharpe, and multiobjective search on gpus. In Robotics Research:
Mary Alexander. Infusion therapy standards of practice, The18thInternationalSymposiumISRR,pages895–912.
8th edition. Journal of infusion nursing: the official Springer, 2020.
publication of the Infusion Nurses Society, 2021.  Intel. Intel realsense technology, 2024.
 Chunhui Gu, Chen Sun, David A Ross, Carl Vondrick, URL 
Caroline Pantofaru, Yeqing Li, Sudheendra Vijaya- architecture-and-technology/realsense-overview.html.
narasimhan, George Toderici, Susanna Ricco, Rahul  Minako Ito, Haruhiko Mitsunaga, and Toshiko Ibe.
Sukthankar, et al. Ava: A video dataset of spatio- Survey of onboarding programs of hospitals for newly
temporally localized atomic visual actions. In Proceed- hired experienced nurses. Journal of St. Luke’s Society
ings of the IEEE conference on computer vision and for Nursing Research (SLNR), 24, 2021.
pattern recognition, pages 6047–6056, 2018.  Mari Kangasniemi, Suyen Karki, Noriyo Colley, and
 YaohuiGuoandXJessieYang. Modelingandpredicting Ari Voutilainen. The use of robots and other automated
trust dynamics in human–robot teaming: A bayesian devices in nurses’ work: An integrative review. In-
inference approach. International Journal of Social ternational journal of nursing practice, 25(4):e12739,
Robotics, 13(8):1899–1909, 2021. 2019.
 Lisa M Haddad, Pavan Annamaraju, and Tammy J  Ulas Berk Karli, Juo-Tung Chen, Victor Nikhil Antony,
Toney-Butler. Nursing shortage. StatPearls [Internet], and Chien-Ming Huang. Alchemist: Llm-aided end-
2020. user development of robot applications. In Proceedings
 Zhao Han, Daniel Giger, Jordan Allspaw, Michael S of the 2024 ACM/IEEE International Conference on
Lee, Henny Admoni, and Holly A Yanco. Building Human-Robot Interaction, pages 361–370, 2024.
the foundation of robot explanation generation using  Charles C Kemp, Aaron Edsinger, Henry M Clever,
behavior trees. ACM Transactions on Human-Robot and Blaine Matulevich. The design of stretch: A
Interaction (THRI), 10(3):1–31, 2021. compact, lightweight mobile manipulator for indoor
 RexHartsonandParthaS.Pyla. TheUXBook. Elsevier, human environments. In 2022 International Conference
2012. on Robotics and Automation (ICRA), pages 3150–3157.
 Bradley Hayes and Julie A Shah. Improving robot IEEE, 2022.
controller transparency through autonomous policy  FinnKensing,JesperSimonsen,andKeldBodker. Must:
explanation. In Proceedings of the 2017 ACM/IEEE A method for participatory design. Human–Computer
international conference on human-robot interaction, Interaction, 13, 1998.
pages 303–312, 2017.  Callie Y Kim, Christine P Lee, and Bilge Mutlu.
 MatthewAHicks,PatrycjaPopowicz,andPeterPLopez. Understanding large-language model (llm)-powered
Central line management. In StatPearls [Internet]. human-robot interaction. In Proceedings of the 2024
StatPearls Publishing, 2023. ACM/IEEE International Conference on Human-Robot
 Marjan Hospers, Erna Kroezen, Anton Nijholt, Rieks Interaction, pages 371–380, 2024.
op den Akker, and Dirk Heylen. An agent-based intelli-  Thomas E Kirschling, Steve S Rough, and Brad C
genttutoringsystemfornurseeducation. Applicationsof Ludwig. Determining the feasibility of robotic courier
medication delivery in a hospital setting. American  Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian
JournalofHealth-SystemPharmacy,66(19):1754–1762, Szegedy,Scott Reed,Cheng-Yang Fu,and Alexander C.
2009. Berg. Ssd: Single shot multibox detector. In Bastian
 Bing Cai Kok and Harold Soh. Trust in robots: Leibe, Jiri Matas, Nicu Sebe, and Max Welling, editors,
Challengesandopportunities. CurrentRoboticsReports, Computer Vision – ECCV 2016, pages 21–37, Cham,
1(4):297–309, 2020. 2016. Springer International Publishing. ISBN 978-3-
 C Koutsojannis, J Prentzas, and I Hatzilygeroudis. A 319-46448-0.
web-based intelligent tutoring system teaching nursing  Yu Lu, Deliang Wang, Penghe Chen, and Zhi Zhang.
students fundamental aspects of biomedical technology. Design and evaluation of trustworthy knowledge tracing
In 2001 Conference Proceedings of the 23rd Annual modelforintelligenttutoringsystem. IEEETransactions
International Conference of the IEEE Engineering in on Learning Technologies, 2024.
Medicine and Biology Society, volume 4, pages 4024–  Camillo Lugaresi, Jiuqiang Tang, Hadon Nash, Chris
4027. IEEE, 2001. McClanahan,Esha Uboweja,Michael Hays,Fan Zhang,
 Andre W Kushniruk and Vimla L Patel. Cognitive Chuo-LingChang,MingGuangYong,JuhyunLee,Wan-
and usability engineering methods for the evaluation Teh Chang, Wei Hua, Manfred Georg, and Matthias
of clinical information systems. Journal of biomedical Grundmann. Mediapipe: A framework for building
informatics, 37(1):56–76, 2004. perception pipelines. ArXiv, 2019.
 Minae Kwon, Sandy H Huang, and Anca D Dragan.  Karthik Mahadevan, Jonathan Chien, Noah Brown,
Expressing robot incapability. In Proceedings of the Zhuo Xu, Carolina Parada, Fei Xia, Andy Zeng, Leila
2018 ACM/IEEE International Conference on Human- Takayama, and Dorsa Sadigh. Generative expressive
Robot Interaction, pages 87–95, 2018. robot behaviors using large language models. In
 Isaac Lage, Daphna Lifschitz, Finale Doshi-Velez, and Proceedings of the 2024 ACM/IEEE International
Ofra Amir. Exploring computational user models for Conference on Human-Robot Interaction, pages 482–
agent policy summarization. In IJCAI: proceedings 491, 2024.
of the conference, volume 28, page 1401. NIH Public  Abrar Majeedi, Ryan M McAdams, Ravneet Kaur,
Access, 2019. Shubham Gupta, Harpreet Singh, and Yin Li. Deep
 Hee Rin Lee, Selma Šabanovic´, Wan-Ling Chang, learning to quantify care manipulation activities in
Shinichi Nagata, Jennifer Piatt, Casey Bennett, and neonatal intensive care units. npj Digital Medicine,
David Hakken. Steps toward participatory design of 7(1):172, 2024.
social robots: Mutual learning with older adults with  M Marc´, A Bartosiewicz, J Burzyn´ska, Z Chmiel, and
depression. In Proceedings of the 2017 ACM/IEEE P Januszewicz. A nursing shortage–a prospect of global
International Conference on Human-Robot Interaction, and local policies. International nursing review, 66(1):
HRI ’17, page 244–253. Association for Computing 9–16, 2019.
Machinery, 2017. ISBN 9781450343367.  Sneha Mehta. Top 6 participatory design methods for
 James R Lewis. Sample sizes for usability studies: your project, 2024. URL 
Additional considerations. Human factors, 36(2):368– participatory-design-methods/.
378, 1994.  Stephanie Milani, Nicholay Topin, Manuela Veloso, and
 Michael Lewis, Katia Sycara, and Phillip Walker. The Fei Fang. Explainable reinforcement learning: A survey
role of trust in human-robot interaction. Foundations of and comparative review. ACM Computing Surveys, 56
trusted autonomy, pages 135–159, 2018. (7):1–36, 2024.
 Daniel Leyzberg, Samuel Spaulding, Mariya Toneva,  Michael J Muller and Sarah Kuhn. Participatory design.
and Brian Scassellati. The physical presence of a robot Communications of the ACM, 36(6):24–28, 1993.
tutor increases cognitive learning gains. In Proceedings  Laurentiu-Marian Neagu, Eric Rigaud, Sébastien
of the annual meeting of the cognitive science society, Travadel, Mihai Dascalu, and Razvan-Victor Rughinis.
volume 34, 2012. Intelligent tutoring systems for psychomotor training–a
 Daniel Leyzberg, Aditi Ramachandran, and Brian Scas- systematic literature review. In International Confer-
sellati. The effect of personalization in longer-term ence on Intelligent Tutoring Systems, pages 335–341.
robot tutoring. ACM Transactions on Human-Robot Springer, 2020.
Interaction (THRI), 7(3):1–19, 2018.  HeatherO’Brien,PaulCairns,andMarkHall. Apractical
 Zhi Li, Peter Moran, Qingyuan Dong, Ryan J Shaw, approachtomeasuringuserengagementwiththerefined
and Kris Hauser. Development of a tele-nursing mobile user engagement scale (ues) and new ues short form.
manipulator for remote care-giving in quarantine areas. International Journal of Human-Computer Studies, 112,
In 2017 IEEE International Conference on Robotics 04 2018. doi: 10.1016/j.ijhcs.2018.01.004.
and Automation (ICRA), pages 3581–3586. IEEE, 2017.  Naomi P O’Grady. Prevention of central line-associated
 Terri Link. Guideline implementation: sterile technique. bloodstream infections. The New England journal of
AORN journal, 110(4):415–425, 2019. medicine, 2023. doi: 10.1056/NEJMra2213296.
 Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, nursingeducation: abibliometricanalysis. In Journalof
Meredith Ringel Morris, Percy Liang, and Michael S Physics: Conference Series,volume 1391,page 012129.
Bernstein. Generative agents: Interactive simulacra of IOP Publishing, 2019.
humanbehavior. InProceedingsofthe36thannualacm  Yao Rong, Tobias Leemann, Thai-Trang Nguyen, Lisa
symposium on user interface software and technology, Fiedler, Peizhu Qian, Vaibhav Unhelkar, Tina Seidel,
pages 1–22, 2023. Gjergji Kasneci, and Enkelejda Kasneci. Towards
 André Pereira, Carlos Martinho, Iolanda Leite, and Ana human-centered explainable ai: A survey of user studies
Paiva. Icat, the chess player: The influence of embod- for model explanations. IEEE transactions on pattern
iment in the enjoyment of a game. In International analysis and machine intelligence, 2023.
JointConferenceonAutonomousAgentsandMultiagent  Fatai Sado,Chu Kiong Loo,Wei Shiung Liew,Matthias
Systems, AAMAS ’08, page 1253–1256, Richland, SC, Kerzel, and Stefan Wermter. Explainable goal-driven
2008. International Foundation for Autonomous Agents agents and robots-a comprehensive review. ACM
and Multiagent Systems. ISBN 9780981738123. Computing Surveys, 55(10):1–41, 2023.
 Peizhu Qian and Vaibhav Unhelkar. Evaluating the  NicoleSalomonsandBrian Scassellati. Time-dependant
role of interactivity on improving transparency in bayesian knowledge tracing - robots that model user
autonomous agents. In Proceedings of the 21st Interna- skills over time. Frontiers in robotics and AI, 2024.
tionalConferenceonAutonomousAgentsandMultiagent  Nicole Salomons, Kaitlynn Taylor Pineda, Adérónké
Systems, AAMAS ’22, page 1083–1091. International Adéjàre,andBrianScassellati. “wemakeagreatteam!”:
Foundation for Autonomous Agents and Multiagent Adults with low prior domain knowledge learn more
Systems, 2022. ISBN 9781450392136. from a peer robot than a tutor robot. In 2022 17th
 Peizhu Qian andVaibhav VasantUnhelkar. Interactively ACM/IEEE International Conference on Human-Robot
explaining robot policies to humans in integrated virtual Interaction (HRI), pages 176–184. IEEE, 2022.
and physical training environments. In Companion  Sangwon Seo, Lauren R Kennedy-Metz, Marco A
of the 2024 ACM/IEEE International Conference on Zenati, Julie A Shah, Roger D Dias, and Vaibhav V
Human-Robot Interaction, pages 847–851, 2024. Unhelkar. Towards an ai coach to infer team mental
 Carlos Quintero-Pena, Peizhu Qian, Nicole M Fontenot, modelalignmentinhealthcare. In2021IEEEConference
Hsin-Mei Chen, Shannan K Hamlin, Lydia E Kavraki, on Cognitive and Computational Aspects of Situation
andVaibhavUnhelkar. Robotictutorsfornursetraining: Management (CogSIMA), pages 39–44. IEEE, 2021.
Opportunities for hri researchers. In 2023 32nd  S Shiny and D Venkatachalam. An analysis on the
IEEE International Conference on Robot and Human integration of ai to assist staff nurses and patients in
Interactive Communication (RO-MAN), pages 220–225. intensive care units. In 2024 3rd International Confer-
IEEE, 2023. ence on Applied Artificial Intelligence and Computing
 Aditi Ramachandran,Chien-Ming Huang,Edward Gart- (ICAAIC), pages 79–83. IEEE, 2024.
land, and Brian Scassellati. Thinking aloud with a  Matthijs Smakman and Elly A Konijn. Robot tutors:
tutoring robot to enhance learning. In Proceedings Welcome or ethically questionable? In Robotics in
of the 2018 ACM/IEEE international conference on Education: Current Research and Innovations 10, pages
human-robot interaction, pages 59–68, 2018. 376–386. Springer, 2020.
 Aditi Ramachandran, Sarah Strohkorb Sebo, and Brian  Richard A Smiley, Clark Ruttinger, Carrie M Oliveira,
Scassellati. Personalized robot tutoring using the Laura R Hudson, Richard Allgeyer, Kyrani A Reneau,
assistive tutor POMDP (AT-POMDP). In Proceedings Josephine H Silvestre, and Maryann Alexander. The
of the AAAI Conference on Artificial Intelligence, 2020 national nursing workforce survey. Journal of
volume 33, pages 8050–8057, 2019. Nursing Regulation, 12(1):S1–S96, 2021.
 Ramya Ramakrishnan, Vaibhav Unhelkar, Ece Kamar,  ClaySpinuzzi. Themethodologyofparticipatorydesign.
and Julie Shah. A bayesian approach to identifying rep- Technical communication, 52(2):163–174, 2005.
resentational errors. arXiv preprint arXiv:2103.15171,  SarathSreedharan,Tathagata Chakraborti,andSubbarao
2021. Kambhampati. Foundations of explanations as model
 Joseph Redmon, Santosh Divvala, Ross Girshick, and reconciliation. Artificial Intelligence, 301:103558, 2021.
Ali Farhadi. You only look once: Unified, real-time  James W Suliburk, Quentin M Buck, Chris J Pirko,
objectdetection. In2016IEEEConferenceonComputer Nader N Massarweh, Neal R Barshes, Hardeep Singh,
VisionandPatternRecognition(CVPR),pages779–788, andTodd K Rosengart. Analysis ofhuman performance
2016. doi: 10.1109/CVPR.2016.91. deficiencies associated with surgical adverse events.
 Elijah W Riddle, Divya Kewalramani, Mayur Narayan, JAMA network open, 2(7):e198067–e198067, 2019.
Daniel B Jones, and Benjamin F Rush. Surgical  Arie Rachmad Syulistyo, Yuichiro Tanaka, and Hakaru
simulation: Virtual reality to artificial intelligence. Tamukoh. Recognizingnursingactivitiesinendotracheal
Current Problems in Surgery, page 101625, 2024. suction: Utilizing multiple readouts reservoir computing
 A Romero, J De La Hoz, and JD González. Robots in and large language models. International Journal of
Activity and Behavior Computing, 2024(2):1–22, 2024. robot policies. Applied AI Letters, 2(4):e52, 2021.
 Aaquib Tabrez, Shivendra Agrawal, and Bradley Hayes.  KatieWinkle,EmmanuelSenft,andSéverinLemaignan.
Explanation-based reward coaching to improve human Leador: A method for end-to-end participatory design
performance via reinforcement learning. In 2019 14th of autonomous social robots. Frontiers in Robotics and
ACM/IEEE International Conference on Human-Robot AI, 8:704119, 2021.
Interaction (HRI), pages 249–257, 2019. doi: 10.1109/  HWorlikar,VVyasVadhiraj,AoifeMurray,JO’Connell,
HRI.2019.8673104. C Connolly, JC Walsh, and DT O’Keeffe. Is it feasible
 Angelique Taylor, Hee Rin Lee, Alyssa Kubota, and to use a humanoid robot to promote hand hygiene
Laurel D Riek. Coordinating clinical teams: Using adherence in a hospital setting? Infection Prevention in
robots to empower nurses to stop the line. Proceedings Practice, page 100188, 2021.
oftheACMonHuman-ComputerInteraction,3(CSCW):  Holly A Yanco, Munjal Desai, Jill L Drury, and Aaron
1–30, 2019. Steinfeld. Methods for developing trust models for
 Angelique Taylor, Tauhid Tanjim, Huajie Cao, and intelligent systems. Robust intelligence and trust in
Hee Rin Lee. Towards collaborative crash cart robots autonomous systems, pages 219–254, 2016.
that support clinical teamwork. In Proceedings of the  X Jessie Yang, Vaibhav V Unhelkar, Kevin Li, and
2024 ACM/IEEE International Conference on Human- Julie A Shah. Evaluating effects of user experience
Robot Interaction, pages 715–724, 2024. and system transparency on trust in automation. In
 Sam Thellman and Tom Ziemke. The perceptual belief Proceedings of the 2017 ACM/IEEE international
problem: Why explainability is a tough challenge in conference on human-robot interaction, pages 408–416,
social robotics. ACM Transactions on Human-Robot 2017.
Interaction (THRI), 10(3):1–15, 2021.  Tuba Yilmazer and Melih Elcin. The effect of high
 AndreaThomaz. Robotsinreallife:Puttinghritowork. and medium fidelity simulator in cardiopulmonary
In Proceedings of the 2023 ACM/IEEE International resuscitation training on nursing students’ knowledge
Conference on Human-Robot Interaction, pages 3–3, and performances. International Journal of Caring
2023. Sciences, 13(2):1250–1256, 2020.
 Eylem Topbas¸, Banu Terzi, Öznur Görgen, and Gülay  Rui Zeng, Yuhui Wen, Wang Zhao, and Yong-Jin Liu.
Bingöl. Effects of different education methods in View planning in robot active vision: A survey of
peritoneal dialysis application training on psychomotor systems, algorithms, and applications. Computational
skills and self-efficacy of nursing students. Technology Visual Media, 6:225–245, 2020.
and Health Care, 27(2):175–182, 2019.  Bowen Zhang and Harold Soh. Large language models
 Jesus Tordesillas and Jonathan P How. Panther: as zero-shot human models forhuman-robot interaction.
Perception-aware trajectory planner in dynamic envi- In 2023 IEEE/RSJ International Conference on Intel-
ronments. IEEE Access, 10:22662–22677, 2022. ligent Robots and Systems (IROS), pages 7961–7968.
 Matthias Tschöpe, Stefan Gerd Fritsch, David Habusch, IEEE, 2023.
Vitor Fortes Rey, Agnes Grünerbl, and Paul Lukowicz.  JesseZhang,JiahuiZhang,KarlPertsch,ZiyiLiu,Xiang
Evaluating deep learning models for posture and move- Ren, Minsuk Chang, Shao-Hua Sun, and Joseph J Lim.
ment recognition during the abcde protocol in nurse Bootstrap your own skills: Learning to solve new tasks
education. In 2024 International Conference on Activity with large language model guidance. In Conference on
and Behavior Computing (ABC), pages 1–10. IEEE, Robot Learning, pages 302–325. PMLR, 2023.
2024.  Matthew J Ziegler, Daniela C Pellegrini, and Nasia
 Chris Varghese, Ewen M Harrison, Greg O’Grady, and Safdar. Attributable mortality of central line associated
Eric J Topol. Artificial intelligence in surgery. Nature bloodstream infection: systematic review and meta-
Medicine, pages 1–12, 2024. analysis. Infection, 43:29–36, 2015.
 Mudit Verma, Siddhant Bhambri, and Subbarao Kamb-
hampati. Theory of mind abilities of large language
modelsinhuman-robotinteraction:Anillusion? InCom-
panionofthe2024ACM/IEEEInternationalConference
on Human-Robot Interaction, pages 36–45, 2024.
 David K Warren, Wasim W Quadir, Christopher S
Hollenbeak, Alexis M Elward, Michael J Cox, and
VictoriaJFraser. Attributablecostofcatheter-associated
bloodstream infections among intensive care patients in
a nonteaching hospital. Critical care medicine, 2006.
 Olivia Watkins, Sandy Huang, Julius Frost, Kush Bha-
 and Anca Dragan. Explaining
