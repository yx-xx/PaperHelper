=== PDF文件: DexterityGen  Foundation Controller for Unprecedented Dexterity.pdf ===
=== 时间: 2025-07-22 09:42:02.446002 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个中文词语（不能是英文，不能是多个，不能是短语，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Foundation Controller for Unprecedented Dexterity
Zhao-Heng Yin1,2, Changhao Wang2, Luis Pineda2, Francois Hogan2, Krishna Bodduluri2, Akash Sharma2,
Patrick Lancaster2, Ishita Prasad2, Mrinal Kalakrishnan2, Jitendra Malik2, Mike Lambeta2,
Tingfan Wu2, Pieter Abbeel1, Mustafa Mukadam2
2FAIR at Meta
zhaohengyin.github.iodexteritygen
Motion Command
Foundation Dexterity
Controller
Dexterous Action
Fig. 1: We introduce DexterityGen (DexGen) as a foundation controller that achieves unprecedented dexterous manipulation
behavior with teleoperation. DexGen is a generative model that can translate an unsafe, coarse motion command produced
by external policy to safe and fine actions. With human teleoperation as a high-level policy, DexGen exhibits unprecedented
dexterity from diverse object rotation and regrasping to using pen, syringe, and screwdriver.
AbstractTeaching robots dexterous manipulation skills, such
as tool use, presents a significant challenge. Current approaches
can be broadly categorized into two strategies: human teleop-
eration (for imitation learning) and sim-to-real reinforcement
learning. The first approach is difficult as it is hard for humans to
produce safe and dexterous motions on a different embodiment
without touch feedback. The second RL-based approach struggles
with the domain gap and involves highly task-specific reward en-
gineering on complex tasks. Our key insight is that RL is effective
at learning low-level motion primitives, while humans excel at
providing coarse motion commands for complex, long-horizon
tasks. Therefore, the optimal solution might be a combination of
both approaches. In this paper, we introduce DexterityGen (Dex-
Gen), which uses RL to pretrain large-scale dexterous motion
leverage this learned dataset to train a dexterous foundational
controller. In the real world, we use human teleoperation as a
prompt to the controller to produce highly dexterous behavior.
We evaluate the effectiveness of DexGen in both simulation and
real world, demonstrating that it is a general-purpose controller
that can realize input dexterous manipulation commands and
significantly improves stability by 10-100x measured as duration
of holding objects across diverse tasks. Notably, with DexGen
we demonstrate unprecedented dexterous skills including diverse
object reorientation and dexterous tool use such as pen, syringe,
and screwdriver for the first time.
DexGen Controller
(Generative Model)
Multi-task Dataset in Simulation
Rotation
Translation
Learned Action Distribution
Likelihood
DexGen Controller
Teleop  Policy
(Dangerous)
(Safe and Useful)
Projection
Training Phase
Inference Phase
Fig. 2: Overview of proposed framework. Left (Training): We collect a large multi-task dexterous in-hand manipulation dataset
in simulation to pretrain a generative model that can generate diverse actions conditioned on the current state. The pretrained
generative model can produce useful actions including rotation, translation, and more intricated behaviors. Right (Inference):
During inference, we can project dangerous motion produced by teleoperation or policy back to a high-likelihood action with
guided sampling. This makes DexGen capable of assisting a coarse high-level policy to perform complex object manipulations.
I. INTRODUCTION
Dexterous robotic hands are increasingly capturing attention
due to their potential across various fields, including manu-
systems can replicate the fine motor skills of the human hand,
enabling complex object manipulation [50, 4]. Their ability
to perform tasks requiring human-like dexterity makes them
valuable in areas where traditional automation falls short.
skills to robotic hands remains a key challenge in robotics.
Recent data-driven approaches to teach robots dexterous
manipulation skills can be boardly categorized into two cate-
limitations in practical applications. For human teleoperation,
a major bottleneck is the collection of high-quality demon-
strations [32, 62]. In contact-rich dexterous manipulation, it
is challenging for humans to perform safe and stable object
manipulation actions, often resulting in objects falling from
the hand. This makes teleoperation impractical for dexterous
manipulation tasks. For sim-to-real RL, challenges arise from
the significant domain gap between simulation and the real
specifications when training an RL agent for complex tasks.
We will discuss these challenges in more detail in Section II.
While each approach has its own set of challenges, com-
bining their strengths offers a promising strategy to address
the complexities of dexterous manipulation. Specifically, re-
cent sim-to-real RL works [41, 63] have shown that it is
possible to train simple dexterous in-hand object manipulation
primitives (e.g. rotation) that can be transferred to a robot
in the real world. This suggests that RL can be leveraged
to generate a large-scale dataset of dexterous manipulation
grasp transitions. Meanwhile, humans excel at composing
these skills through teleoperation to address more challenging
tasks. For example, Yin et al. have shown that they can perform
in-hand reorientation by calling several rotation primitives
sequentially . However, the external inputs in these studies
are limited to a few discretized commands, lacking control
over low-level interactions, such as finger movements and
object contact. This limitation makes it difficult to prompt ex-
isting models to generate more detailed, finger-level interaction
Motivated by these observations, in this paper, we propose
a novel training framework called DexterityGen (DexGen) to
address the challenges of teaching dexterous in-hand manip-
ulation skills. Our main idea is to use a broad, multitask
simulation dataset generated via RL to pretrain a generative
behavior model (DexGen) that can translate a coarse motion
command to safe robot actions which can maximally preserve
the motion while guaranteeing safety. In real-world appli-
an imitation policy, can be used to prompt DexGen to exe-
cute meaningful manipulation skills. Our approach effectively
decouples high-level semantic motion generation from fine-
grained low-level control, serving as a foundational low-level
dexterity controller.
We validate our DexGen framework through both simulated
and real-world experiments. In simulation, we demonstrate
that DexGen significantly enhances the robustness and per-
formance of a highly perturbed noisy policy, extending its
stable operation duration by 10-100 times and enabling success
even when input commands are predominantly noise. In real-
world scenarios, we employ human teleoperation as a proxy
for high-level motion commands and test the framework on
various challenging dexterous manipulation tasks involving
complex hand-object interactions across a diverse set of ob-
jects. Notably, it successfully synthesizes trajectories to solve
challenging tasks, such as reorienting and using syringes and
screwdrivers for the first time (with human guidance).
II. EXISTING APPROACHES:
CHALLENGES AND OPPORTUNITIES
In this section, we review the challenges and opportunities
with existing approaches to dexterous manipulation that mo-
tivate our work.
A. Human Teleoperation for Imitation Learning
challenging for humans due to the following reasons:
a) Partial Observability: During in-hand manipulation,
the object motion is determined by the contact dynamics
between hand and object [58, 38, 23]. Successful manipulation
requires perceiving and understanding contact information,
such as normal force and friction, to generate appropriate
torques. However, human operators face challenges in ob-
serving this information due to occlusion and limited tactile
feedback. Additionally, existing discrete haptic feedback (e.g.
binary vibration) alone is often inadequate for conveying
complex touch interactions and contact geometries.
b) Embodiment Gap: Although human and robot hands
may appear similar at first glance, they differ significantly in
their kinematic structures and geometries. For example, human
fingers have smooth and compliant surfaces, while the robot
fingers often have rough edges. These differences result in
discrepancies in contact dynamics, making it challenging to
directly transfer our understanding of human finger motions
for object manipulation to robotic counterparts. In our early
change of fingertip shape.
c) Motion Complexity: Dexterous in-hand manipulation
involves highly complex motion. The process requires precise
control of a high degree-of-freedom dynamical system. Any
suboptimal teleoperation motion at any DOF can lead to
failures such as breaking grasping contacts.
d) Inaccuracy of Actions (Force): Existing robot hand
teleoperation systems are based on hand retargeting with po-
sition control, which lacks an intuitive force control interface
to users. As a result, users can only influence force through
position-control errors, making teleoperation particularly chal-
lenging in force-sensitive scenarios. Moreover, the presence of
noise in real world robot system further complicates control.
While humans may find it challenging to provide fine-grained,
low-level actions directly, human teleoperation or even video
demonstrations can still offer valuable coarse motion-level
guidance for a variety of complex real-world tasks. Humans
possess intuitive knowledge, such as where a robot hand
should make contact and what constitutes a good grasp. Thus,
human data can be leveraged to create a high-level semantic
action plan. In locomotion and whole-body control research,
recent studies have proposed using teleoperation commands
as high-level motion prompts [10, 17]. However, extending
this approach to finegrained dexterous manipulation remains
an open question.
B. Sim-to-real Reinforcement Learning
dexterous manipulation involves two main challenges:
a) Sim-to-Real Gap: It is difficult to reproduce real-
world sensor observation (mainly for vision input) and physics
in simulation. This gap can make s
