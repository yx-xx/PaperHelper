=== PDF文件: Neural Inertial Odometry from Lie Events.pdf ===
=== 时间: 2025-07-22 15:49:35.520050 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个最核心的最有代表性的中文关键词，要中文关键词（不能是英文，不能是多个，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Neural Inertial Odometry from Lie Events
Royina Karegoudra Jayanth
Yinshuang Xu
Evangelos Chatzipantazis
Kostas Daniilidis
Daniel Gehrig
Department of Computer Science, University of Pennsylvania
{royinakj,xuyin,vaghat,kostas,dgehrig}seas.upenn.edu
AbstractNeural displacement priors (NDP) can reduce the
drift in inertial odometry and provide uncertainty estimates that
can be readily fused with off-the-shelf filters. However, they fail
to generalize to different IMU sampling rates and trajectory
address this challenge, we replace the traditional NDP inputs
comprising raw IMU data with Lie events that are robust to
input rate changes and have favorable invariances when observed
under different trajectory profiles. Unlike raw IMU data sampled
at fixed rates, Lie events are sampled whenever the norm of
the IMU pre-integration change, mapped to the Lie algebra
of the SE(3) group, exceeds a threshold. Inspired by event-
based vision, we generalize the notion of level-crossing on 1D
signals to level-crossings on the Lie algebra and generalize binary
polarities to normalized Lie polarities within this algebra. We
show that training NDPs on Lie events incorporating these
polarities reduces the trajectory error of off-the-shelf downstream
inertial odometry methods by up to 21 with only minimal
preprocessing. We conjecture that many more sensors than IMUs
or cameras can benefit from an event-based sampling paradigm
and that this work makes an important first step in this direction.
MULTIMEDIA MATERIAL
Open source code can be found here:
RoyinaJayanthNIO Lie Events.
I. INTRODUCTION
Visual inertial odometry (VIO) has become a staple of
modern localization and navigation systems powering a diverse
range of applications including Augmented and Virtual Reality
(ARVR) , autonomous driving, and robotics . In short,
it works by integrating accelerometer and gyroscope measure-
ments from an inertial measurement unit (IMU) and correcting
the resulting drift with observations from a standard frame
camera . However, the usefulness of these visual obser-
vations is often limited by the quality of the captured camera
lighting conditions and high-speed motion scenarios.
In seeking to overcome these limitations, a promising
alternative has emerged, namely using neural displacement
priors (NDPs). NDPs learn to map raw IMU measurements
themselves to displacement and covariance terms, and these
can then be used to correct drift, while circumventing the
pitfalls of classical frame-based algorithms. Surprisingly, these
priors have been shown to possess similar drift-correcting
capabilities to frame-based observations , and have thus
resulted in a resurgence of IMU-only, i.e. purely Inertial
Odometry (IO) [31, 20, 6]. These neural priors generate
Neural Inerial Odometry from Lie Events. We train Neural Displace-
ment Priors (NDPs), which enable low-drift inertial odometry, with Lie Events
derived from acceleration a(ti) and angular rate (ti) measurements from
an Inertial Measurement Unit (IMU). These events enhance the robustness
of NDPs due to their favorable properties under varying sampling rates and
trajectory profiles. To generate these events, we produce pre-integrations x(t)
which reside in the special Euclidean group SE(3) and then perform level-
crossing on this signal which prompts the generalization of level-crossing and
event polarities (red and blue arrows) to higher dimensional manifolds.
denoised displacement measurements with associated uncer-
tainties by recognizing patterns in the IMU data and can
be readily fused using off-the-shelf filters. However, learning
generalizable priors has proven to be a challenging endeavor.
This is because IMU data exhibits a high degree of variability
as a result of differing IMU mount orientations, motion direc-
addressed via data augmentation , consistency losses  or
remains elusive. In particular, NDPs need to learn to ignore
data variability which may arise from different gaits or speeds.
consistency remains an open challenge.
In this work, we take on this challenge by training NDPs
with Lie Events instead of raw IMU data, visualized in
Fig. 1. Lie Events are generated when the change in IMU
pre-integration exceeds a pre-specified threshold. IMU pre-
integrations correspond to raw integrations of debiased IMU
accelerometer and gyroscope measurements. Change is mea-
sured by projecting the endpoint of the pre-integrated path
onto the Lie algebra of SE(3) and taking its norm. We show
both theoretically and empirically that this behavior imbues
the resulting events with favorable invariances with respect
to different sampling rates and trajectory profiles, enhancing
the robustness of downstream NDPs. To generate these events,
we take inspiration from classical event-based vision [29, 38],
and generalize notions of level-crossing and event polarities
to arbitrary Lie groups. In particular, we generalize level-
crossing on 1D signals to level-crossing in the Lie algebra
centered at a reference element and introduce Lie polarities
which generalize binary polarities to normalized elements in
this Lie algebra. They characterize the direction of significant
pre-integration change in the Lie algebra. Unlike their binary
analog values. These generalizations reduce to the standard
case in [29, 38] for 1D signals. Finally, we show that event
generation partially canonicalizes the IMU data with respect
to motion variations within an interval. This canonicalization
transforms IMU sequences to a space with lower data variabil-
ity and thereby enhances the generalizability of NDPs trained
in this space. Our contributions are the following:
We present a canonicalization scheme for IMU data
which converts them into Lie Events. These Lie Events
are directly compatible with a wide range of existing
ness with only minimal preprocessing.
We show both empirically and theoretically that these
Lie Events possess favorable invariances with respect to
motion variations within an interval, highlighting their
benefit for NDP training.
Lie Events, which requires the extension of traditional
notions of level-crossing and event polarities to arbitrary
Lie groups. These tools are applicable in a wide range of
To show the generality of our method we apply it to multiple
down-stream NDPs and multiple datasets, where we show
consistent error reductions, with only minimal preprocessing.
II. RELATED WORK
Neural Prior for IO: Learning-based inertial odometry (IO)
effectively reduces integration drift by leveraging neural priors.
Recent approaches [43, 1, 20] introduce neural priors via
velocity regression. Specifically, RIDI  utilizes CNNs to
predict velocity for IMU data refinement, PDRNet  applies
recurrent networks for velocity regression, and RONIN
employs TCNs to directly integrate the predicted velocity for
neural-based fusion. Some works [7, 31, 9, 40] learn the
displacement prior. Specifically, TLIO  predicts both 3D
displacements and diagonal covariances via a network, and
incorporates them in an Extended Kalman Filter (EKF) via
a measurement equation. RNIN-VIO  extends TLIO to
continuous pedestrian motion estimation with visual inputs.
In the meanwhile, there are some methods
Brossard et al.
, Buchanan et al. , Brossard et al.  that leverage the
power of deep learning to denoise the motion and Steinbrener
et al.  predicts the IMU biases. Our proposed Lie events
can be directly applied to TLIO , and enhance its robust-
ness to variations in motion and sampling rate.
long been widely practiced with both hand-crafted and learned
techniques. Recently, canonicalization with equivariant models
to improve generalization in off-the-shelf models has gained
popularity. Kaba et al.  first theoretically proposed using
Learned Canonicalization Functions to achieve equivariance
with general off-the-shelf models. In practical applications,
Li et al. , Baker et al.  canonicalize point clouds
by constructing global and local frames, Deng et al.
introduces an equivariant canonicalization method in PointNet
for 3D shape analysis and reconstruction, and Jayanth et al.
learns an equivariant frame to canonicalize IMU data
with respect to reflections and rotations. Additionally, with
the rise of large pretrained models, recent work  applies
canonicalization as an input preprocessing step to such models.
Event-based Sensors: Event-based sensors are most promi-
nently used in the computer vision community, where they
address the bandwidth-latency tradeoff [12, 16] of algorithms
based on fixed-rate images from standard frame-based image
sensors. Capturing high-speed motion requires high framer-
risks missing vital scene dynamics due to the increased latency.
Event cameras like the dynamic vision sensor (DVS) ,
address this by adapting their sampling rate to the scene
dynamics. They do this by responding only to changes, i.e.
performing event-based sampling on the log intensity signal
observed at a single pixel. Alternative cameras, like the Asyn-
chronous Time-based Image Sensor (ATIS) , use the same
event-based sampling technique but instead measure absolute
intensities. Most recently, the work in  introduced the
generalized event camera, which explored a large range of
possible event cameras differing in the condition when an
event is triggered, and what type of data is read out for each
event. Beyond the vision domain, event-based sensing has
been also generalized to asynchronous binaural spatial audition
presented in
shows the benefits of using event-guided
guidance to a structured light system for efficient scene recon-
struction. This growing set of event-based sensors inspires the
development of an event-based IMU, presented in this work.
Similar to works in event-based control theory  which
consider attitude consensus, our work focuses on generating
events on the manifold. However, unlike , we use these
events for inertial odometry and consider the full SE(3)
manifold instead of only SO(3).
III. METHOD
The goal of this work is neural inertial odometry from a
single IMU, comprised of an accelerometer providing linear
acceleration measurements a(ti) R3, and a gyroscope
providing angular velocity measurements (ti) R3 at
discrete times ti. These measurements are related to the true
canonical event timestamps
reference  ()
event timestamps
arc len.
Event timestamps j generated from reference signal x(t)
x((t)) can be computed from the event timestamps
j of the path x(s),
by applying the inverse mapping 1. Moreover, references xref,j  x(j)
j ) are equal and independent of a specific .
angular velocity (ti) and acceleration a(ti) via
(ti)  (ti)  bg(ti)  g(ti)
a(ti)  a(ti) Rwb
(ti)g  ba(ti)  a(ti)
where g R3 denotes the gravity direction pointing down-
ward in world frame w, Rwb(ti) is the transformation between
body frame b and w at time ti, and bg, ba and g, a
i are IMU
biases and noises respectively.
As in previous works  we assume access to a gravity
direction and bias estimate via a filter, with which IMU
measurements are gravity-compensated and bias-corrected:
(ti)  Rg(ti)((ti) b
a(ti)  Rg(ti)(a(ti) b
a(ti))  g
where Rg(ti) is the estimated gravity aligned frame, such that
Rg(ti) R
wb(ti)g  R(ti)g  g and R(ti) is an unobserv-
able yaw around the gravity axis. The resulting measurements
thus mimic the true body rates (ti), a(ti). Note that estimates
of gravity and biases can be easily found by running an
We address inertial odometry with neural displacement
priors that regress displacements and covariances from a se-
quence of IMU measurements regularly sampled at timestamps
ti  it within a time interval I  [0, T]. We will denote
these sampling times with T  (t1, ..., tN) and N  T
We will use the shorthand (T ) to denote the set {(ti)}tiT .
Then the displacement prior can be written as
Here d R3 is the displacement between times t  0 and
t  T, and  R33 is its associated covariance. Note that
our exposition also encompasses methods like
predict averaged velocity v over a time window. Displacement
can be simply recovered via d  vT, with constant T.
In what follows, we will derive steps to make the above
neural network robust to variations in IMU speed, thus en-
hancing its generalizability. In particular, we achieve this
by generating canonicalized inputs (E), a(E) sampled at
specifically chosen event timestamps E  (1, ..., M), and
augmented by Lie polarities p(E) with p(j) S5 R6
via a suitable preprocessing step, using on-manifold event
generation. These polarities are normalized vectors that encode
the change direction of pre-integrations, and will be defined
later. We term these network inputs Lie events. In summary,
our neural network uses inputs
In particular, we parametrize the uncertainty with a diagonal
covariance   exp (diag(2ux, 2uy, 2uz)) with learnable
will study the impact of speed variations on the original neural
network inputs, and then how to derive the new inputs above.
A. Modeling Speed Variations in IMU motion
Let the IMU trajectory1 T(t)  (R(t), t(t)) SE(3) on
the interval I be decomposed into
T(t)  T((t))
with path2 T(s) parametrized by arc-length s and unit
velocity v(s) 1 and time parametrization  : I [0, 1]
with speed (t) > 0 and (0)  0 and (T)  1. Note that
network outputs in Eq. (6) only depend on the path, since
0(tT t0)  R
where R0, t0 and RT , tT denote the pose at time t  0 and
t  T respectively. Moreover, for methods like
predict average velocity v  d
T  vfor a fixed and
given T. Yet, the network inputs are affected by (t) via the
kinematic relations
R(t) R(t)
a(t)  t(t)
where (.)maps a skew-symmetric matrix to a vector. Using
the chain rule we find that
where canonical angular rate and acceleration are defined as
R(s)R(s)
and a(s)  t(s). Note the use
of (.) to denote derivatives, as these are no longer temporal
derivatives. Thus the network inputs (T ) and a(T ) depend
on  in the same form as above: First,  modulates the function
evaluation time, i.e. shifts the evaluation time from T to (T ),
and second it modulates the magnitude of the measurement
via its derivative. We perform partial canonicalization of the
existing inputs and provide additional canonical inputs by
introducing new event timestamps E  (1, ..., M) and Lie
polarities p(E). Crucially, these event timestamps depend on
the trajectory T(t) taken by the IMU and, by construction, will
depend on the event timestamps E (
M) derived
from the path T(s) via E  1(E)3. Likewise, we will
construct polarities p(j) that only depend on the path, and
1Subscripts wb (body to world transformation) are omitted for brevity.
2We distinguish between path which is simply the sequence of points, and
trajectory which depends on time.
3Note that since (t) > 0 the function  is invertible.
Illustration of on-manifold event generation. (A) For a reference signal x(t) on SE(3) we find the tangent space at the last reference pose xref,i. In
this space, we find the moment it exits the -ball and record the polarity p(j) with unit norm perpendicular to that ball, and update the reference pose to
are thus equal to the polarities p(
j ) derived from the path.
As a result, the inputs to the network become
a(E)  (E)2a(E)  (E)v(E)
p(E)  p(E)
simplifying
dependence
p(E), v(E), (E), a(E)
canonicalized
only depend on path T(s), not T(t), and that the polarity is
completely independent of . Thus networks trained on these
quantities exhibit better generalization to variation in motion
. Next, we discuss how to construct E and p(j) with the
properties outlined above.
B. Generating IMU Events
To construct the event timestamps E we take inspiration
from event-based cameras . These cameras have indepen-
dent pixels that trigger an event whenever the difference of the
log intensity log(I(t)) at a specific pixel with respect to some
reference log(Iref) exceeds a threshold . We generalize this
notion by identifying the pixel intensity with a new variable
termed reference signal x(t) . I(t). Thus, given that an event
was triggered at the last time step j1 and reference xref,j1,
the next event timestamp and reference can be written as
t>j1{t :  log(x(t)) log(xref,j1)},
and xref,j
x(j). Furthermore, event cameras report a
polarity p(j) which can be defined as
i.e. the sign of the change since the last reference. Using the
Setting the initial event timestamp 1  0, and refer-
ence to xref,1
. x(1) we can generate event timestamps
ities p(2), ..., p(M) recursively from a given signal x(t).
We will show that such a sampling scheme has the desired
property E  1(E). In particular, as the log intensity L(t)
at a given pixel, we can let the reference signal x(t) depend
on a canonical reference x(t)  x((t)). We can inductively
prove the following theorem (see appendix, Sec. I):
Theorem 1. If x(t)  x((t)) with (t) > 0 and (0)
j ) and xref,j  x
The implications of this theorem are that for all j we can
simply find the event timestamps j by computing
j from the
path x(s) and applying 1. Note that, since xref,j  x
the polarity p(j), defined in Eq. 16, only depends on events
on the path x(s), i.e. p(j)  p(
j ). We visualize these
relations in Fig. 2. This theorem establishes the core invariance
property of Lie polarities (dependent on xref,j) to variations in
parametrization (t). Moreover, it shows that we can derive
such polarities without needing to directly access unobservable
(t) and x(s) by simply performing event-based sampling on
observable x(t). Crucially, we never explicitly compute x(s)
or (t). Having established these event properties, we turn
to finding a suitable reference signal x(t) for IMU inertial
odometry. We will show that the codomain of this reference
is SE(3), and thus, we extend the notion of event-based
sampling to manifolds.
C. On-manifold Event Generation
Several options exist for selecting the reference signal as
long as it can be written in terms of x(s) as x(t)  x((t)).
This excludes acceleration- or velocity-like signals since these
transform as a,  (i.e. depend on , ), but includes distance-
like signals, e.g. the distance over time from some selected
origin. We use relative IMU pose estimates over the time
x(t)  ( R(t),t(t)). These terms are the on-manifold forward
Euler integrated solution R(t),t(t) to (9), using raw IMU
measurements a(ti), (ti). Forster et al.  provides formu-
lae for these, given initial pose ( R(t1),t(t1))  ( R(t1),t(t1))
and velocity v(t1)  v0, namely
R(ti1)  R(ti)Exp({(ti) bg(t1)}t)
v(ti1)  v(ti)  R(ti)(a(ti) ba(t1))t  gt
t(ti1)  t(ti)  v(ti)t  1
R(ti)(a(ti) ba(t1))t2
which provides finite samples R(ti),t(ti) for ti T . We
define the continuous signal x(t) by interpolating between
these samples. In particular, between samples i and i  1 we
construct the geodesic path defined on [ti, ti1] as
x(t)  x(ti)Exp
Log(x1(ti)x(ti1))
Here Log : SE(3) se(3) is the log map, which sends
relative poses to elements in the tangent space, and Exp :
se(3) SE(3) is the (inverse) exponential map. In Sec. IV-D,
we show that event generation is robust to IMU rate variations,
and interpolation errors.
While during test time we use the EKF state to set v0,
during training we use ground truth, and add random perturba-
tions to v0 to simulate filter uncertainty. Since pre-integrations
mimic the true pose of the IMU, they approximately depend
on pre-integration paths R
While previously our reference signal was simply a 1-D signal
(log intensity), the above pre-integrations naturally reside in
SE(3). Thus notions such level-crossing, and polarities need
to be generalized. We start off by replacing the notion of signal
change between xref,j1 and x(t) with the geodesic distance
in SE(3), and use this to replace the L2-norm in Eq. 15
and xref,j  x(j). Note that this equation mimics Eq. (34)
applied to event-based attitude control on SO(3).
We extend this to SE(3) and introduce the notion of event
polarities in this space, which we use to enhance the robustness
of our method. We visualize the event generation process in
3 (a). We see that on the manifold, event generation
amounts to finding the timestamp when the signal projected
to the tangent space centered at xref,j1 steps outside of a ball
of dimension 6. At the point where this crossing happens we
record the unit vector perpendicular to this sphere and define
it as being the Lie polarity of the event at time j:
where S5 denotes the 6D unit sphere. we can reconstruct the
original signal with p(j) recursively
These closely mimic the formulae for event generation in
Eqs. (15) and (16), but are valid for arbitrary Lie groups. More-
Eqs. (15),(16), and (17) and polarities p(j) S0  {1, 1}.
Note also that Theorem 1 can be seamlessly transferred to this
In Fig. 3 (b) and (c) we illustrate the invariance of polarities
to time reparametrizations by considering a toy example of a
dot moving in R2 without orientation. We visualize two refer-
ence signals x1(t)  x(1(t)) and x2(t)  x(2(t)), with
different speed profiles. The tangent planes around reference
poses in R2 can be visualized as planes perpendicular to time,
and the  ball can be visualized as a cylinder parallel to time.
Polarities are 2D unit vectors perpendicular to the cylinder.
Projecting this image onto the xy-plane (Fig. 3 (c)) reveals
that the polarities only depend on the path x(s), not .
D. Network Inputs
As our method generates a variable number of events it is
not directly compatible with off-the-shelf neural displacement
priors  which are designed to handle a fixed number of
IMU measurements. Inspired by event-based vision, we use
event stacks . We convert Lie events (E),a(E), p(E) to
tensors Ea,, Ep RB6 with B  200 via:
[a(j)(j)][b j]
Ep[b]  1
p(j)[b j]
where M is the number of events triggered on the interval
[0, T], and  is the Kronecker delta. Note that M can be much
smaller than B, leading to sparsity in the inputs. Future work
could tackle leveraging this sparsity for efficient processing.
Acceleration and angular rates have been concatenated. Here
nb denotes the number of samples mapped to index b and lb
denotes the norm of the vector at index b so as to normalize the
polarity. Furthermore, j
maps the index
of the event into a range [0, B 1]. Note that we linearly
and Ep along the channel dimension, resulting in an input
tensor of shape B  12.
Note on Timestamps: We do not feed in raw time stamps
into the network since they vary with the unobservable speed
(t) from the trajectory, not the path x(s). They would thus
re-introduce data variability, which the network would need
to learn to ignore. We believe the network can recover the
displacement by leveraging event polarities. Eq
(25) shows
that the path x(s), which is sufficient to find, d can be
recovered from polarities alone and without raw time stamps.
We argue that the network learns to correct this reconstruction
with priors and additional information from a(j) and (j).
IV. EXPERIMENTS
of Theorem 1 in Sec. IV-A, before demonstrating the gen-
erality of our approach by applying it to the neural inertial
odometry frameworks TLIO  (Sec. IV-B) and RoNIN
(Sec. IV-C). Furthermore, we will present a sensitivity study
that highlights the robustness of our approach with respect to
IMU rate variations in Sec. IV-D, and round off with ablation
and hyperparameter sensitivity studies in Sec. IV-E.
Ref. x(t)
Correction
Contrast Threshold
pre-integration
ground truth
CHAMFER DISTANCE IN  BETWEEN EVENT TIMESTAMPS (E) AND
CANONICAL EVENT TIMESTAMPS E. NO CORRECTION DENOTES THAT E
WAS NOT REMAPPED USING .
A. Toy Example
ence signals based on the pre-integration of IMU accelerations
and angular rates, and show their relation to event timestamps
Egenerated from canonical pre-integrations. We use IMU
data from the TLIO test dataset , which comprises 60
hours of 1 kHz IMU data, with 200 Hz ground truth trajectory
data from MSCKF . It was gathered from five individuals
performing a broad range of activities, for example, walking,
stair traversal, and kitchen organization. More dataset details
are in the appendix, Sec. V.
We denote non-overlapping 1-second ground truth trajec-
tories as paths T(s) and generate synthetic new trajectories
T(t)  T((t)), where (t)  ( t
t) [0, 1] with
t  1s and  {0.5, 1.0, 2.0}. We then generate artificial
IMU measurements by fitting a spline through the poses and
finding derivatives. We apply bias, noise, and bias drift consis-
tent with the noise magnitudes found in . We then perform
pre-integration on IMU data from the path R(s),t(s) and
trajectories R(t),t(t). Finally, we generate events using
different thresholds  {0.005, 0.01, 0.02} producing canon-
ical event timestamps Eand non-canonical event timestamps
E. Finally, we map E to the canonical setting, i.e. compute
(E) and compare them with Evia the chamfer distance.
For comparison, we also report the chamfer distance without
remapping. We compare with noiseless ground truth poses as
the reference signal to show the lower error bound.
Tab. I shows that event generation is capable of sampling
the correct measurement even after time dilation. The smallest
threshold 0.005 achieves an error of 1.15  for a remapping
of (t)  t2. We also see that using ground truth significantly
reduces this error to about 0.1 in the same setting validating
the theory for ideal references. Future research can benefit
from more accurate pre-integration schemes.
B. Application to TLIO
TLIO is a learning-based inertial odometry algorithm that
estimates the 6-DoF IMU pose with an extended Kalman
filter (EKF). Propagation is performed by integrating raw ac-
celerometer and gyroscope measurements, while measurement
updates are performed with neural network-based displace-
ment and covariance predictions d R3 and  R33. The
network takes 1-second windows of 200 IMU measurements
as input with shape 200  6. IMU data is bias-corrected
using factory calibration bias values, and gravity aligned using
the EKF orientation state. EKF details and propagation and
measurement equations are provided in Sec. II, and network
details in Sec. IV of the appendix.
Implementation Details We pre-integrate accelerometer
and gyroscope measurement sequences of length 200 and
obtain the orientation and position estimates in a gravity-
aligned world frame. We use the EKF estimates of orientation,
testing. We then generate event timestamps and polarities
using this reconstructed trajectory and a threshold   0.01.
Sec. IV-E shows a sensitivity analysis motivating the choice
of . For consistency, we map the polarity into the gravity-
aligned frame after generation.
described in the appendix, and evaluate it on the TLIO Test
Set and the Aria Everyday Activities (Aria) Datasets .
Aria is an egocentric dataset collected using the Project Aria
glasses  and comprises a left (800 Hz) and right (1 kHz)
IMU with ground truth position and orientation. It contains 7.3
hours of data and includes a wide range of wearers engaged
in everyday activities like reading, exercising, and relaxing.
More dataset details are in the appendix, Sec. V.
Training Details: We train the first 10 epochs we train with
a component-wise MSE loss , so that the displacement
prediction converges, and we then, for 40 epochs, switch
to a Maximum Likelihood Error (MLE) loss  which
incorporates both the predicted displacement and diagonal
covariance. We use a learning rate of 104, the Adam op-
models on NVIDIA a40 GPUs. During training, we use ground
truth initial velocities v0 for bootstrapping pre-integration, and
perturb it with uniform noise nv0 U[0.5, 0.5]. To simulate
noise in the gravity-aligned frame, we perturb the gravity
direction by 5uniformly at random and apply a random
yaw. Furthermore, we add uniform noise n U[0.05, 0.05]
and na U[0.2, 0.2] to angular rates, and accelerations
simulating uncertainties in bias estimates. We also add noise
np U[0.5, 0.5] to polarities before renormalizing.
ants of TLIO , which, similar to our method, target time
scale robustness. During training, we randomly subsample
the 200 Hz IMU data to rates r {20, 40, 100, 200}. Since
natively TLIO requires an input of 200 samples, we convert the
subsampled data back to 200 by interpolation (denoted TLIO
interp.) or by using the event stack in Eq. (26) (denoted TLIO
splat.). Note that our method (denoted TLIO  events) is
not trained with rate augmentation.
and written out in detail in the appendix, Sec. VI:
Mean Squared Error (MSE) between predicted (d(ti))
and ground truth displacements (d(ti)) averaged over the
trajectory.
Absolute Translation Error (ATE), i.e. the RMSE between
estimated (t(ti)) and ground truth positions (t(ti)).
NN evaluation
NNEKF evaluation
TLIO Dataset
Aria Right
Aria Left
TLIO Dataset
Aria Right
Aria Left
events (ours)
TABLE II
COMPARISON OF OUR METHOD AGAINST BASELINES TLIO WITH AND WITHOUT DATA AUGMENTATION ON THE TLIO DATASET , AND ARIA
EVERYDAY DATASETS . NOTE HERE LEFT AND RIGHT DENOTE THE LEFT AND RIGHT IMUS IN THE ARIA DATASETS.
Relative Translation Error (RTE), i.e. local differences
between t(ti) and t(ti) over a 1-second or (1 minute for
RoNIN) window t.
Absolute Yaw Error (AYE), i.e. the yaw RMSE.
Translational drift over the total distance traveled.
To limit the impact of outliers we report the median error
over the different trajectories of the dataset. Furthermore, to
evaluate the impact of the neural network and EKF separately,
we evaluate two types of trajectories produced by our method:
The first uses simple integration of the network outputs, and
the corresponding metrics are denoted with a , and the second
uses the EKF, and is denoted without a .
in Sec. VII of the appendix. First, we see that, without EKF,
events improve ATEon all datasets. They reduce the ATE
on the TLIO Dataset by 13, on Aria Right by 11, and
on Aria Left by 19 compared to base TLIO. Moreover, it
reduces MSEon most datasets, reducing by 17 on Aria
than base TLIO on the TLIO Dataset. As in  we argue
that the correlation between MSE and ATE is not exact, since
other methods may produce displacement estimates with lower
Our methods EKF accuracy (ATE), is 10 higher on the
TLIO Dataset, 3 on the Aria Right Dataset, and 12 on the
Aria Left Dataset compared to base TLIO. We also see that
our method outperforms base TLIO in terms of drift but is
outcompeted by methods that use data augmentation.
C. Application to RoNIN
RoNIN  is a 2D inertial navigation method designed for
IMU-based pedestrian tracking. It works by regressing velocity
a ResNet-18 . These velocities are regressed with a 25ms
using known orientations from the IMU.
Implementation Details: As in
we use the RoNIN
of 200 measurements into events, using the same parameters
as for TLIO but a higher contrast threshold   0.1 due to
the higher average accelerations. We also use the last velocity
prediction as initialization for pre-integration.
RoNIN dataset  which comprises 200 Hz IMU and ground
truth trajectory data collected from pedestrians with varied
Training
RoNIN  ResNet
RoNIN  LSTM
RoNIN  TCN
RoNIN  ResNet
events (ours)
Integration
TABLE III
APPLICATION OF OUR METHOD TO THE RONIN ARCHITECTURE, AND
COMPARISON ON THE RONIN, RIDI, AND THE OXFORD INERTIAL
ODOMETRY DATASETS (OXIOD). NOTE,  INDICATES TRAJECTORY
RECONSTRUCTION WITHOUT AN EKF, AS REPORTED IN [20, 6].
placements and devices. We report results on the RoNIN
test set, and also on the RIDI  and Oxford Inertial
Odometry Dataset (OxIOD) . RIDI comprises pedestrian
data at 200 Hz, with four different sensor placements, and
includes forward, backward, and sideways walking motion as
well as accelerating and decelerating motions. This dataset
uses Umeyama alignment  before calculating metrics. The
OxIOD dataset also comprises smartphone-based pedestrian
data with various motion modes, devices, and device place-
ments. More dataset details are in the appendix, Sec. V.
Training Details: Training mirrors  with 50 of the
training data that is public, minimizing the robust velocity
loss proposed in . We use ADAM  with a batch size
of 128 and an initial learning rate of 104 and a decay by
a factor of 0.1 if the validation loss does not decrease in 10
epochs. The maximum number of epochs is 120. Furthermore,
the linear layers use dropout with p  0.5.
As in  we
omit gravity perturbation, and bias noise, and leave other noise
sources and magnitudes the same.
on raw IMU data with three different temporal processing
and also compare against RIO . RIO adds two additional
strategies to RoNIN which enforce approximate yaw equivari-
ance. The first one, termed joint training (denoted with J),
optimizes an auxiliary equivariant consistency loss between
predictions observed under different yaws. The other strategy,
adopted during testing and termed adaptive test-time-training
(denoted with TTT) performs gradient descent steps on the
current model at 20 Hz, based on the equivariant consistency
loss derived from a buffer of 128 past IMU measurements.
Backpropagation is only performed on losses between samples
IMU rate sensitivity analysis. Each method is trained on the TLIO training set. Methods  interp. and  splat. were trained with IMU rate augmentation
and TLIO and TLIO  events were trained without data rate augmentation.
contrast threshold
Error [m]
v0 noise
Error [m]
polarity noise
Error [m]
Hyperparameter Sensitivity: (left) the contrast threshold determines the distance to the reference when events are fired, (middle) initial velocity v0
and (right) polarity p(j) noise determine the range of uniform noise perturbing these quantities during training. In particular, v0 noise affects pre-integration.
that have a significant predicted velocity mismatch. Further-
via a separate ensemble of models that estimate prediction
uncertainty online. Finally, we report the results of a naive
double integration baseline (denoted with Integration).
in Sec. VII for the appendix. Note that the first three rows
are results reported in  which use 100 of the training
data. Other methods are retrained with the public training data,
which is only 50. We observe that, despite this mismatch,
in terms of ATE, our method outperforms RONIN on 50
data on the RONIN dataset, on RIDI, and on OxIOD. Test-
time training and yaw consistency methods can be used
complementarily to our method to further improve results.
Similar to the results when applied to TLIO,
the above results highlight the strength of using events 
