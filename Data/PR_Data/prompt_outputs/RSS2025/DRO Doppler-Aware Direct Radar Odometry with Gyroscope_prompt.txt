=== PDF文件: DRO Doppler-Aware Direct Radar Odometry with Gyroscope.pdf ===
=== 时间: 2025-07-22 15:50:53.979510 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个最核心的最有代表性的中文关键词，要中文关键词（不能是英文，不能是多个，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Cedric Le Gentil, Leonardo Brizi, Daniil Lisus, Xinyuan Qiao, Giorgio Grisetti and Timothy D. Barfoot
Autonomous Space Robotics Lab
University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Ontario, Canada
Department of Computer, Control, and Management Engineering Antonio Ruberti
Sapienza University of Rome
AbstractA renaissance in radar-based sensing for mobile
robotic applications is underway. Compared to cameras or lidars,
millimetre-wave radars have the ability to see through thin
heavy rain, fog, snow, and dust. In this paper, we propose a novel
SE(2) odometry approach for spinning frequency-modulated
continuous-wave radars. Our method performs scan-to-local-map
registration of the incoming radar data in a direct manner
using all the radar intensity information without the need for
feature or point cloud extraction. The method performs locally
continuous trajectory estimation and accounts for both motion
and Doppler distortion of the radar scans. If the radar possesses a
specific frequency modulation pattern that makes radial Doppler
velocities observable, an additional Doppler-based constraint is
formulated to improve the velocity estimate and enable odome-
try in geometrically feature-deprived scenarios (e.g., featureless
tunnels). Our method has been validated on over 250 km of on-
road data sourced from public datasets (Boreas and MulRan)
and collected using our automotive platform. With the aid of a
an average relative translation error of 0.26 on the Boreas
leaderboard. When using data with the appropriate Doppler-
enabling frequency modulation pattern, the translation error is
reduced to 0.18 in similar environments. We also benchmarked
our algorithm using 1.5 hours of data collected with a mobile
robot in off-road environments with various levels of structure
to demonstrate its versatility. Our real-time implementation is
publicly available:
I. INTRODUCTION
From air traffic control to weather forecasting via marine
During the early days of mobile robotics, radars were used to
detect specific landmarks and perform Simultaneous Locali-
sation And Mapping (SLAM) . While the advent of lidar
technologies and the ubiquity of cameras drove the state esti-
mation research community away from radar sensing , we
are currently experiencing a new wave of interest toward this
modality . This interest is partly driven by the robustness
of radars with respect to adversarial weather conditions. In this
and benchmark its performance across different datasets in
both automotive and off-road robotic scenarios as shown in
The working principle of radar sensing consists of emitting
radio waves and analyzing the signal returned through various
reflections of the waves from objects present in the environ-
Estimate
Groundtruth
Sequence Start
Estimate
Groundtruth
Sequence Start
This paper presents a Direct Radar Odometry (DRO) method
that provides state-of-the-art performance in a wide range of environments
including unstructured ones (right) and geometrically degenerated ones such
as featureless tunnels (left).
ment to collect geometric information about the surroundings.
This work leverages data from millimeter wave (mmWave)
radars that use electromagnetic waves with a length scale that
is in the order of magnitude of one millimetre. Waves in
such frequency bands can penetrate through plastic, textiles,
radar allows the system to sense its environment in a wide
range of conditions, even under intensely adverse weather
conditions such as fog, rain, and snow. Like any wave, the
radar-emitted signals are subject to the Doppler effect when
the relative velocity between the system and part of its
environment is not zero. Thus, when using specific frequency
patterns and processing, radar data can allow for the extraction
of Doppler-based radial velocity information. These benefits
represent a competitive advantage of radars compared to other
proposed odometry method accounts for the Doppler-based
distortion of the radar data and can integrate a Doppler-
specific velocity constraint in its optimization, allowing it
to robustly perform odometry even in geometrically feature-
deprived environments, such as featureless tunnels (see Fig. 1
(left)).
Two types of radar sensors are typically used in robotics
In this work, we focus on spinning radars, as they provide
a 360Field-of-View (FoV) that contains dense intensity
information from up to several hundred meters away. This
makes spinning radar enticing for navigational tasks such as
the entire surroundings is required for robustness and safety.
The most common spinning-radar-odometry approaches use
the dense intensity information to extract a set of points or
features [21, 3, 17, 9, 14, 47, 54]. These approaches work
of-the-art (SOTA) [3, 46], but they require computationally
costly data association, critical parameter tuning, and they
ultimately discard a large amount of the gathered data in favour
of sparse representations. Methods that have used the entire
scan directly for odometry have done scan-to-scan correlation
matching on the intensity image
, sometimes requiring
pre-processing using a deep learning network [10, 62]. How-
and Doppler distortion of the radar data, and discretize the
relative transform search space to lower the computational
cost. Additionally, the need for a learned processing compo-
nent limits the transferability of these approaches to different
environments.
In this work, we present the first Direct Radar Odometry
(DRO) framework that accounts for the continuous motion
and Doppler distortion of the incoming data in a principled
way. It can be aided by a yaw-axis gyroscope and does not
rely on deep-learning techniques or hand-tuned discretization
parameters. As demonstrated on more than 250 km of data,
it is applicable to a wide range of environments. With the
appropriate radar emission pattern, it can also perform in
geometrically challenging scenarios that generally lead to
degenerated state estimates. The main contributions are as
1) The formulation of the first direct radar registra-
tion method that accounts for continuous motion and
Doppler-based distortion in a gradient-based optimiza-
tion that does not discretize the search space.
2) A novel way to leverage the Doppler effect for velocity
estimation from spinning radar without assuming that
consecutive radar beams correspond to the same objects.
3) Our method is capable of SOTA radar-odometry perfor-
mance when used with a gyroscope.
4) A real-time GPU-based implementation. 1
II. RELATED WORK
A radar odometry system [37, 1, 61, 20], like other odom-
etry systems, aims to estimate the ego-motion of the sensor,
in this case, a radar, thus determining the trajectory of the
platform on which the sensor is mounted. The motion esti-
mation process typically involves formulating an optimization
and an environment model that maximizes the probability
of observing the measured data. This principle is known as
maximum-likelihood estimation.
In the last decade, radar odometry has been dominated by
indirect approaches , which rely on selecting salient points
or features from radar measurements. Early works, such as
, started by leveraging computer vision approaches, such
as SIFT  features, from radar Cartesian images, while
more recent state-of-the-art methods, such as CFEAR ,
select points based on each individual azimuths of a radar
signal. There exist two main categories for feature extrac-
tion methods : signal-based and spatial-based extractors.
Signal-based methods identify points by applying thresholds
to individual azimuths in the radar signal. A well-known ex-
ample is the Constant False Alarm Rate (CFAR) method ,
which processes each azimuth of a radar scan using a sliding
window. The power readings within the window are used to
calculate a detection threshold. Many variants of CFAR exist
[51, 57, 33, 65, 63, 60, 11]. Another signal-based extractor,
a static threshold along each azimuth. In contrast, spatial-
based extractors rely on extracting features and descriptors
from radar scans transformed into Cartesian images, some of
those leverage computer vision algorithms, such as ORB
or SIFT .
Indirect odometry systems, extracting points from the radar
is one of the most critical building blocks of these systems.
Burnett et al.  introduced motion-compensated RANSAC
to ensure robust association. Subsequently, they developed
matching within the ESGVI  batch state estimation frame-
work. In CFEAR , the authors extract the surface points
and demonstrate that the point-to-line and point-to-distribution
perform better than point-to-point, as these metrics mitigate the
problem of erroneous associations between individual points.
After an initial scan filtering step, Kung et al.  extract
sets of local Gaussian distributions and perform point-to-
distribution registration. Finally, some other systems exploit
data-driven approaches to downscale noisy point contributions
in the optimization problem  or to select others suitable
for the data association .
association. While this kind of method has been well studied
for lidar [23, 25, 35] and monocular odometry [28, 30, 36,
somewhat limited and methods are slower than feature-based
methods. Barnes et al.  proposed a brute-force approach
that samples and selects rotations to maximize the dense
correlation between radar scans. Similarly, Checchin et al.
and Park et al.  addressed the need for sampling by
decoupling rotation and translation. They utilized the Fourier-
Mellin Transform, maximizing phase correlation between log-
polar and Cartesian images to estimate rotation and translation,
respectively. A coarse-to-fine phase correlation refinement on
Cartesian images was then applied to improve the translation
estimate. While Barnes et al.  achieved remarkable per-
formance in odometry estimation, their method suffered from
high computational complexity. To address this, Weston et al.
replaced the brute-force rotation search with an FFT-based
of slightly lower accuracy. Overall, existing direct methods
either decouple the estimation of rotation and translation
or sub-sample the problem within a discrete search space.
These strategies can result in susceptibility to local minima
and poor scalability across different resolutions. In contrast,
our approach optimizes the locally continuous SE(2) radar
trajectory without discretizing the search space.
For both direct and indirect methods, motion distortion can
significantly degrade system performance. In the literature,
this issue has been addressed using continuous-time trajectory
cameras . This work applies similar concepts to radar
data while also correcting Doppler distortion in a continuous-
time optimization. The Doppler information channel provides
valuable additional data that can be leveraged for odometry
and ego-motion estimation. Several works have explored its
integration with different models and estimation techniques
to enhance motion estimation accuracy. Kellner et al.
demonstrated that automotive radar, combined with an Ack-
ermann vehicle model, can estimate ego-motion by fitting
least-squares to stationary point Doppler velocities identified
via RANSAC. In , a gyroscope is used to alleviate the
need for an Ackermann platform. Galeote-Luque et al.
extended this by using Doppler measurements for 3D odom-
etry with RANSAC and a kinematic model. Kubelka et al.
showed that integrating high-quality Doppler data with
an IMU outperforms ICP in feature-deprived environments,
and Lisus et al.  implemented a continuous-time approach
with a white-noise-on-acceleration prior. In , the authors
extend the deep-learning-based preprocessing from  and
trained an additional network for per-scan velocity regression.
In contrast, our model-based approach does not require any
training data and does not suffer from any generalization
III. BACKGROUND
A. Gaussian process regression
Gaussian Process (GP) regression  is a probabilistic,
non-parametric interpolation method. Let us consider a sig-
nal h(x), with x RD, modeled with a GP h(x)
GP (0, k (x, x)). The function k (x, x) is the so-called co-
variance kernel that characterizes the covariance between two
instances of h (at x and x). Given noisy samples yi
h(x)  , with  N (0, ) and i  (1,    , N), GP
regression aims at inferring the signal h and its variance at
any new input location x. The definition of a GP corresponds
to the following multivariate normal distribution:
k (x, x)
Frequency
Sawtooth modulation
Triangular modulation
Velocity
Slope -s
up-chirp
down-chirp
Impact of different frequency modulation patterns (top) and Doppler
effect on the data collected with spinning FMCW radars (bottom).
where kxX  (kXx)
k (x, x1)
k (x, xN)
conditioning (1) with respect to the noisy observations we
obtain the inference of h at xas
h(x)  kxX
k (x, x) kxX
B. Radar data and Doppler effect
Let us consider the type of radars commonly used in
the automotive and robotic industries: Frequency-Modulated
Continuous-Wave (FMCW) radars. As their name suggests,
these radars are continuously emitting frequency-modulated
electromagnetic waves. Thus, instead of directly measuring the
time between the emission and reception of waves, the distance
to an electromagnetic reflector corresponds to a frequency
difference f between the signal transmitted and received. For
the sake of simplicity, the following explanation will consider
a single reflector at a certain distance r from the radar. In
many range bins along the emission beam.
Considering linear modulation of the frequency with a slope
s as shown in Fig. 2, the distance r between the radar and
reflector is
where c is the speed of light, and the divider 2 accounts
for the fact that f represents twice the distance r due
to the time for the wave to reach the reflector and return.
This relationship is only true (r  r) if the relative velocity
between the sensor and the reflector is null. In the presence
of relative motion, the measured f is impacted by the
Doppler effect that compresses or expands the electromagnetic
the shift corresponding to the waves travelling time, and
fd the Doppler-induced frequency shift. This shift fd is
proportional to the signal frequency
t and the velocity along
the emission beam, denoted radial velocity u, as
perturbed by the Doppler effect
r  rd(u).
When considering a frequency modulation with a sawtooth
pattern and multiple measurements of the same reflector, we
cannot dissociate ft and fd from f. However, if we use
a triangle pattern consisting of a succession of up-chirps and
down-chirps as illustrated in Fig. 2, two measurements of the
same reflector allow for the recovery of the radial velocity:
where the components in ft cancel out resulting in
r  rr 2uc
In reality, FMCW radars do not only expect one return
per beam but collect reflectivity information through a wide
range of discrete ranges through a fast-Fourier transform of
the received signal. Thus, the data from such radars can be
interpreted as intensityreflectivity images, in which rows cor-
respond to different beam azimuths and columns to different
ranges. Fig. 2 illustrates the effect of the Doppler effect on
FMCW data. The data collected with a moving radar using
a triangular pattern presents an alternating shift between each
row of the scans, while all the rows are shifted according to
the sign of the radial velocity for sawtooth radars. Depending
on the radar model, the modulation pattern can be changed
or not in the firmware. Thus, not all spinning FMCW radars
enable the extraction of Doppler-based velocities.
IV. METHOD
The proposed method addresses the issue of radar odometry
optionally aided by a gyroscope. The main concept is the direct
use of FMCW intensity data without any point cloud or feature
A. Problem statement and overview
Let us consider a 2D mmWave FMCW spinning radar and
a rigidly mounted gyroscope. Without loss of generality, the
extrinsic calibration (rotation matrix) between the two sensors
is assumed to be known and will not appear in the following
derivations. The gyroscope provides measurements i, at times
of the radar. The radar data is assumed to be collected in
scans covering the 360field-of-view. Each scan contains
information collected from N beams, each associated with
an azimuth n and timestamp tn, and each beam consists of
the electromagnetic reflection intensity nm at M different
ranges rm. Accordingly, a radar scan can be interpreted as a
polar intensity image or a set of tuples {n, rm, nm}.
The rotation, position, and velocity of the radar reference
frame with respect to an Earth-fixed frame are described with
continuous functions t R 7Rt
W SO(2), pt
W R2, respectively. The details of the various motion
models used to obtain Rt
W from a finite set
of state variables S will be discussed in Section IV-D. The
proposed method aims to estimate the state variables S, thus
the sensors trajectory, during the collection time of the last
radar scan using the radar intensity data and optionally the
angular velocity from the gyroscope. The estimation is done
with the numerical optimization of a combination of objective
functions as
S argmax
with O an objective function that relates to the direct
registration of the radar intensity data (cf., Section IV-B, and
Od to the Doppler effect (cf., Section IV-C). Fig. 3 provides
an overview of the proposed method. As detailed later in
this section, both O and Od can be interpreted as cross-
correlation scores between different parts of the present and
past radar data.
B. Direct intensity objective function
This objective function is inspired by direct methods in
traditional monocular state estimation. The goal is to estimate
the continuous pose of the sensor to registeralign the last
radar scan with past radar data. In this work, we opted for a
local map that is updated on-the-fly as a way to combine
past radar scans into a single image representation of the
sensors environment with intensity in Cartesian coordinates
(as opposed to raw radar data in polar coordinates). The
motivation for using a local map instead of solely the last
radar scan is the higher robustness to outliers such as moving
vehicles or multipath echoes.
1) Direct registration: Let us assume the availability of an
image-like local map M of the sensors environment expressed
in the radars reference frame at time t1. The rows and columns
of M image correspond to discrete Cartesian coordinates. The
function B(M, x, y) allows querying the local map intensity
for any x and y R with bilinear interpolation.
To compute the direct registration objective between the
incoming radar scan and the local map M, we need to correct
for the Doppler effect and the motion of the radar as
with rn the Doppler-induced shift (7) as a function of the
body-centric velocity and the beam azimuth:
The sign  is defined by the chirp direction for the azimuth
n. Please note that this objective function accounts for the
Doppler effect but does not require an FMCW radar with
a triangular pattern. Once the radar scan is corrected using
the current estimate of the trajectory, the objective function is
simply the cross-correlation score,
nmB(M, xnm, ynm),
between the corrected scan and the local map.
SE(2) continuous trajectory
2D spinning radar image
Yaw gyroscope
GP infill: up-chirp and
down-chirp image inference
(Fig. 4)
Orientation
preintegration
Continuous trajectory optimisation:
Doppler-based
velocity constraint
Direct intensity
registration
Local map update
Local map
Undistorted scan
Overview diagram of the proposed direct radar odometry method. To leverage the Doppler-based velocity constraint, the radar must use a triangular
frequency modulation pattern. Note that O accounts for motion and Doppler-induced distortion.
2) On-the-fly local map: The proposed local map consists
of an image-like representation of the past radar data using a
per-pixel low-pass filter to update M with the last radar scan
and the corresponding state estimate. Concretely, given the
convergence of the optimization problem (8), the radar scan
is corrected to the first timestamp of the following scan in
Cartesian coordinates (using (9) replacing Rtn
t1 and ptn
tN1 and ptn
converted into an image-structure I M with the help of bilinear
interpolation. Then the local map update is
M (1 )M  I M,
with  [0, 1] a user-defined parameter (  0.1 in our
implementation). Note that after receiving the very first radar
C. Doppler-based objective function
As presented in Section III-B, an FMCW radar using a
triangular modulation pattern (alternating up-chirp and down-
chirp for each collected beam) allows for observability of
the radial velocity along that beam if the consecutive beams
observe the same part of the environment. Unfortunately, this
is not quite true in the context of mobile radar sensing, since
the vehicle and the radar dish move in between consecutively
recorded returns. We propose to split the incoming radar
scan into two image-like structures based on chirp direction
and use GP regression (2) to infill the missing rows in
both images. This is illustrated in Fig. 4. We denote the up-
chirp and down-chirp infilled images as I {n, rm,
and I {n, rm,
nm}, respectively. Thanks to the GP
regression step, the part of the environment observed in each
row of I, be it observed or interpolated, is the same as in
the corresponding row of I.
We show in Fig. 5 that when the sensors are static, both
Iand Ioverlap well. However, the Doppler shift is clearly
visible in the difference between Iand Iwhen the sensors
move. The objective function Od aims to constrain the esti-
mated velocity v(t) using Iand I. First, we must compute
the range shift, with (10), between each row of the two
images as a function of the sensor velocity. Then, we define
the function L(I, n, r) that queries the intensity value of
Ifor any value of r R using linear interpolation for each of
the images row. The objective function is a cross-correlation
score between Iand the Doppler-rectified version of I:
nmL(I, n, rm  rn).
The objective function Od is maximised when the body-
centric velocity estimate R(tn)v(tn) corresponds to the
actual velocity of the sensor.
D. Motion models
In this section, we present different ways to obtain the
continuous trajectory functions Rt
W from the
state variables S. As Rt
W is in SO(2), the rotation can easily
be represented with a simple rotation angle (t) as
cos((t))
sin((t))
sin((t))
cos((t))
with Rt1
W being the starting rotation obtained from the state
estimate of the previous radar scan. We introduce two different
models to obtain (t) in Subsections IV-D1, and IV-D2.
Regarding the translation and velocity, we use a simple con-
stant body-centric velocity model in Subsection IV-D3. For
state variables, and vb the body-centric velocity.
1) Constant angular velocity: In the absence of a gyro-
constant angular velocity  for the duration of any radar
scan with (t)  (t t1). Therefore, the state variable is
2) Gyro preintegration: Inspired by , when using a
defined as a function of the angular rate measurements. To
account for the frequency discrepancy between the radar
azimuths and the gyroscope measurements, it leverages con-
tinuous preintegration concepts drawn from  and . For
the sake of simplicity and lightweight computation, we use a
simple piece-wise linear model
(t)  (ti)  (i1  i)(t ti)
2(ti1 ti)
i(t ti),
Raw radar data
GP-inferred image I
GP-inferred image I
Illustration of the proposed infilling. The raw Doppler distorted radar data (left) is split between up and down-chirp azimuths. Gaussian Process (GP)
regression is used to interpolate every second azimuth (middle two, the interpolated portion is in grey). Both Iand Ivirtually observe the same geometry
without assuming that two consecutive azimuths of the raw data observe the same part of the environment (right, with blue positive and red negative).
Raw radar scan
Up-image I(filtered)
Difference II
Illustration of the GP-based infill highlighting the Doppler effect on
radar data collected with a triangular frequency modulation pattern (the blue
arrow is the sensor velocity).
with i  i b, t [ti, ti1], We decided not to include the
gyroscope bias b in the estimated state. In our experiments,
biases range from 5e5 to 4e3 corresponding to a
maximum of 0.057drift over the 250 ms of a scan. With
the typical 0.9radar angular resolution, the signal-to-noise
ratio is too high to enable robust bias estimation in a frame-
to-frame approach like ours. This is especially true as the
proposed objective functions are not probabilistic, thus imped-
ing the integration of additional residualsobjective functions
from other modalities and the probabilistic priorprevious
knowledge of the bias. Accordingly, when using a gyroscope,
the rotational state is empty SR  . However, we use a
separate online bias estimation strategy based on a simple yet
effective heuristic: when the vehicles velocity is zero, so is
the angular rate. Accordingly, the bias estimate is initialized by
averaging the first Q raw gyroscope measurements collected
when the velocity estimate is under 5 cms. Then it is updated
with a low-pass filter whenever the velocity estimate is under
3) Constant body-centric velocity: This model assumes a
constant body-centric velocity vb R2 during any radar scan.
The velocity in the global frame is vt
W vb. The position
with pt1
W the position resulting from the state estimation during
the previous radar scan. The integral in (16) is computed
analytically when using the constant angular velocity assump-
tion. Otherwise, when using a gyroscope, it is numerically
preintegrated using a piece-wise linear model similar to (15)
upon each of the matrix elements.
V. EXPERIMENTS
A. Implementation
The proposed method has been implemented in Python
using PyTorch for matrix and algebra operations. Accordingly,
it can easily be run on either a GPU or a CPU. Note that
we have implemented (8) with analytical Jacobians and our
solver without relying on PyTorchs automatic differentiation
and integrated solvers. When using a gyroscope and the
Doppler-based velocity constraints, our method converges in
13.5 iterations on average.
1) Gaussian process regression: GP regression is known
to suffer cubic computational complexity due to the matrix
inversion in (2). With around 2 million points in each radar
the grid-pattern (image-like) nature of both the radar data
and the inference locations in the proposed GP-based infill
step. By only considering the data in a U  V neighbourhood
around each inference location, kxX
1 can be
precomputed and the multiplication with y is a simple con-
volution operation. Accordingly, with a GPU implementation,
the inference of Iand Iis extremely efficient.
Similarly to , each row of the GP-inferred image is
independently filtered to attenuate multipath and specular
noise. First, the intensity standard deviation is computed and
any range bin with a value inferior to twice the deviation
is nullified. Then the intensity values are normalized so
that the maximum value equals one. Per-azimuth Gaussian
blur is applied to smooth the discontinuities introduced in
the previous steps. Finally, each intensity value is cubed to
augment contrast.
2) Optimisation: The optimization problem (8) is solved
with a gradient ascent algorithm with an update step
S S  c (Od  O)
(Od  O),
Raw radar scan
Difference II
Vehicles in the opposite lane
Vehicles in the same lane
On-board camera view
Skyway ground view
Illustration of a challenging situation with a line of vehicles coming
the other way while driving over a skyway (very few static elements visible
in the radar data).
where is the gradient operator, and c is a constant equal to
0.1 at the start of the optimization and halved for every non-
ascending step. Note that the objective functions are element-
wise products of intensity values. Thus, the computations
linked to intensity values that are equal to zero do not
contribute to the optimization problem and can be omitted
to lower the computational burden.
3) Robust weighting: The proposed objective functions Od
and O are generally robust to outliers such as moving
vehicles and specular noise. However, in very rare occasions (2
frames among 42k in our automotive experiments), a very high
proportion of consistent outliers can lead to erroneous state
estimates. A typical example is illustrated in Fig. 6 when the
sensing platform is moving over a bridgeskyway with a very
small amount of static reflectors in the surroundings, and a line
of vehicles comes the other way. It can make the velocity esti-
mate suddenly jump unrealistically. Such scenarios are easily
detected with a simple threshold on the sensors acceleration
from one scan estimate to the next. When detected, we re-run
the optimization weighting the objective functions O and Od
nmnm(, , ),
with   d or . Intuitively, the weighting  acts as an
outlier-rejection mechanism by down-weighting the objective
components that are too dissimilar in terms of intensity.
4) Velocity bias in Doppler constraint: Similarly to ,
we have empirically observed a velocity bias when performing
Doppler-only velocity estimation. This bias mostly concerns
the lateral velocity of the sensing platform. We believe this
bias is partly explained by the disparity between the actual
measurement process and the simple measurement model that
assumes the information contained in a row of the radar
data corresponds to a single azimuthtimestamp: in reality,
the radars scanning pattern is continuous. Thus, every mea-
surement from a row could correspond to a different azimuth
and timestamp. We think that the motion models inaccuracy
leads to a velocity bias that appears as environment-dependent
due to the ignored correlation between the data range and
azimuthtimestamp. The authors of  addressed this issue by
fitting a linear model to the velocity error using held-out data
with accurate velocity ground-truth. Then, the linear model is
used to correct the velocity estimates directly. In this work,
we propose to leverage the non-slip kinematics constraint to
estimate and compensate for the lateral component of the
velocity bias online without a calibration phase.
Using the angular rate and the extrinsic calibration between
the radar and the vehicles rear axle, the velocity estimated
based solely on the Doppler-based constraint Od is projected
into the axle reference frame. The y component is projected
back to the radar frame to update a low-pass filter that tracks
the lateral velocity bias. The filters output is then used to
correct the radial velocities when computing the shifts (10) for
Doppler distortion correction. This estimation and correction
process is only applied when Od is part of the optimization
problem (8). It is important to note that this mechanism
does not strictly enforce the non-slip constraint thanks to the
low-pass filter. Accordingly, the vehicle can be subject to
momentary side slips without altering the state estimates.
B. Metrics
To benchmark our algorithm, we use well-established met-
rics in the odometry literature. For datasets with ground-truth
are adopted. Succinctly, for one pose estimate, the estimated
trajectory is aligned with the ground-truth. Then, after a certain
distance travelled from the aligned poses (segments varying
from 100 to 800 m), the estimated and ground-truth poses are
used to compute position and orientation errors relative to the
segment lengths. This process is repeated every 5 poses of the
estimated trajectory and the results are reported as the average
relative errors in  and 100 m. In the absence of ground-
truth orientation, we adapted the Relative Position Error (RPE)
introduced in  to SE(2) trajectories. It corresponds to the
position Root Mean Squared Error (RMSE) between aligned
segments of the ground-truth and the estimated trajectory. The
length of segments [50 m, 100 m, 150 m, 200 m]. Similarly to
the KITTI metric, we display the RMSE error as a percentage
of the segment lengths.
C. Doppler-enabled automotive odometry
In this section, we provide a detailed analysis of our
methods performance on a dataset collected with our auto-
motive sensing platform. Note that the radar used in this set
of experiments uses a triangular frequency modulation pattern,
thus enabling the use of the Doppler-based velocity constraints
Od in (8).
1) Dataset description: The goal of this set-up is to repli-
cate experiments from . To do so, we have collected
data with an automotive platform equipped with a Navtech
RAS6 radar, a Silicon Sensing DMU41 Inertial Measurement
Unit (IMU), a Velodyne Alpha Prime lidar, and an accurate
Applanix RTK-GNSSINS solution for ground-truth with post-
processing. All the sensors have been accurately synchronized.
The data used for benchmarking has been collected repeatedly
four times along four routes (16 sequences in total) displaying
an increasing level of difficulty: Suburbs, Highway, Tunnel,
and Skyway. The first two environments provide a relatively
large amount of geometric constraints via the presence of many
buildings and other human-made structures in the vehicles
surroundings. In Tunnel and Skyway, the geometric features
are either degenerate (not constraining all the movements
axes) or close to nonexistent, respectively. In these scenarios,
only Doppler-induced information can lead to usable odometry
performances. The skyway scenario is especially challenging
as for a couple of kilometres the radar does not observe any
significant static features except for sparse lamp posts and
weak returns from the side barriers (the radar is mounted
on the top of the vehicle and the barriers are relatively
barriers). Accordingly, the ratio of moving to static elements
in the radars FoV is very high. The length and velocity
characteristics of each sequence type are given in Table I
along with the results discussed later in Section V-C3. Fig. 1
(left) shows our collection vehicle while recording a Tunnel
sequence.
2) Baselines: To benchmark the proposed algorithm, we
have replicated four baselines from  and , three based
on radar data and one on lidar. The first baseline, denoted
available teach and repeat framework . It consists of an
ICP-based continuous-time scan registration using point clouds
extracted from the raw radar data. The trajectory estimates
are computed via a sliding window optimization based on a
continuous-time GP state representation. Note that the velocity
estimates are used to compensate for the Doppler-induced shift
of the radar points. The second baseline is DG and replicates
the work from  on per-azimuth radial velocity extraction,
followed by a RANSAC-based outlier rejection and robust
optimization. With the constant-velocity assumption, it allows
for the estimation of the vehicles velocity for each radar
scan. Combined with the gyroscopes angular rate, it enables
association-free radar odometry, even in geometrically feature-
deprived environments. Despite not extracting any point cloud
out of the radar data, one can consider the radial velocity as
features extracted in a front-end before an optimization-
based state estimation step. Third is CT-RDG, the integration
of the per-scan velocity estimates from  and the gyroscope
measurements within CT-R. Finally, the lidar baseline denoted
CT-LG consists of the continuous-time ICP from  with
additional gyroscope constraints. The various parameters of
the baseline, as well as the radar-specific value of , have
been tuned using an extra sequence of each type.
3) Results: Table I shows the average odometry error
(KITTI metrics) obtained with each baseline and our algorithm
in the four environments. While a thorough ablation study is
conducted in the following subsection, here, we consider three
variations of DRO that all rely on the gyroscope integration
for the orientation estimation. The first variant, denoted DRO-
estimate the linear dynamics of the system. The second one,
O. Note that DRO-G still leverages Doppler compensation of
the radar data as part of O. Ultimately, DRO-GD combines
both Od and O as presented in (8).
radar methods. While the performance gap between DRO-GD
and DRO-G is minimal in the well-structured suburban envi-
challenging. The best radar baseline, CT-RDG, shows errors
around twice as large as ours throughout all the sequences
When considering Doppler-only approaches, DG  and
DRO-D perform similarly in Suburbs and Highway. In the
more challenging environments, DRO-D displays a noticeable
advantage. All these observations suggest that the direct nature
of the proposed approach (considering all the radar informa-
tion in a single optimization without any feature extraction)
and our novel GP-based infill for Doppler data provide a
greater level of robustness. Without the Doppler-based velocity
challenging scenarios, similar to CT-R. Despite not completely
failing on all the Tunnel sequences (3 out of 4 runs present a
translation error under 2.5), the Doppler-compensation that
happens in O is not sufficient for robust estimation in feature-
deprived environments. Only the lidar baseline outperforms
DRO-G in some feature-dense environments (Suburbs). How-
(Tunnel and Skyway) while DRO-GD keeps a similar level of
performance.
Visualizations of the raw data, velocity estimate and local
map are provided in the supplementary materials. Fig. 7 pro-
vides a sample of the estimated trajectories for each sequence
type. It is interesting to note that despite relatively similar
KITTI metrics, CT-RDG and DRO-DG result in fairly different
truth. Part of the explanation is that the KITTI metrics only
consider segments up to 800 m where the small orientation
drift of CT-RDG has a weak impact on the position at the end
of each segment. However, along the full trajectory length,
the orientation drift leads to large position errors that are
visually noticeable. This observation supports the fact that
for kilometre-long odometry, the direct integration of the
gyroscope data can provide better orientation estimates than
SOTA odometry.
4) Ablation study: We have conducted a thorough ablation
study to determine which of the presented mechanisms impacts
the algorithms accuracy the most. Due to the extremely
AVERAGE RELATIVE POSE ACCURACY OF THE PROPOSED METHOD AND SEVERAL BASELINES ON OUR DATASET (BEST RADAR-BASED METHOD IN BOLD).
Sequence type (length, avg.  max. vel.)
DRO-D (ours)
DRO-G (ours)
Suburbs (4  7.9 km, 8.1  18.6 ms)
Highway (4  9.3 km, 11.1  27.0 ms)
Tunnel (4  1.9 km, 8.9  28.2 ms)
KITTI odometry metric reported as XX  YY with XX [] and YY [100 m] the translation and orientation errors, respectively.
Groundtruth
Sequence Start
Sequence End
Groundtruth
Sequence Start
Sequence End
Groundtruth
Sequence Start
Sequence End
Groundtruth
Sequence Start
Sequence End
(a) Suburbs
(b) Highway
(c) Tunnel
(d) Skyway
Trajectory estimate samples for the different sequence types.
TABLE II
POSE ACCURACY ABLATION STUDY: EACH ROW CORRESPONDS TO A
MARGINAL DIFFERENCE WITH DRO-GD.
Vel. er.
DRO-GD (ours)
No gyr. bias
No vel. bias
No local map
No gyroscope
KITTI odometry metric reported as XX  YY with XX []
and YY [100 m] the trans. and rot. errors, respectively.
Avg RMSE
challenging nature of the Skyway sequences, we have chosen
to leave them out of this study, as other factors, such as
the high proportion of outliers, can have a greater impact
on the results. Table (II) shows the relative pose error of
the proposed DRO-GD when various elements are removed
from the pipeline. For the no local map row, DRO-GD
is run replacing the proposed local map updated on the fly
with simply the last motion and Doppler-corrected scan. As
performance degradation, leading to accuracy slightly better
than CT-R in Table I (also without a gyroscope) for feature-
dense environments. Estimating the systems orientation in a
continuous manner using only radar data is challenging due to
the low angular resolution of the sensor (0.9) and the beam
width (1.8), even when leveraging a motion prior like CT-
R. Interestingly, in more challenging scenarios like the Tunnel
as for CT-R thanks to the proposed Doppler-based velocity
constraint. Regardless, the velocity RMSE is not significantly
impacted by the absence of a gyroscope. As for the other
In Fig. 8 we study the sensitivity of DRO-GD with respect
to the  parameter used in the local map update. One can
see that the methods accuracy is not very sensitive to . We
also analyze the estimated side velocity bias and empirical
evidence that, given the assumption made in our formulation, it
depends on the observed environment in Appendix B. Overall,
this ablation study demonstrates that the proposed direct radar
registration is sound and robust.
D. Public automotive benchmarks
We have benchmarked the proposed method against state-
of-the-art frameworks over the Boreas and MulRan datasets.
In both cases, the radar uses a sawtooth modulation pattern.
Doppler-based objective function Od.
2For the gyroscope-less operation, we correct the estimated state with an
angular velocity bias calibrated using held-off data (0.034s for Suburbs
and Highway, and 0.057s for Tunnel). We have also applied the robust
weighting when the change in orientation between consecutive scans is not
realistic. Without the bias correction, we obtain relative translation errors of
1.37, 1.61, and 3.67 for Suburbs, Highway, and Tunnel, respectively.
Mean translation error []
Sensitivity analysis of DRO-GD with respect to the local map update
parameter .
1) Boreas dataset: The Boreas dataset  was collected
by driving a vehicle equipped with a sensor suite composed
of a 3D lidar, a 2D spinning radar (sawtooth pattern), a front-
facing camera, and an RTK-GNSSINS solution for ground-
truthing. The dataset consists of 44 sequences collected over
one year along more than 350 km of roads in Toronto, Canada.
ditions ranging from clear summer sky to heavy snow and
rain. A specificity of Boreas is that most sequences follow a
unique route in a suburban environment, allowing one to test
an algorithms robustness with respect to changing conditions.
The Boreas dataset also offers a leaderboard for odometry
benchmarking that leverages 13 of the sequences above. Note
that the GNSSINS ground-truth is not publicly available for
these sequences.
After testing our algorithm on 6 sequences with ground-
G. Our algorithm significantly outperforms all the other
methods. We have reported the four best radar-based meth-
ods in Table III. The core principle of CFEAR  and
STEAM-RIO  is similar as both methods extract a
point cloud from the incoming radar data before performing
registration to multiple previous scans. A difference is that
CFEAR first performs motion distortion correction based on
the previous estimate and uses point-to-distribution residuals,
while STEAM-RIO leverages a GP motion prior, point-to-
point constraints and IMU data. CFEAR  builds atop
CFEAR by embedding the use of the IMU and some semantic
information.
Our results confirm the ability of DRO-G to provide state-
of-the-art performances without requiring a radar with a trian-
gular modulation pattern and Od as long as the environment
contains sufficient geometric cues. In Appendix A, we provide
a table that details the error obtained for each of the 13
sequences. As expected, there seems to be no correlation
between the weather conditions and the translation error. An
interesting observation is that the orientation estimates of
DRO-G using solely the gyroscope integration outperform
the other inertial-aided methods. This means that the radar
constraints in CFEAR and STEAM-RIO play a negative
role on the orientation estimates.
2) MulRan dataset: The MulRan dataset  has been
recorded with a lidar, 2D spinning radar, and an IMU mounted
atop a car while driving in 4 different locations in Daejeon
TABLE III
BOREAS DATASET SE(2) ODOMETRY LEADERBOARD.
Trans. err. []
Rot. err. [100m]
DRO-G (ours)
STEAM-RIO
and Sejong, South Korea. This dataset originally targeted
the task of place recognition, but the availability of a 6-
DoF trajectory ground-truth also enables the benchmarking
of odometry and SLAM algorithms. However, unlike in the
previous experiments, the ground-truth is not obtained with
an RTK-GNSS but via the optimization of a pose graph that
leverages wheel odometry, an optical-fibre gyroscope, and a
VRS-GPS. Additionally, the quality of the IMU is significantly
lower than in the Boreas and our automotive datasets.
Table IV shows the KITTI odometry errors of the proposed
method and variations of CFEAR as reported in . As
introduced in the previous subsection, CFEAR relies on a scan-
to-local-keyframes registration. C-FEAR-3 and C-FEAR-3-50
refer to  using a different number of past keyframes in the
registration process: 4 and 50, respectively. The table shows
the ability of DRO-G to outperform SOTA methods even with
a low quality IMU. The level of rotational accuracy highlights
the soundness of the proposed integration-only orientation and
reiterates the observation from the Boreas leaderboard that
radar data can have a detrimental impact on the systems
rotation estimate compared to pure integration and a simplistic
bias estimation strategy.
significantly larger with MulRan data than with the Boreas
dataset. We believe that the nature of the ground-truth gen-
eration process leads to noisier poses, but also that extrinsic
calibration and synchronization are suboptimal. For example,
we observed that the difference between consecutive IMU
data timestamps presents a variation of 35 around the
nominal period of 10 ms and that there is a constant offset
with respect to the other sensors. In our experiments, we
corrected the IMU synchronization by removing 50ms to each
inertial timestamp of all sequences. We also adjusted the radar
heading by 0.172(without the heading correction DRO-G
leads to errors of 1.46 and 0.38100m). For completeness,
without the gyroscope bias estimation, we obtain errors of
6.00 and 1.57100m on average. Due to the lower quality
of the dataset, we believe no strong conclusion can be drawn
from this experiment other than the demonstration that DRO-
G does not require a high-end gyroscope to perform at the
level of SOTA methods.
E. Off-road navigation
To demonstrate the versatility of the proposed method, we
collected a series of radar-inertial data sequences with an off-
road mobile robot.
TABLE IV
AVERAGE ERROR PER SEQUENCE TYPE OF THE MULRAN DATASET.
Sequences
CFEAR-3-50
DRO-G (ours)
Riverside
KITTI odometry metric reported as XX  YY with XX []
and YY [100 m] the translation and orientation errors, respectively.
1) Dataset description: Our off-road dataset comprises 16
test sequences divided into four locations ranging progres-
sively from highly structured to unstructured environments.
The robots maximum velocity is approximately 1.2 ms. The
sensor suite comprises a Navtech RAS3 radar and an Ouster
lidar with its embedded IMU. The robot is driven over the
same loop three or four times for each environment. The
easiest one, Parking, takes place in a parking 
