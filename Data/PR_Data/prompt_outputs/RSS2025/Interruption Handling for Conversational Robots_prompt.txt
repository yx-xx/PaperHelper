=== PDF文件: Interruption Handling for Conversational Robots.pdf ===
=== 时间: 2025-07-21 13:49:06.642117 ===

请从以下论文内容中，按如下JSON格式严格输出（所有字段都要有，关键词字段请只输出一个中文关键词，要中文关键词）：
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Interruption Handling for Conversational Robots
Shiye Cao1, Jiwon Moon1, Amama Mahmood1, Victor Nikhil Antony1,
Ziang Xiao1, Anqi Liu1, and Chien-Ming Huang1
Equal Contribution 1 Johns Hopkins University, Baltimore, Maryland, 21218, USA
{scao14, jmoon47, amama.mahmood, vantony1, ziang.xiao, aliu.cs, chienming.huang}jhu.edu
Cooperative agreement
How about a ashlight next?
It provides 24-hour signaling capability
and can be used for various purposes.
Participant clicked to add overcoat to the list
it might be challenging to use
effectively.
[I still think a]
navigate at night. It requires some
knowledge of constellations...
Cooperative clarication
Disruptive interruption
can also be used as a signaling item,
since the sound is very large, and I
think it'll do way better than the
cosmetic mirror.
taking a break and shifting our focus
can do wonders for our mood...
We present an interruption handling system that classies user-initiated interruptions into 1) cooperative agreement, 2) cooperative assistance, 3)
cooperative clarication, and 4) disruptive interruption and adapts different strategies to handle the interruptions accordingly. This gure illustrates how the
system responded to three user-initiated interruptions using different handling strategies (see Fig. 3 for details). We highlight overlapping speech in blue. R
denotes robot and P denotes participant. Participants consent was obtained for images in this publication.
involved. Despite advancements in robotic systems, state-of-the-
art systems still have limited capabilities in handling user-
initiated interruptions in real-time. Prior research has primarily
focused on post hoc analysis of interruptions. To address this
and manages them in real-time based on the interrupters intent
(i.e., cooperative agreement, cooperative assistance, cooperative
signed based on interaction patterns identied from human-
human interaction data. We integrated our system into an LLM-
powered social robot and validated its effectiveness through a
timed decision-making task and a contentious discussion task
with 21 participants. Our system successfully handled 93.69
(n104111) of user-initiated interruptions. We discuss our learn-
ings and their implications for designing interruption-handling
behaviors in conversational robots.
I. INTRODUCTION
Robots are envisioned to become assistants, teammates, and
companions in peoples everyday lives, capable of taking on
complex social and physical tasks. To achieve effective and
intuitive human-robot interaction (HRI), it is crucial that robots
possess natural conversation capabilities .
Interruptionsoccurring when a listener attempts to take
the oor before the speakers utterance is completeare a fun-
damental aspect of human communication . Interruptions
can be used to signal understanding (cooperative agreement),
assist the speaker (cooperative assistance), seek clarication
when needed (cooperative clarication), or express disagree-
ment and shift the topic (disruptive) , leading to more
uid and fast-paced conversations when effectively used and
handled. However, interruptions can disrupt the ow of the
and the interrupter feeling excluded if addressed inadequately.
and manage interruptions on-the-y .
Humans are naturally adept at handling interruptions, but
state-of-the-art conversational robots, which have only recently
shifted from scripted to more natural interactions, still lack
the ability to handle user-initiated interruptions effectively.
Existing spoken dialogue systems mostly rely on explicit turn-
taking signaling (e.g., push-to-talk mechanism  and wake-
words ) to detect user-initiated interruptions. Moreover,
existing systems are designed to always yield the speaker
turn immediately after an interruption is detected . Previous
work emphasizes the importance of classifying the intent of
the interrupter to enable the system to respond accordingly to
the interruption to allow more natural and uid conversations
[24, 19]. Towards this goal, studies have explored the use of
multi-modal inputs (i.e., , acoustic features, facial expressions,
and head movements) to classify interruptions as either co-
operative or disruptive during post hoc analysis of human-
human conversation data . However, to the best of our
classication into its interruption-handling framework, and
little work has explored how conversational robots should
manage different types of interruptions. When should robots
yield to users? When should robots hold their turn?
As a rst step towards answering these questions, in this
interaction patterns identied from human-human interaction
data. We integrated our interruption handling system into a
social robot and showed that our system can successfully
handle 93.69 of user-initiated interruptions (e.g., Fig. 1) in
timed decision-making and contentious discussion tasks.
II. RELATED WORK
A. Interruptions in Human-Human Interaction
Interruptions occur when a listener tries to take the oor
before the speakers utterance is complete . They are a com-
mon aspect of human conversations and can occur more than
once per minute in dyadic  and group conversations .
While most interruptions involve overlapping speech, brief
overlapping speech that does not purloin the speakers oor
such as during speaker exchanges  or verbal backchannels
(conversation continuers signaling attention, understanding,
and agreement, such as uh-huh or yeah) is not
considered an interruption. Interruptions can be categorized
as cooperative or disruptive based on the intention of the
interrupter . Cooperative interruptions are intended to aid
the completion of the current turn by expressing concurrence
or understanding (cooperative agreement), providing a word
or idea that the speaker may need (cooperative assistance), or
asking the speaker to clarify or elaborate on previous informa-
tion (cooperative clarication) . Disruptive interruptions
occur when the listener challenges the speakers control and
disrupts the conversational ow to express an opposing opinion
(disagreement), further develop the current topic (oor taking),
change the subject (topic change), or summarize the speakers
point to end the turn and avoid unwanted information (tangen-
tialization) . Prior work found that the type and frequency
of interruptions are shaped by the conversational and power
dynamics of interaction . However, limited work inves-
tigated how humans handle interruptions in conversations.
with varying power dynamics between speakers to understand
how people handle different types of interruptions.
B. Interruptions in Human-Agent Interaction
Existing conversational robots have very limited capabilities
in handling interruptions. Many systems ignore overlapping
speech altogether (e.g., ), while others treat any overlapping
speech as interruption (e.g., ) or rely on designed explicit
turn-taking signaling (e.g., user touches the robots head )
to detect user-initiated interruptions. Popular commercial voice
assistants take a step further by relying on wakewords (e.g.,
Alexa) to detect user-initiated interruptions . However,
these approaches remain error-prone due to their rigidity (may
mistake ambient microphone noise as interruption  and rely
on users to remember the wakeword ), and are unnatural
in human conversations. Recent advances, such as Alexas
follow-up mode and Siris ability to handle back-to-back
the uidity of the conversation. However, these systems still
struggle with managing complex, multi-turn interruptions ,
yielding the oor to all interruptions equally without assessing
intent. Prior work in human-agent interaction recommended
distinguishing between cooperative and disruptive interrup-
tions to help determine how the agent should deal with the
interruption . Multi-modal features (i.e., acoustic proles,
head activity, gaze behavior, lexical features, and facial expres-
sions) have been used to automatically classify interruptions as
cooperative or competitive . However, prior efforts for han-
dling these cooperative and disruptive interruptions have been
limited to post hoc evaluation of a dataset ; to the best of
our knowledge, no existing conversational agent has the ability
to handle user-initiated interruptions based on the context of
the interruption in real-time. In this work, we leverage natural
language understanding capabilities of large language models
(LLMs) to classify and handle user-initiated interruptions in
real-time. By categorizing interruptions into four ner-grained
categoriescooperative agreement, assistance, clarication,
and disruptiveour system tailors handling strategies to match
the context and user intention behind the interruption.
III. INTERRUPTION HANDLING IN HUMAN INTERACTION
In HRI, robot behaviors are often designed based on human
behavior patterns observed in human-human interaction (e.g.,
[2, 11]), as this can make robot behavior feel more natural and
align better with user expectations. However, there is limited
prior research on interruption handling in both human-robot
and human-human interaction, providing little guidance for
designing conversational robots. To address this, we analyzed
natural human conversations to identify human behavior pat-
terns when handling interruptions.
A. Human Conversational Data
As the frequency and type of interruption correlate with
power dynamics in conversations , we selected the top ve
YouTube videos for three categories of conversations with
varying power dynamics, ltered by view count and duration
(420 minutes), resulting in 246 interruptions.
Discussions (nD
106 interruptions) represent casual
settings with no clear power dynamics. We analyzed two
dyadic conversations and three multi-party discussions.
Talk show interviews (nT  122 interruptions) represent
casual settings with moderate power dynamics, exemplied
by clips from The Tonight Show Starring Jimmy Fallon.
While the interviewer can control the conversation, they
typically refrain due to the low-stakes nature.
Press briengs (nP  18 interruptions) featuring former
U.S. White House press secretary Jen Psaki are high-
stakes settings where the speaker holds signicant power,
controlling the narrative.
Handling Strategies
Interruption
Cooperative
agreement
Hold floor
Cooperative
assistance
Cooperative
clarification
Disruptive
interruption
Interaction patterns of interruption handling in human conversations.
The highlighted strategies were implemented in our system (Fig. 3). Ack
denotes acknowledge and Cont. denotes continue.
B. Analysis
Informed by the taxonomy of interruption types from prior
work and research highlighting the need to tailor interruption
handling to the intention (type) of the interruption (detailed
in Section II-A), we coded the videos for 1) intention of the
interruptereither cooperative (i.e., agreement, assistance, or
clarication) or disruptiveand 2) the strategy individuals use
to manage interruptionsyield or hold the oor. Our goal
was to identify interaction patterns that reveal how humans
handle different types of interruptions. Interaction patterns
were created based on the sequence of these two states.
One coder transcribed and coded the interruptions, while a
secondary coder independently coded 10 to assess inter-
coder reliability (Cohens Kappa  1).
C. Interaction Patterns
We identied the following interaction patterns (Fig. 2):
1) Cooperative: agreement hold oor: When speakers
encountered cooperative agreement, they typically acknowl-
edged the interruption and continued speaking (nD  26,
nT  48, nP  2). A deviation from this pattern was noted
in only one case, where the speaker yielded the oor to the
interrupter upon agreement during a discussion (nD  1).
2) Cooperative: assistance hold oor: When the inter-
rupter offered assistance, the speaker typically acknowledged
words), then resumed speaking (nD  7, nT
deviation occurred a few times, where the speaker yielded the
oor to the interrupter (nD  4, nT  2).
3) Cooperative: clarication hold oor or yield: When
the interrupter sought clarication, the speaker typically ac-
knowledged the question, paused for the interrupter to nish,
nT  8, nP  1). However, in contentious discussions, the
speaker sometimes yielded the oor (nD  3, nP  1), show-
ing that clarifying questions can be used to assert alternative
points and take control of the oor from the speaker.
4) Disruptivehold oor or yield: Disruptive interrup-
tions were the most common (130 of 246) and showed
different patterns across tasks. Speakers either held the oor
(nD  19, nT  37, nP  7) or yielded it (nD  41,
7). In debates, speakers often yielded
due to the polarized nature of the discussions, while in less
polarized settings (talk shows) they typically held the oor,
where disruptive interruptions can be more acceptable.
We identied three strategies speakers used to hold the
acknowledge the interruption while implicitly signaling intent
to retain oor by repeating a few words spoken at the time
of interruption and continue speaking, and 3) explicitly state
intent to continue (e.g., Let me nish my thought) and
then continue speaking. The rst two strategies were more
common for mild interruptions later in the speakers turn, after
part of their message had been conveyed. The third strategy
was used by the speaker to defend their turn from more
aggressive disruptive interruptions (e.g., disruptive interruption
early in their turn or repeated interruption attempts). In multi-
party discussions, other participants sometimes intervened to
protect the speakers turn during such aggressive interruptions.
Speaker acknowledgments to interruptions were mostly non-
verbal (i.e., nods and mutual gaze). Verbal acknowledgements
(e.g., sure or yeah) occurred in only 13 cases. Similar to
prior work , speakers averted gaze to hold oor, and held
prolonged mutual gaze until interrupter took over to yield oor.
We used these interaction patterns to guide the design of
our interruption handling system for conversational robots.
IV. INTERRUPTION HANDLING SYSTEM FOR
CONVERSATIONAL ROBOTS
Our interruption handling system has three main modules:
interruption detection, intent classication, and interruption
handling. Fig. 3 illustrates how user input ows through
it. We provide an example implementation of our system
integrated into an LLM-powered social robot built on Platform
for Situation Intelligence (psi) 1.
A. User-Initiated Interruptions Detection
We detect interruptions by monitoring for simultaneous
speech. As overlapping speech towards the end of turn is
common during speaker oor exchanges and is not considered
an interruption . So, if at the time of the overlapping
speech left, the system simply ignores it and nish-up (Line
4 ). Verbal backchannels are also not considered interruptions;
interruption (e.g., No) requires identifying the intent of the
1 Supplemental materials (contains additional implementation details):
Is robot
talking?
talking?
Is robot
left < 2 s
classification
immediately
finish-up
Generate
behavior
behavior
Generate
behavior
Generate
behavior
since start
of robot turn
1 or 2 words
Disruptive
interruption
yield immediately
Generate
behavior
ack and wrap-up
Summarize
behavior
Cooperative
agreement
continue
behavior
ack and continue
behavior
Cooperative
assistance
ack and continue
behavior
Cooperative
clarification
to clarifying
question
behavior
clarify and continue
Metro-map-inspired diagram of the interruption handling system, illustrating how user speech ows through the interruption detection, intent
overlapping speech between the user and the robot. We use Line <color> to refer to different interruption handling paths in the gure. Ack denotes
acknowledge and Cont. denotes continue.
dictability in human-agent interactions than human-human
triggered interruptions. When wakeword (i.e., the robots
name) or stop is heard as overlapping speech, the system
always yield immediately (Line 4 ).
B. Interrupter Intention Classication
In human communication, the speakers choice of inter-
ruption handling strategy depends on the intention of the
interrupter. So, we prompt-engineered a large language model
(GPT-4o-mini) to classify the intention of the interrupter into
cooperative agreement (includes backchannels), cooperative
given the conversational history and the amount of time
elapsed in the turn since the robot started talking.
Both backchannels and cooperative agreements are used to
support the speaker by expressing attention, understanding,
and agreement. In this work, we differentiate them by overlap
C. Interruption Handling
Following the interaction patterns identied in Section II-B,
the system adopts different interruption handling strategies
based on the predicted intention of the interrupter:
Cooperative Agreement: If the cooperative agreement is
only one or two words, it is likely a verbal backchannel,
which the system disregards it and continues with the
remaining planned content from the last punctuation mark
(continue, Line 4 ). If the cooperative agreement contains
more than two words, the system acknowledges verbally
(with ya, yes, uhhum, or sure), nods, and then
continues with the remaining planned content (ack and
Cooperative Assistance: The system acknowledges ver-
bally (with yeah, yes, or thanks), nods, and continues
with the remaining planned content from the last punctuation
mark. (ack and continue, Line 4 ).
Cooperative Clarication: Cooperative clarications are
handled by an LLM prompted to address the clarication
requested and then continue with the remaining previously
planned content (clarify and continue, Line 4 ).
Disruptive Interruption: Disruptive interruptions occurring
within 5 seconds of the robot starting to speak are consid-
ered aggressive disruptive interruptions by our system. In
such cases, an LLM is prompted to generate behavior for
the robot to express its intent to maintain the turn (e.g., Let
me nish my thought in Fig. 1), provide a summary of the
remaining content, and then yield (ack and wrap-up, Line
4 ). For milder disruptive interruptions, the system yields
the oor immediately and a new robot response is generated
based on the content of the interruption (yield immediately,
Line 4 ).
V. EVALUATION STUDY: METHODOLOGY
We conducted a user study to validate our system by inte-
grating the interruption handling system into an LLM-powered
social robot. We implemented basic social robot interaction
behavior by hand-crafting a bank of facial expressions (happy,
positions (left gaze, right gaze, look at screen, left nod, right
LLM (GPT-4o-2024-05-13) to generate contextualized robot
speech and select tting facial expressions, head movements,
and task actions (additional details provided in supplemental
materials1 Section II).
A. Inducing User-Initiated Interruptions
To encourage user-initiated interruptions, we made the fol-
lowing design choices in our implementation:
1) Task: We contextualized our system in a timed decision-
making and a contentious discussion task, anticipating
that time pressure and controversy can encourage inter-
ruptions. In the decision-making task, participants had ve
minutes to select seven out of fteen items to help them
survive in a desert survival simulation. The robot was
instructed to persuade, rather than simply agree, with users.
A countdown timer was shown to add time pressure. In the
discussion task, participants prepared for a 2-minute pre-
sentation on whether the federal government should abolish
capital punishment. The robot remained neutral until the
participant clearly stated their position, at which point it
adopted an opposing stance to encourage consideration of
alternative perspective.
2) Robot persona: We designed the robot to have a feminine
name (Luna), a feminine voice (Google en-US-Standard-
H), gaze aversion while it is talking, and generally positive
facial expressions (see supplemental materials1 Fig. 1).
Prior research highlights that gender signicantly affects
interruption patterns; women are more likely to be inter-
rupted than men, particularly when they avoid direct eye
contact with their conversation partners . Additionally,
women tend to smile more during conversations, which has
been linked to a higher likelihood of being interrupted .
3) Pre-programmed events: We designed two pre-programmed
events 1 per task where the robot holds the oor for roughly
one minute to provoke user-initiated interruptions. In event
introduces itself and provides disclaimers. In event two,
triggered 3.5 minutes into the discussion, the robot tells an
unrelated fun story or facts.
B. Study Procedure
We set up two cameras to record the participants interac-
tions with the robot from both the front-view and back-view
during the study (see Fig. 4). After providing consent, par-
ticipants completed a demographic questionnaire and watched
a 1-minute sample interaction video. They then engaged in
a practice task, designed to familiarize them with the robot,
answering four factual questions about space exploration.
Following the practice task, participants completed two tasks
(in random order) and completed a post-task questionnaire
after each task. The study concluded with a semi-structured
interview aimed to understand their overall experience working
with the robot and to collect feedback on robot interruption
handling.
C. Participants
We recruited 21 participants (11 female, 10 male), aged
18 to 30 (M22.38, SD3.58), through convenience sam-
pling from the local community via electronic newsletters
and mailing lists. Most participants had limited experience
using speech-based AI technology (M2.81, SD1.25, Min1,
5 being extensive experience) and reported that they have
only used it for simple commands, i.e., setting alarms and
checking the weather. The study took roughly 45 minutes, and
participants were compensated at 15.00 per hour. The study
was approved by our institutional review board (IRB).
D. Metrics
We constructed two subjective scales (see supplemental ma-
terials1 Section III for details) from the post-task questionnaire
to explore how interruption handling might affect the users:
Perceived inclusion in discussion (rating scale 15): Three-
item scale (Cronbachs   .78) measuring how heard,
Overall satisfaction with discussion (rating scale 15): Nine-
item scale (Cronbachs   .77) assessing users enjoyment,
willingness to engage in future discussions.
E. Coding
One coder transcribed all interactions and extracted con-
versation snippets with overlapping speech. For ground truth
and ne-grained understanding of interruptions, two coders
independently analyzed 100 of the interruptions, classifying
them by type (disruptive, cooperative agreement, assistance,
or clarication) and by attributes such as statement (opinion
or non-opinion), question (opinion or factual), or verbal back-
fully addressed, meaning that the robot effectively responded
to the interrupter without causing a conversation breakdown.
Cohens kappa was 0.92, and coders resolved conicts through
discussion.
VI. EVALUATION STUDY: FINDINGS
We identied 121 user-initiated interruptions from 206.59
minutes of interaction data (e.g., Fig. 4) involving 525 user
query-robot response pairs, or turns (decision-making: 312
some people argue that knowing
the perpetrator has been executed
can bring a sense of finality and
justice. They believe it can help
families move forward by ensuring
the criminal cannot harm anyone
[else. However, I]
that not]
give me] (1.5)
data? Like (.) has it actually
has it [worked as a deterrent?]
Repeated I
Participant interrupted.
System classified user speech
as cooperative agreement.
Robot stopped briefly and
continued. Line
Participant interrupted.
System classified user speech
as cooperative clarification.
Robot stopped and answered
the question. Line
the data on whether capital punishment
acts as a deterrent is mixed. Some
studies suggest... Overall, the evidence
is inconclusive...
Speech overlapped.
Not a user-initiated
interruption.
Robot generated new
behavior (response). Line
Cut off planned speech
Because of the 1.5 s delay in
participant speech, this was
treated as a new question.
Example conversation where the system handles various types of compounded interruptions. Overlap 3 is an example of a robot-initiated interruption.
We used the Jeffersonian transcription system . R denotes robot and P denotes participant.
(n  86) had more than twice as many user-initiated interrup-
tions as the contentious discussion task (n  35).
TYPES OF INTERRUPTIONS OBSERVED AND EXAMPLES.
Speech act
Attribute Example
Cooperative agreement (n  18)
Verbal back-channel
Statement
Thats a good idea
gestions
Cooperative assistance (n  2)
Statement
Another thing that I was
thinking was jack knife.
Cooperative clarication (n  9)
Question
and the parachute?
What percent?
Disruptive interruption (n  92)
Question
about adding the pistol to the
How many states have capital
punishment?
Statement
I do not think that the cos-
metic mirror is necessary. I
think we should change it into
45 caliber pistol
A. The majority of interruption attempts were disruptive
Based on the interruption intent coded by the research team,
the most common type of interruption was disruptive (n  92,
76.03), followed by cooperative agreement (n  18), coop-
erative clarication (n  9), and rarely, cooperative assistance
(n  2). Participants attempted disruptive interruptions in
various ways, including asking opinion (n  42 out of 92,
45.65) and factual (n  16) questions or issuing opinion
(n  7) and non-opinion (n  27) statements. See Table I for
more details and example interruptions.
B. 88.78 of interruption intent was correctly classied
Five interruptions triggered pre-programmed events (see
description in Sec. 3), bypassing the interruption handling
system. During a 35-second time frame in one study, there
was an abnormally large delay in the speech-to-text API, likely
caused by a network error, causing the system to be unable
to detect user speech. Hence, our system did not handle the
ve interruptions (all disruptive) during this time. We exclude
these ten cases from the rest of our analysis.
Amongst the interruptions handled by the system (n  111),
participants used wakeword(s) in 47 interruptions (decision-
to immediately yield when a wakeword is heard during
overlapping speech (n  43). It treats all interruption attempts
containing wakeword(s) as strong disruptive interruptions
without passing the intent classier module (SR2, Line 4 in
Fig. 3). Due to speech recognition errors, wakewords were
not heard in 4 out of 47 cases. Additionally, interruptions
made when less than two seconds of robot-planned speech
remained (n  13) also bypassed the intent classier module
(SR3, Line 4 in Fig. 3). Of the 55 interruption attempts that
passed through the intent classication module2, the module
correctly classied the intent of 44 interruptions (80.00).
2111 total handled interruptions minus 43 with wakeword(s) detected, and
13 occurring near the end of robot-planned speech.
(n  43), our system incorrectly classied the intent in 11 out
of 98 (11.22) interruptions, meaning 88.78 were correctly
classied.
C. 93.69 of the interruptions were successfully handled
Not all interruption intent classication errors resulted in un-
successful handling, nor were all correctly classied interrup-
tions handled successfully. Of the 111 interruptions handled,
107 cases were the users rst interruption attempt during that
Among the seven unsuccessful initial attempts, the robot
continued speaking in four cases due to intent classication
attempts were successful. Overall, 104 out of 111 (93.69)
interruptions were successfully handled.
TABLE II
TYPES OF INTERRUPTIONS AND HANDLING STRATEGIES (MISCLASSIFIED
INTERRUPTIONS ARE HIGHLIGHTED).
Interruption
type (coded)
(by model)
Interruption
handling
<2s of plan-
ned speech
Finish-up3
Continue
Agreement
Ack and continue
Agreement
Disruptive
Yield immediately
Assistance
Assistance
Ack and continue
Clarication
Clarify and continue
Clarication
Disruptive
Yield immediately
Yield immediately
Disruptive
Ack and wrap-up
Agreement
Ack and continue
Assistance
Ack and continue
Clarication
Clarify and continue
Disruptive
wakeword
not used
Clarication
LLM error handling4
Yield immediately
wakeword
Agreement
Continue
D. Speech recognition errors caused the majority of interrup-
tion handling failures
To better understand the cause of unsuccessfully handled
interruptions (n  7), we analyze their potential links to intent
classication errors (n  11), as shown in Table II.
Misclassied disruptive interruption as cooperative agree-
ment (n  3). The robot continued speaking due to mis-
classication; two of which contained a wakeword but were
still misclassied due to speech recognition error.
Misclassied disruptive interruption as cooperative assis-
tance (n  1). The participant attempted to interrupt
3Two cooperative agreements, one assistance, one clarication, and nine
disruptive interruptionstwo used wakewords but were not heard by system
due to speech recognition errorwere handled through nish-up.
4LLM failed to generate correctly formatted robot behavior, so the robot
performed default LLM error handling. See supplemental materials 1 Section
II for details.
with The rst aid kit but abandoned the interruption
assistance. Five seconds later, the participant reattempted a
disruptive interruption, and the robot yielded immediately.
Misclassied disruptive interruption as cooperative clar-
ication (n  4). Despite the miss-classication, these
interruptions were considered successfully handled, as the
robot answered the users questions.
Misclassied cooperative agreement as disruptive (n  2).
While the robot yielded to cooperative agreements (e.g.,
manifest as unsuccessful interruption handling.
Misclassied cooperative clarication as disruptive (n  1).
A clarifying question was misclassied as disruptive and
inadequately answered due to speech recognition error.
Although correctly classied, two interruptions were unsuc-
cessfully handled due to errors in determining where the robot
left off at the time of interruption (n  2). For example,
[overlapping speech]
Since text-to-speech services do not provide word-by-word
on the average speaking rate and the amount of time elapsed.
To prevent missing context, we also designed the robot to
repeat its speech up to the last punctuation mark. Despite this,
misalignment still occurs; however, users were able to recover
by asking a follow-up question about the missing information
in both cases.
E. Unsuccessful interruption handling led to decreased per-
ceived inclusion, and lower discussion satisfaction.
While unsuccessful interruption handling was relatively
interruption handling error might affect users perception of
the discussion. Pearson correlation coefcient was used to
examine the linear relationship between the number of un-
successfully handled interruptions, users perceived inclusion
in the discussion, and users satisfaction with the discussion.
We found a negative correlation between the number of
unsuccessfully handled interruptions and the users perceived
inclusion in the discussion, (42)  .43, p  .005. We
also found a negative correlation between the number of
unsuccessfully handled interruptions and the users satisfaction
with the discussion, (42)  .35, p  .021.
ipants generally perceived their experience with the robot
positively (n  1521, describing it as good, nice, or
helpful). Among those who recalled initiating interruptions
(n  18), 14 found it easy to interrupt the robot or were
generally satised with how it handled interruptions, while
four found it hardone because the system failed to detect
ve interruptions due to network error, and three because they
wanted the robot to always yield immediately.
VII. DISCUSSION
In this work, inspired by interaction patterns observed in
human conversations, we designed and implemented an inter-
ruption handling system for conversational robots. To the best
of our knowledge, no existing robotic system has integrated in-
tention classication into its interruption handling framework.
Most existing conversational robots either ignore interruptions
or always yield to any overlapping speech. Systems that
ignore interruptions are prone to conversational breakdowns
as they disregard the users intention to shift the conversation.
ow when they yield to non-disruptive overlapping speech
(e.g., cooperative agreement, cooperative assistance, self-talk,
and backchannels), which can result in user frustration over
time. The distribution of types of interruptions depends on the
task context (i.e., a higher number of disruptive interruptions
in our survival task, likely due to the time constraint). In our
cooperative clarication (n  8) and disruptive interruptions
(n  73), leading it to successfully handle only 27.03 of
the interruptions. A system that always yields would fail
to handle cooperative agreement (n  16) and cooperative
assistance (n  1), causing it to successfully handle 84.68 of
the interruptions. In comparison, our proposed intention-based
system successfully handled 93.69 of the interruptions. This
shows the benet of intention-based interruption handling.
our exploration to help guide future designs of interruption
handling behavior in conversational robots.
A. Robots Role, Task Context, and Interruption Handling
While oor holding is a common strategy for handling in-
terruptions in human conversations, robots holding the oor
particularly during disruptive interruptions (e.g., Fig. 1)
were not perceived favorably by all participants. In fact, one
participant explained that I felt like I am trying to solve the
so their ideal interaction is the moment I speak, it wants to just
like immediate listen, and like my speech should take precedence
over anything it says. The participants perceived the robots
role in the task as assistive rather than collaborative, so they
expected it to yield immediately at every turn. This shows the
importance of aligning the robots role and task context with its
interruption handling behavior. Future research should explore
how a robots designed and perceived role inuences users
expectations for how the robot should handle interruptions.
On the other hand, interruption handling design may help
reinforce a robots intended role in a given context. For ex-
oor more aggressively to help establish the power dynamics,
while a robot designed to be an assistive tool in a causal task
should adopt a more exible and accommodating interruption-
handling approach. However, this needs to be approached with
with authoritative robots even if it is wrong . Future work
is needed to dene the balance between when a robot should
hold the oor in conversations based on its role and the task.
B. Breaking Habits: From Scripted to Natural HRI
While some participants preferred the predictability of
having a designated stop mechanism (wakewords), some
also felt uncomfortable using the robots name ( Luna) or
stop to initiate interruptions, as it can be viewed as rude in
human-human conversations. However, one participant, who
reported to use voice assistants on a daily basis, began nearly
every query with Luna. When they initiated interruptions,
they consistently said Luna and waited for the robot to
stop speaking before proceeding with their query. While their
conversation with the robot was fast-paced, it was very rigid.
This was not a unique case in our study. The habits users have
developed when interacting with commercial voice assistants
constrain their interactions with systems capable of more nat-
interruptions more uidly. It may also limit their perception of
the robots role to that of an assistive query-answering tool.
Future research should design more natural yet predictable
interactions and explore the lasting inuence of current tech-
nology use on how users engage with emerging technologies
that offer more advanced conversational capabilities.
C. Limitations
We designed our interruption handling framework based
on observations from human-human conversation data from
YouTube. However, the sample size was small and limited to
a few specic settings. Additionally, our HRI study focused
solely on robot as cognitive aid in timed decision-making
and contentious discussion scenarios. Future work is needed
to explore interruption handling in physical tasks, as well as
how interruption handling can be personalized and tailored
based on user behavior (e.g., repeated interruptions), user
preferences (e.g., their perceived role of the robot), and task
context (e.g., time constraint) for designing more compre-
hensive interruption management for HRI. Furthermore, our
study used convenient sampling and did not design interruption
handling to support special population. Future work should
explore how interruption handling may be designed to improve
interactions for special populations (e.g., older adults with
neurodegenerative disease). Finally, our evaluation was limited
to one-time interactions in the lab setting. Future work should
explore longer-term, multi-session interactions in the wild.
Our system also had a few limitations. As shown in our
failure for the intention classication module. While the LLM
absorbed some speech recognition errors (some errors did not
affect the LLMs ability to understand context), our current
system cannot detect discrepancies between the transcribed
speech and actual user speech. Future work could investi-
gate using multimodal inputs with multimodal LLMs as an
additional information source. Additionally, our system does
not account for non-verbal interruptions. We observed seven
instances where the users body language (e.g., opening their
mouths) indicated an intention to interrupt the robot without
making any sounds. Future work should explore how non-
verbal interruption can be leveraged in interruption handling
and how non-verbal interruptions should be handled by conver-
sational robots. In addition, our system focuses on interruption
handling in dyadic conversations; future work should explore
how robots should handle interruptions in multi-party and team
situations.
ACKNOWLEDGMENTS
This work was supported by the National Science Founda-
tion award 2141335.
AI Statement. This paper has been proofread by a lan-
guage model. The authors veried that the resulting content
accurately reects their original intent.
CRediT author statement. Shiye Cao: Conceptualization,
istration. Jiwon Moon: Conceptualization, Methodology, Soft-
REFERENCES
James F Allen, Bradford W Miller, Eric K Ringger, and
Teresa Sikorski.
A robust system for natural spoken
dialogue. arXiv preprint cmp-lg9606023, 1996.
Sean Andrist, Xiang Zhi Tan, Michael Gleicher, and
Bilge Mutlu. Conversational gaze aversion for humanlike
In Proceedings of the 2014 ACMIEEE inter-
national conference on Human-robot interaction, pages
Geoffrey W Beattie. Interruption in conversational in-
interactants. Linguistics, 1981.
pretty face: affordances of embodiment. In Proceedings
of the 5th international conference on Intelligent user
Leigh Clark, Nadia Pantidi, Orla Cooney, Philip Doyle,
Diego Garaialde, Justin Edwards, Brendan Spillane,
Emer Gilmartin, Christine Murad, Cosmin Munteanu,
et al. What Makes a Good Conversation?: Challenges
in Designing Truly Conversational Agents. In Proceed-
ings of the 2019 CHI conference on human factors in
computing systems, pages 112, 2019.
Adam Csapo, Emer Gilmartin, Jonathan Grizou, Jing-
Guang Han, Raveesh Meena, Dimitra Anastasiou, Kris-
tiina Jokinen, and Graham Wilcock. Multimodal conver-
sational interaction with a humanoid robot. In 2012 IEEE
3rd International Conference on Cognitive Infocommu-
nications (CogInfoCom), pages 667672. IEEE, 2012.
Patrick Gebhard, Tanja Schneeberger, Gregor Mehlmann,
Tobias Baur, and Elisabeth Andre. Designing the Impres-
sion of Social Agents Real-time Interruption Handling.
In Proceedings of the 19th ACM International Confer-
ence on Intelligent Virtual Agents, pages 1921, 2019.
Felix Gervits and Matthias Scheutz. Pardon the interrup-
embodied articial agents. In Proceedings of the 19th
annual SIGdial meeting on discourse and dialogue, pages
Julia A Goldberg. Interrupting the discourse on interrup-
and rapport-oriented acts. Journal of Pragmatics, 14(6):
Katherine Hilton.
What Does an Interruption Sound
Like? Stanford University, 2018.
Chien-Ming Huang and Bilge Mutlu.
Modeling and
Evaluating Narrative Gestures for Humanlike Robots. In
Ulas Berk Karli, Shiye Cao, and Chien-Ming Huang.
What If It Is Wrong: Effects of Power Dynamics and
Trust Repair Strategy on Trust and Compliance in HRI.
In Proceedings of the 2023 ACMIEEE International
Conference on Human-Robot Interaction, pages 271
Carol W Kennedy and Carl Camden. Interruptions and
nonverbal gender differences.
Journal of Nonverbal
Peter Kollock, Philip Blumstein, and Pepper Schwartz.
Sex and power in interaction: Conversational privileges
and duties. American sociological review, pages 3446,
Amama Mahmood, Junxiang Wang, and Chien-Ming
Situated Understanding of Errors in Older
Adults Interactions with Voice Assistants: A Month-
Bryan A Myers, Anam Furqan, Jennifer Nebolsky, Kevin
obstacles in voice user interfaces. In Proceedings of the
2018 CHI Conference on Human Factors in Computing
Song Hee Park and Alexa Hepburn. The Benets of a
Jeffersonian Transcript. Frontiers in Communication, 7:
Vojtech Pipek. On Backchannels in English Conversa-
PhD thesis, Masarykova univerzita, Pedagogicka
Sathish Chandra Pammi, Bart van Straalen, Khiet
tion with a virtual human. Journal on Multimodal User
Merle M Reimann, Florian A Kunneman, Catharine
agement in human-robot interaction. ACM Transactions
on Human-Robot Interaction, 2024.
Abigail J Sellen.
Remote conversations: The effects
of mediating talk with technology.
Human-computer
Ruchen Wen, Alyssa Hanson, Zhao Han, and Tom
Williams.
Fresh start: Encouraging politeness in
wakeword-driven human-robot interaction. In Proceed-
ings of the 2023 ACMIEEE International Conference on
Human-Robot Interaction, pages 112121, 2023.
Liu Yang.
What If I Interrupt You.
In Proceedings
of the 2021 International Conference on Multimodal
Liu Yang, Catherine Achard, and Catherine Pelachaud.
Multimodal classication of interruptions in humans
interaction.
In Proceedings of the 2022 International
Conference on Multimodal Interaction, pages 597604,
