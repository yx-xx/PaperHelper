=== PDF文件: MISO Multiresolution Submap Optimization for Efficient Globally Consistent Neural Implicit Reconstru.pdf ===
=== 时间: 2025-07-21 15:15:42.085583 ===

请从以下论文内容中，按如下JSON格式严格输出（所有字段都要有，关键词字段请只输出一个中文关键词，一个中文关键词，一个中文关键词）：
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Globally Consistent Neural Implicit Reconstruction
Yulun Tian, Hanwen Cao, Sunghwan Kim and Nikolay Atanasov
Department of Electrical and Computer Engineering
University of California, San Diego
La Jolla, CA 92093, USA
(a) Coarse level features
(b) Fine level features
(c) SDF reconstruction
(d) Mesh and trajectory estimates
Fig. 1: Demonstration of MISO on the FastCaMo-Large dataset . MISO leverages multiresolution submaps that organize neural implicit
features at different spatial resolutions (visualized in (a) and (b) using principal component analysis). By performing hierarchical optimization
within (local) and across (global) submaps, MISO can efficiently and accurately reconstruct SDF (c) and estimate mesh and robot trajectory
(d). For clarity, we only visualize the features and SDF values within 30 cm of the surface. The scene size is 26.0 m  16.7 m  7.5 m.
AbstractNeural implicit representations have had a signifi-
cant impact on simultaneous localization and mapping (SLAM)
by enabling robots to build continuous, differentiable, and high-
fidelity 3D maps from sensor data. However, as the scale and com-
plexity of the environment increase, neural SLAM approaches
face renewed challenges in the back-end optimization process to
keep up with runtime requirements and maintain global consis-
tency. We introduce MISO, a hierarchical optimization approach
that leverages multiresolution submaps to achieve efficient and
scalable neural implicit reconstruction. For local SLAM within
each submap, we develop a hierarchical optimization scheme with
learned initialization that substantially reduces the time needed
to optimize the implicit submap features. To correct estimation
drift globally, we develop a hierarchical method to align and fuse
the multiresolution submaps, leading to substantial acceleration
by avoiding the need to decode the full scene geometry. MISO
significantly improves computational efficiency and estimation
accuracy of neural signed distance function (SDF) SLAM on
large-scale real-world benchmarks.
I. INTRODUCTION
In recent years, neural fields  have emerged as a new
frontier for scene representation in simultaneous localization
and mapping (SLAM). Compared to conventional approaches
based on hand-crafted features or volumetric representations,
neural SLAM  offers advantages including continuous and
differentiable scene modeling, improved memory efficiency,
and better handling of measurement noise. However, a crucial
limitation remains in the back-end optimization of neural
existing approaches consider increasingly larger optimization
problems that ultimately limit their real-time performance.
A powerful idea to achieve more efficient SLAM is to de-
pend on a hierarchical representation that explicitly disentan-
gles coarse and fine information of the environment. Equipped
with such a hierarchical model, a robot can perform inference
over varying spatial resolutions, e.g., by first capturing the
core structure in the environment and then optimizing the fine
details later. In SLAM, this idea dates back to several seminal
works such as . Recently, hierarchical or multiresolution
representations have also achieved success in neural fields
, demonstrating state-of-the-art performance and cost-
quality trade-offs in many computer vision tasks. Nevertheless,
neural SLAM systems have yet to benefit from these recent
utilize the hierarchical form of the representations.
In this work, we develop a hierarchical optimization ap-
proach that directly uses multiresolution implicit features for
neural SLAM. This approach enables us to solve a significant
portion of the back-end optimization in the implicit feature
robustness compared to existing methods that depend on
geometric reconstruction , . To scale to larger scenes,
we adopt a submap-based design that models the environment
as a collection of local neural implicit maps. In this context, we
show that the proposed hierarchical optimization significantly
enhances both local submap optimization and global submap
fusion stages in SLAM. We apply our approach to neural
signed distance function (SDF) SLAM  and demonstrate
its effectiveness on real-world, large-scale datasets.
Contributions. We present MISO (MultIresolution Submap
Optimization), a hierarchical optimization approach for neural
implicit SLAM. MISO performs local pose and submap op-
timization and global submap fusion, which can be used to
achieve SDF SLAM from depth images or LiDAR scans. For
local submap optimization, MISO introduces a learning-based
hierarchical initialization method to generate multiresolution
submap features, which are subsequently refined through joint
optimization with robot poses. As a theoretical motivation,
we derive a closed-form solution to the initialization problem
under the special case of linear least squares optimization.
Leveraging this theoretical insight, we design hierarchical
encoders to learn effective initializations in the general case.
For global submap fusion, MISO presents a hierarchical
optimization method to align and fuse submaps in the global
frame. Compared to previous works, our approach achieves
faster and more robust performance by directly using infor-
mation stored in the hierarchical implicit features rather than
relying on geometric reconstruction. Evaluation on benchmark
datasets shows that MISO achieves competitive estimation
quality and significantly outperforms existing methods in
computational efficiency. Fig. 1 demonstrates MISO on the
real-world FastCaMo-Large dataset .
Notation. Unless stated otherwise, lowercase and uppercase
letters denote vectors and matrices, respectively. We define
[n] {1, 2, . . . , n} as the set of positive integers from 1 to
n. The special Euclidean group in 3D is denoted by SE(3),
and SE(3)n denotes its product manifold. A local perturbation
on the tangent space of SE(3) is represented by a vector
R6. The exponential map Exp : R6 SE(3) is given by
Exp()  exp([]), where [] se(3) is the Lie algebra
element corresponding to  and exp is the standard matrix
exponential. The inverse of the exponential map is denoted as
x R3, Tx  Rx  t R3 denotes the transformed point.
II. RELATED WORK
We review related work on neural implicit representations
for SLAM, with particular focus on neural SDF reconstruction
and submap decompositions. The reader is referred to recent
tive representations including 3D Gaussian splatting .
A. Neural Implicit Representations
Neural implicit representations offer continuous and differ-
entiable modeling of 3D scenes with high fidelity, memory
such as DeepSDF  and NeRF  rely solely on 3D
coordinates and a single multi-layer perceptron (MLP) to
reconstruct the scene. However, this approach is insufficient
for capturing larger scenes or complex details, prompting
subsequent works to introduce hybrid methods that combine
MLP decoders with additional implicit features. The implicit
features are commonly organized in a 3D grid , .
To enable continuous scene modeling, trilinear interpolation
is used to infer a feature at an arbitrary query location that is
subsequently passed through the MLP decoder to predict the
environment model (e.g., occupancy, distance, radiance). Re-
cent works propose several alternative approaches to improve
the memory efficiency over 3D feature grids. K-Planes
factorizes the scene representation into multiple 2D feature
planes rather than using a full 3D voxel grid. Similarly,
TensoRF  employs tensor decomposition to compactly
represent radiance fields. PointNeRF  constructs the scene
representation directly from point clouds by efficiently aggre-
gating local features at surface points.
Hierarchical strategies for organizing the implicit features
have been particularly effective at capturing different levels
of detail while maintaining efficiency , , .
DVGO  performs progressive scaling that gradually in-
creases the feature grid resolution during training. InstantNGP
significantly accelerates feature grid training and infer-
ence by introducing a multiresolution hash encoding scheme.
Neuralangelo  extends this concept with a coarse-to-fine
optimization scheme that preserves fine-grained details. In
sentations for large scenes by varying spatial resolution where
SDF mapping by combining octree-based coarse SDF and
multiresolution feature grids, where the latter is optimized
to learn residual geometry. Hierarchical representations have
also been explored for fast RGB-D surface reconstruction
, . In this work, we leverage these hierarchical neural
representations to achieve efficient and accurate back-end
optimization for neural SLAM.
B. Neural SDF SLAM
Recent SLAM systems have achieved remarkable progress
by modeling the environment using neural implicit SDF.
Building on DeepSDF , iSDF  uses a single MLP for
online SDF reconstruction from streaming RGB-D data. iSDF
selects keyframes based on information gain  and samples
free-space and near-surface points along camera rays to train
the MLP. VoxFusion  leverages a sparse octree to organize
implicit features and Morton coding for efficient allocation and
environments. Vox-Fusion  extends the method to large-
scale scenes through submap support. NICER-SLAM
transforms estimated SDF to density for volume rendering
during monocular SLAM. NeRF-LOAM  similarly uses
SDF to represent the geometry for neural lidar odometry
and mapping, and develops a dynamic voxel embeddings
generation method to speed up octree queries. PIN-SLAM
reconstructs SDF via sparse neural point features, and employs
voxel hashing to speed up spatial querying for online SLAM.
PINGS  is a concurrent work that extends PIN-SLAM
to enable photorealistic rendering via Gaussian Splatting. The
neural point features are decoded to spawn Gaussian primitives
enhance geometric consistency. ESLAM  uses multi-scale
axis-aligned tri-plane feature grids with a TSDF representation
to achieve memory-efficient reconstruction and localization.
Co-SLAM  combines smooth one-blob coordinate encod-
ing with local-detail hash-grid embeddings to improve camera
tracking. GO-SLAM  supports loop closing and online
bundle adjustment with a multi-resolution hash-grid design for
both SDF and color. Despite these advancements, achieving
globally consistent SDF reconstruction of large-scale scenes
remains challenging. In this work, we address this limitation
by developing a hierarchical approach for both local and global
multiresolution submap optimization.
C. Submap-based Neural SLAM
An effective strategy for large-scale 3D reconstruction is to
partition the scene into multiple submaps. Kahler et al.
create submaps storing truncated SDF values based on visi-
bility criteria and align them by optimizing the relative poses
of overlapping keyframes. MIPS-Fusion  extends this idea
by incrementally generating MLP-based submaps based on
the cameras field of view and aligning them via point-to-
plane refinement. Vox-Fusion  adopts a dynamic octree
structure for each submap and performs joint camera tracking
and submap alignment by optimizing a differentiable rendering
loss. Loopy-SLAM  uses a neural-point-based approach,
creating submaps upon large camera rotations and later con-
structing a pose graph with iterative closest point (ICP) to
detect loop closures. More recently, PLGSLAM  com-
bines axis-aligned tri-planes for high-frequency features with
an MLP for low-frequency components, enabling multiple
local representations to be merged efficiently. NEWTON
employs a spherical coordinate system to create local maps
that accommodate flexible boundary adjustments. Multiple-
SLAM  and CP-SLAM  consider collaborative scenar-
ios and fuse local neural implicit maps from multiple agents.
Although effective, existing methods require reconstructing
the scenes geometry to align submaps, which can be costly
and inaccurate in real-world settings. In contrast, our method
aligns submaps directly in the feature space via hierarchical
without explicit geometric reconstruction.
III. OVERVIEW
In MISO, we represent the scene as a collection of posed
submaps. Correspondingly, the back-end optimization involves
two types of problems: (i) local SLAM within each submap
and (ii) global alignment and fusion across all submaps. See
Fig. 2 for an illustration.
Given odometry and point-cloud observations from depth
images or LiDAR scans, a robot aims to estimate its trajectory
and build a local map represented as a multiresolution feature
grid (Fig. 2a). Organizing implicit features into a hierarchy
of grids effectively disentangles information at different spa-
tial resolutions. At inference time, interpolated features from
different hierarchy levels are aggregated and processed by a
decoder network to predict the scene geometry. To speed up lo-
cal optimization, we introduce hierarchical encoder networks
to initialize the grid features at each hierarchy level directly
from input observations. To achieve further acceleration and
enable generalization to new environments, both the encoder
and decoder networks are pre-trained offline over multiple
scenes and fixed during online SLAM. Sec. IV presents in
detail our local SLAM method.
In large environments or over long time durations, the robot
trajectory estimates will inevitably drift and cause the submaps
to be misaligned. To address this challenge, MISO introduces
an approach to align and fuse all submaps in the global
reference frame (Fig. 2b). Each submap is associated with a
base pose that determines the transformation from the local
(submap) frame to the global frame. Compared to existing
an explicit representation like occupancy, mesh, or distance
implicit features in the multiresolution submaps. We show that
this results in significantly faster optimization and outperforms
other methods under large initial alignment errors. Sec. V
presents the details of the global alignment and fusion method.
IV. LOCAL SLAM
This section introduces our submap representation utilizing
multiresolution feature grids and our hierarchical submap
optimization method.
A. Local SLAM with Multiresolution Feature Grid
We represent each local submap as a multiresolution feature
Definition 1 (Multiresolution Feature Grid). A multiresolution
feature grid contains L > 1 levels of regular grids with
increasing spatial resolution ordered from coarse (l  1) to
fine (l  L). At each level l, each vertex located at zl,i R3
stores a learnable feature vector fl,i Rd. Together with a
kernel function kl : R3  R3 R, the feature grid defines
a continuous feature field fl(x)  P
iIl kl(x, zl,i)fl,i, where
x R3 is any query position, and Il indexes over all vertices
at level l. To obtain a scalar output (e.g., signed distance or
occupancy) at query position x, the features at different levels
are concatenated (denoted by L) and processed by a decoder
network D,
h(x; F, )  D
The model has the set of features from all levels F and the
decoder parameters  as learnable parameters.
In this work, we implement the kernel functions kl using
trilinear interpolation. While the multiresolution feature grid
offers a powerful representation, directly using it as a map
representation in SLAM presents a computational challenge
due to the need to train the decoder network D. Even if
computation is not a concern, training the decoder with a small
dataset or during a single SLAM session may lead to unreliable
generalization or catastrophic forgetting .
To address these challenges, we pre-train the decoder D
offline over multiple scenes, similar to prior works (e.g.,
, ). The details of the offline decoder training are
presented in Appendix A. During online SLAM, the decoder
weights are fixed (as shown in Fig. 2a), and the robot only
needs to optimize the grid features F and its own trajectory.
estimates { T s
k}k (e.g., from odometry) and associated obser-
vations {Xk}k, where each Xk  {xk
mk} R3 is
a point cloud observed at pose k. Using this information, we
Coarse Feature Grid
Fine Feature Grid
Hierarchical Encoders
(a) Local mapping with multiresolution feature grid
Base Pose
(b) Global submap alignment and fusion
Fig. 2: Overview of MISO. (a) Given point cloud observations, MISO performs local hierarchical SLAM within a submap represented as
a multiresolution feature grid (Sec. IV). (b) Given locally optimized submaps, MISO performs global alignment and fusion across submaps
to eliminate estimation drift and achieve globally consistent scene reconstruction (Sec. V).
seek to jointly refine the robots pose estimates and the submap
features F via the following optimization problem.
Problem 1 (Local SLAM within a submap). Given n initial
pose estimates { T s
k}k in the reference frame of submap s
and associated point-cloud observations {Xk}k in the sensor
k }kSE(3)
where cj : R R is a cost function associated with the
j-th observation and  : SE(3)  SE(3) R is a pose
regularization term. We drop the dependence of the model
h on the decoder parameters  to reflect that the decoder is
trained offline.
The first group of terms in (2) evaluates the environment
reconstruction at observed points xk
j by transforming them to
the submap frame (i.e., xs
j ) and querying the feature
grid model h. Empirical results show that introducing the sec-
ond group of pose regularization terms helps the optimization
remain robust against noisy or insufficient observations. We
use regularization inspired by trust-region methods [41, Ch. 4],
( bT, T)  w max
Log( bT 1T)
which penalizes pose updates larger than the trust-region
In our implementation, we solve Problem 1 approxi-
mately by parametrizing each pose variable locally as T s
k) where s
k R6 is the local pose correction.
Both the grid features F and the correction terms {s
optimized using Adam  in PyTorch .
We introduce definitions of the cost cj specific to neural
SDF reconstruction next. Whenever clear from context, to ease
the notation we use xj xs
j to represent a point in
the submap frame.
Cost functions for neural SDF reconstruction. We follow
iSDF  to design measurement costs for SDF reconstruc-
tion. Specifically, we classify all observed points as either (i)
on or near surface (default to 30 cm as in iSDF), or (ii) in free
space. For on or near surface observations, the cost function
cj  csdf
is based on direct SDF supervision,
j (h(xj))  wsdf
j h(xj) yj ,
where wsdf
> 0 is measurement weight (default to 5.4 as in
iSDF) and yj R is a measured SDF value on or near surface
obtained using the approach from iSDF .
For free-space observations, we use the cost to enforce
bounds on the SDF values. Specifically, we follow iSDF to
obtain lower and upper bounds bj,bj on the SDF from sensor
j (h(xj))  max(e(bjh(xj)) 1, 0),
j (h(xj))  max(h(xj) bj, 0),
(h(xj))  max(clo
j (h(xj)) , cup
j (h(xj))).
This cost applies exponential penalty (  5 by default) for
the lower bound and linear penalty for the upper bound. This
is because, in practice, violation of the lower bound is usually
more critical, e.g., if bj  0 and the model predicts negative
SDF values. We do not include Eikonal regularization
because we observed that it has limited impact on accuracy
while making the optimization slower.
B. Hierarchical Feature Initialization for Local SLAM
In practice, the bulk of the computational cost in Problem 1
is incurred by the optimization over the high-dimensional grid
features F. To address this challenge, we propose a method
that leverages the structure of the multiresolution grid to learn
to initialize F from sensor observations. While prior works
such as Neuralangelo  advocate for coarse-to-fine training
are still optimized from scratch, e.g., from zero or random
initialization. Our key intuition is that, at any level, a much
more effective initialization can be obtained by accounting for
optimization results from the previous levels.
In the following, we use Fl to denote the subset of latent
features at level l, and F1:l denote all latent features up to and
including level l. We consider the problem of initializing Fl
Algorithm 1 HIERARCHICAL LOCAL SLAM
k}k, F  HIERARCHICALLOCALSLAM
for level l  1, 2, . . . , L do
Initialize features at level l: Fl El(r1:l1(x)).
From the initialized values, jointly update features F and
poses {T s
k}k by minimizing (2).
return {T s
k}k and F.
given fixed submap poses and coarser features F1:l1. This
amounts to solving the following subproblem of Problem 1,
j ; F1:l1, Fl, 0l1:L)
where we explicitly expand F into the (known) coarser fea-
tures F1:l1, the target feature to be initialized Fl, and finer
features (assumed to be zero). During initialization, we do
not consider pose optimization and thus drop the trust-region
regularization in Problem 1.
To develop our approach, we first present theoretical analy-
sis and derive a closed-form solution to (8) in a special linear-
least-squares case. Leveraging insight from the closed-form
solution in the linear case, we then develop a learning approach
to initialize the grid features at each level, applicable to the
general (nonlinear) problem in (8).
Special case: linear least squares. Consider the special
case where the decoder D in Definition 1 is a linear function.
e.g., cj(h(xj))  (h(xj) yj)2. For instance, this would
correspond to using squared norm for the SDF cost in (4).
Under these assumptions, problem (8) is a linear least squares
the normal equations, as shown next.
Proposition 1 (Linear least squares). With linear decoder D
and quadratic costs cj(h(xj))  (h(xj) yj)2, the optimal
solution to (8) is:
l  E(r1:l1(x)) :
where x  {T s
j } and y  {yj} collect all observed points
and labels in two vectors, J  h(x; F)Fl is the Jacobian
matrix evaluated at x, and r1:l1(x) are the residuals of prior
Observe that the residual vector r1:l1(x) is mapped to the
least-squares solution F
by a linear function, which we
denote as E().
Proposition 1 reveals an interesting structure of the optimal
initialization F
of the prior levels residuals r1:l1(x). We will build on this
insight to approach the problem in the general case.
Input Point Cloud
with Residuals
Voxelized Input
CNN Output
Predicted Feature
Fig. 3: Illustration of the level-l encoder El. Input point cloud with
residuals {xj, rin
j }j is voxelized via averaging pooling and processed
by a 3D CNN. The CNN outputs at all vertices are then transformed
via a shared MLP to predict the target feature grid Fl.
General case: learning hierarchical initialization. We
take inspiration from Proposition 1 to develop a learning-based
solution for the general case, where the decoder is nonlinear
(e.g., an MLP) and the measurement costs are generic func-
tions. Motivated by the previous insight, we propose to replace
the linear mapping E in Proposition 1 with a neural network
El to approximate F
l from the residuals r1:l1(x),
l El(r1:l1(x)),
where l are the neural network parameters. We refer to El as
an encoder due to its similarity to an encoding module used by
prior works such as Convolutional Occupancy Networks
and Hierarchical Variational Autoencoder . In this work,
we train a separate encoder El to initialize the feature grid Fl
at each level l. Given the learned encoder networks, we apply
them to initialize the multiresolution feature grid progressively
in a coarse-to-fine manner, before jointly optimizing all levels
together with the robot trajectories, as shown in Algorithm 1.
ral SDF reconstruction. The input to the encoder is represented
as a point cloud. For each 3D position xj R3 in the submap
struct an initial feature vector rin
h(xj) yj,
if xj near surface,
max(h(xj) bj, 0),
if xj in free space,
max(bj h(xj), 0),
if xj in free space,
otherwise.
The first feature rin
The remaining two features correspond to the residuals of
upper and lower bounds used to compute (7). The initial
point features are pooled onto a 3D voxel grid with the
same resolution as the target feature grid at level l. Each 3D
vertex stores the average residual features from points nearby.
A vertexs feature is set to be zero if there are no nearby
points. This voxelized input is then passed through a small
3D convolutional neural network (CNN). Finally, the CNN
outputs at all vertices are passed through a shared MLP to
predict the target feature grid Fl. Fig. 3 shows a conceptual
inputs and predictions on a real-world dataset. Similar to the
multiple environments. In particular, when training the level l
encoder El, we use a training loss based on (8),
where S contains the indices of all training submaps, Js
contains the indices of all points in submap s, and F s denotes
the features for submap s. During training, we use noisy poses
within the submaps to compute xs
j to account for the possible
pose estimation errors at test time.
C. Extension to Incremental Processing
The local SLAM optimization formulated in (2) can be per-
formed in an incremental manner. We describe an implemen-
tation inspired by PIN-SLAM  and present corresponding
evaluation on outdoor datasets in Sec. VI-D. At each time step
cost terms {cj}mk
j1 in (2). We then alternate between tracking
and mapping to update the estimated robot pose and the neural
implicit submap. During tracking, we only optimize the current
robot pose T s
k and keep the submap features F fixed. Specifi-
voxel downsampling (voxel size 0.6 m in Sec. VI-D). We
estimate the robot motion by minimizing (2) with respect to
to improve robustness against outlier measurements. During
submap features F. Voxel downsampling is similarly applied
but with a smaller voxel size (0.08 m in Sec. VI-D). In
the incremental setting, the encoder initialization is disabled.
frames to update the submap features F by minimizing (2).
V. GLOBAL SUBMAP ALIGNMENT AND FUSION
As the robot navigates in a large environment or for an
extended time, its onboard pose estimation will inevitably drift.
To achieve globally consistent 3D reconstruction (e.g., after
loop closures), it is imperative to accurately align and fuse the
submaps in the global frame. Many state-of-the-art systems,
such as MIPS-Fusion  and Vox-Fusion , employ
approaches that align submaps using learned SDF values.
noise. In this section, we address this limitation by developing
a hierarchical method for submap alignment and fusion, which
attains significant speed-up by directly performing optimiza-
tion using the features from the multiresolution submaps.
Hierarchical Submap Alignment. Consider the problem
of aligning a collection of ns submaps, each represented as
a multiresolution feature grid from Sec. IV. For each submap
u [ns], we aim to optimize the submap base pose in the
world frame, denoted as T w
u SE(3). The key intuition for our
approach is that, for any pair of submaps to be well aligned,
their implicit feature fields should also be aligned in the global
frame. We present our hierarchical and correspondence-free
Algorithm 2 HIERARCHICAL SUBMAP ALIGNMENT
u }u  SUBMAPALIGNMENT
Initialize submap poses {T w
for level l  1, 2, . . . , L do
Update {T w
u }u by solving (17) at level l for kf,l iters.
Update {T w
u }u by solving (19) for ks iters.
return {T w
approach to exploit this intuition. Our method performs align-
ment by progressively including features at finer levels. In
the following, let f u
l (x) Rd denote the level-l interpolated
feature at query position x in submap u. Furthermore, let
including level l, i.e., f u
l (x) Rld.
Consider a pair of overlapping submaps u, v [ns]. Let
u. Using these vertices, we define the following pairwise cost
to align features,
v )1(T w
In (16), Iuv
denotes the indices of level-l vertices in submap
u that lie within the overlapping region of the two submaps.
interpolated from the two submaps. The first feature comes
from the source grid u evaluated at its grid vertex position
v )1(T w
feature grid. Finally, d denotes a distance metric in the space
of implicit features. In our implementation, we use the L2
2 as we find it works well
empirically. Sec. VI-E presents an ablation study on alternative
choices of d.
Given the pairwise alignment costs defined in (16), MISO
performs joint submap alignment by formulating and solving
a problem similar to pose graph optimization. Let E denote
the set of submap pairs with overlapping regions. Then, we
jointly optimize all submap poses {T w
u }u SE(3) as follows.
Problem 2 (Level-l submap alignment). Given ns submaps
with current base pose estimates { bT w
u }u, solve for updated
submap base poses via,
u }uSE(3)
where  is the trust-region regularization defined in (3).
Similar to local SLAM, we solve (17) using PyTorch
where the poses are updated by optimizing local corrections
(represented in exponential coordinates) to the initial pose es-
timates { bT w
u }u. Our formulation naturally leads to a sequence
of alignment problems that include features at increasingly fine
levels. We propose to solve these problems sequentially, using
solutions from level l as the initialization for level l  1; see
lines 3-5 in Algorithm 2.
The hierarchical, feature-based method presented above
achieves robust and sufficiently accurate submap alignment.
To further enhance accuracy, we may finetune the submap
pose estimates during a final alignment stage using predicted
SDF values. Since only a few iterations are needed in typical
efficiency compared to other methods that directly use SDF
for alignment. We define the following SDF-based pairwise
alignment cost for submap pair (u, v),
csdf(T w
j ; F u)hv((T w
j ; F v)
In (18), Juv contains the indices of observed points that
are in the intersection region of the two submaps. For each
observation j, xu
j R3 denotes its position in the frame of
submap u. Compared to (16), in (18) we minimize the squared
difference of the final SDF predictions from both submaps.
Using this in the pose-graph formulation leads to an SDF-
based submap alignment.
(SDF-based
alignment).
submaps with base pose estimates { bT w
u }u, solve for updated
submap base poses via,
u }uSE(3)
csdf(T w
where  is the trust-region regularization defined in (3).
In Algorithm 2, the SDF-based submap alignment is per-
formed at the end to finetune the submap base poses (see
line 6). In Sec. VI-E, we demonstrate that the combination
of feature-based and SDF-based submap alignment yields the
best performance in terms of both robustness and computa-
tional efficiency.
Submap Fusion. So far, we addressed the problem of
aligning submaps in the global frame to reduce estimation
drift. In some applications, there is an additional need to
extract a global representation (e.g., a SDF or mesh) of the
entire environment from the collection of local submaps. In
submaps to decode the global scene. For any submap u, let
f u(xu) denote the output of its multiresolution feature field
evaluated at a position xu R3 in the submap frame. Given
any query coordinate in the world frame xw R3, we first
compute the weighted average of all submap features,
wu(xw)f u((T w
u )1xw),
where each submap is associated with a binary weight wu(xw)
computed using its bounding box,
if xw is inside submap us bounding box,
otherwise.
The final prediction is obtained by passing the average feature
to the decoder network,
hw(xw)  D(f w(xw)).
In summary, the proposed scheme achieves submap fusion via
an averaging operation in the implicit feature space.
tune the estimation by jointly optimizing all submap features
and pose variables using global bundle adjustment:
F u, T w
u SE(3),
k }kSE(3), u[ns]
In (22), each cj is the same cost term induced by a local
measurement as in Sec. IV. Each observed local position
j is transformed to the world frame to evaluate the re-
construction. The integers ns, nu, mk denote the number of
number of measurements made at robot pose k, respectively.
In Sec. VI-D, we show that this global bundle adjustment step
allows the method to further improve the reconstruction quality
on outdoor datasets.
VI. EVALUATION
In this section, we evaluate MISO using several publicly
available real-world datasets. Our results show that MISO
achieves superior computational efficiency and accuracy com-
pared to state-of-the-art approaches during both local SLAM
and global submap alignment and fusion.
A. Experiment Setup
We used four datasets in our experiments: Replica ,
Among these datasets, Replica is used to pre-train the encoders
and decoder networks offline; see Appendix A for details.
the real-world ScanNet dataset and the large-scale FastCaMo-
Large dataset without additional fine-tuning. Lastly, we present
a larger scale evaluation on sequences from the outdoor Newer
College dataset.
For quantitative evaluations, we compare the multiresolution
submaps in MISO against the MLP-based representation from
iSDF  and the neural-point-based representation from PIN-
code. In the following, we refer to these two baselines as
iSDF and Neural Points, respectively. When evaluating the
performance of submap alignment, we introduce two base-
line techniques from state-of-the-art submap-based systems.
The first is the correspondence-based method from MIPS-
correspondence-free method from Vox-Fusion , here-
after referred to as VFPP. In addition, we compare against
an ICP-based method introduced by Choi et al.  and
implemented in Open3D . Given the raw surface points
observed in the submaps, this baseline first aligns pairs of
submaps via point-to-plane ICP on voxel-downsampled point
TABLE I: Evaluation of local mapping quality for different methods on ScanNet . MISO is optimized for 20 epochs and the baselines
iSDF and Neural Points are optimized for 100 epochs. For each scene, we report optimization time (sec), Chamfer-L1 error (cm), and F-score
() computed using a threshold of 5 cm. Best and second-best results are highlighted in bold and underline, respectively.
iSDF  (GT pose)
Neural Points  (GT pose)
MISO (GT pose)
MISO (noisy pose)
TABLE II: Comparison between local mapping and SLAM on ScanNet  using colored ICP odometry as initial guess. For each scene,
we report translation RMSE (cm), rotation RMSE (deg), and Chamfer-L1 error (cm).
Tran err.
Rot err.
Tran err.
Rot err.
Tran err.
Rot err.
Tran err.
Rot err.
Color ICP   Mapping
Color ICP   SLAM
(a) MISO (init)
(b) MISO (opt)
(c) iSDF
(d) Neural Points
Fig. 4: Visualization of estimated SDF at a fixed height on ScanNet
scene 0207. MISO performs SLAM using noisy poses. iSDF and
Neural Points use ground truth poses and only perform mapping.
clouds. The aligned submaps are then fused in the global
frame via outlier-robust pose graph optimization. Whereas the
submaps used by the neural approaches (including ours) have
a fine-level resolution of 0.1 m, we allow the ICP baseline to
use a higher resolution of 0.02 m and the other parameters
are set to default. For MISO, we implement each submap as a
two-level multiresolution feature grid with spatial resolutions
[0.5 m, 0.1 m] for indoor and [1.0 m, 0.2 m] for outdoor
scenes. The feature dimension at each level is set to d  4. All
methods are implemented using PyTorch . All experiments
are run on a laptop equipped with an Intel i9-14900HX CPU,
an NVIDIA GeForce RTX 4080 GPU, and 12 GB of GPU
B. Evaluation on ScanNet Dataset
ScanNet  features a collection of real-world RGB-D
sequences with accurate camera poses and 3D reconstructions.
In the following, we use ScanNet to separately evaluate the
proposed local SLAM (Sec. IV) and global alignment and
fusion (Sec. V) methods. Joint evaluation is reported in the
next subsection on the larger FastCaMo-Large  datasets.
Local SLAM evaluation. Our first experiment evaluates
the performance of the local optimization approach in MISO
(Algorithm 1). Since each scene in ScanNet is relatively small,
we represent the entire scene as a single submap. For each
perturbing the ground truth poses with 3 deg and 5 cm errors.
For comparison, we also run MISO and the baseline iSDF
and Neural Points methods using ground truth poses, where
pose optimization is disabled. Table I reports results on four
(a) Level 1 rin
(b) Level 1 rin
(c) Level 1 SDF (d) Level 1 mesh
(e) Level 2 rin
(f) Level 2 rin
(g) Level 2 SDF (h) Level 2 mesh
Fig. 5: Inputs and output predictions from learned hierarchical
encoders on ScanNet scene 0024. Red and blue show positive and
negative residual or SDF values, respectively.
ScanNet scenes. For each method, we report its GPU time
and the mesh reconstruction error against the ground truth,
measured in Chamfer-L1 distance and F-score. Both MISO
variants are optimized for 20 epochs. For the iSDF and Neural
Points baselines, since they do not have access to pre-training,
we optimize both for 100 epochs for a fair comparison. As
shown in Table I, MISO achieves either the best or second-best
reconstruction results on all scenes. Using ground truth poses,
MISO achieves superior speed, requiring only 0.71.5 sec for
optimization. MISO with noisy poses takes longer due to the
additional pose estimation but is still significantly faster than
the baseline techniques.
Fig. 4 shows a qualitative comparison of the estimated SDF
at a fixed height on scene 0207. MISO starts from noisy
poses and performs full SLAM, while the baseline methods
use ground truth poses and perform mapping only. Fig. 4a
shows the initialization produced by the learned encoder (cor-
responding to line 4 in Algorithm 1), which already captures
the scene geometry to a large extent. The remaining errors and
missing details are fixed after running 20 optimization epochs,
as shown in Fig. 4b. Because iSDF uses a single MLP to
represent the scene, its output (see Fig. 4c) is overly smooth,
which leads to lower recall and F-score than MISO. Lastly,
the SDF prediction from Neural Points (Fig. 4d) is especially
TABLE III: Submap alignment evaluation on ScanNet  from
initial errors of 5 deg and 0.20 m. For each scene, we report the GPU
time (sec), and the final submap rotation error (deg) and translation
error (m) compared to ground truth. Results averaged over 10 trials.
Best and second-best results are highlighted in bold and underline.
0011 (159 poses, 4 submaps)
0024 (227 poses, 5 submaps)
Tran err
Tran err
noisy in free space, due to the lack of neural point features
far away from the surface.
To provide more insight on the performance of the learned
hierarchical encoders, Fig. 5 visualizes the inputs and output
predictions on scene 0024. For this visualization, we do not
use noisy pose estimates. At each level (shown as a row in
the figure), we visualize two channels rin
3 of the voxelized
input residuals defined in (12) and (14), the predicted SDF,
and the predicted 3D mesh. The level 1 encoder, although
with a coarse resolution of 0.5 m, already captures the rough
scene geometry and free space SDF. On top of this coarse
recover objects such as the sofa and the table.
initial trajectory estimates, we include an experiment with
color ICP odometry  as the initial guess. When running
local SLAM, we let MISO incrementally process a sliding
window of 10 frames and disable pose regularization in (2).
Table II shows that performing local SLAM substantially
improves performance compared to mapping only.
Submap alignment and fusion evaluation. The next set
of experiments evaluates the submap alignment and fusion
approach in MISO. We run MIPS-Fusion  to obtain the
submap information. We select scene 0011 and perform local
SLAM within all submaps starting from noisy poses with 1 deg
and 0.1 m errors. We then evaluate the performance of the
proposed alignment (Algorithm 2) and the baseline MIPS ,
alignment errors. All methods are run for 100 iterations
before evaluating their results. For MISO, we allocate 45
iterations for alignment at each feature level and 10 iterations
for final alignment using SDF, which corresponds to setting
methods use the same trust-region-based pose regularization,
where the trust-region radius  in (3) is set based on the
initial submap alignment error. For each setting of the initial
error shown on the x axis, we perform 10 random trials
and show the final results as boxplots in Fig. 6. With a
small initial alignment error of 1 deg and 0.1 m, all methods
produce accurate alignment results. However, as the initial
error increases, both MIPS and VFPP methods quickly fail,
showing that solely relying on SDF prediction is very sensitive
to the initial guess. The ICP baseline results in higher variance
indicating more frequent alignment failures despite the use
13.0 deg
17.0 deg
Initial Error
Rotation error (deg)
(a) Rotation error (deg)
13.0 deg
17.0 deg
Initial Error
Translation error (m)
(b) Translation error (m)
Fig. 6: Evaluation of submap alignment on ScanNet scene 0011 under
varying initial errors over 10 trials for each configuration.
(a) Before alignment
(b) After alignment
Fig. 7: 3D mesh reconstruction with oriented submap bounding
on ScanNet scene 0011.
of robust optimization. The proposed hierarchical alignment
in MISO is more robust under more severe misalignments
and outperforms the baseline methods significantly. Since our
experiments are offline, we record the total GPU time and final
accuracy. Timing results for ICP are omitted as the method
is not implemented on GPU. Table III reports the results on
scenes 0011 and 0024. The initial submap alignment error is
set to 5 deg and 0.2 m, and results are collected over 10 trials.
MISO is significantly faster since the majority of iterations in
Algorithm 2 only uses features for alignment and does not
need to decode the SDF values. In terms of accuracy, MISO
demonstrates competitive performance and achieves either best
or second-best results.
Fig. 7 visualizes the reconstructed global mesh on scene
0011 before and after submap alignment. To extract the global
which uses the average feature from all submaps to decode
the scene in the world frame. Along with the mesh, we also
show the oriented bounding boxes of all submaps. As shown in
Fig. 7a, the initial mesh is very noisy in areas where multiple
submaps overlap. Fig. 7b shows that MISO effectively fixes
this error and recovers clean geometry (e.g., the table and
TABLE IV: Evaluation on Newer College dataset . For each scene, we report translation RMSE (m), rotation RMSE (deg), Chamfer-L1
error (cm), and F-score () with a threshold of 20 cm. Best and second-best results are highlighted in bold and underline, respectively.
Quad (1991 scans)
Maths Institute (2160 scans)
Tran err.
Rot err.
Tran err.
Rot err.
ICP   MISO Mapping
KISS-ICP   MISO Mapping
PIN-SLAM
MISO (Odometry)
MISO (Full)
Fig. 8: Qualitative evaluation on the FastCaMo-Large dataset . We
show the final reconstructed mesh along with estimated and reference
robot trajectories (from ) in red and green, respectively.
chairs) in the global frame.
C. Qualitative Evaluation on FastCaMo-Large Dataset
FastCaMo-Large  is a recent dataset with multiple real-
world RGB-D sequences. Compared to ScanNet, this dataset
features larger indoor environments (up to 200 m2) and fast
camera motions, making it suitable for evaluating the overall
accuracy and scalability of our method. Since ground truth
is not available, we only focus on qualitative evaluation
in this experiment. We compare the performance of MISO
against iSDF, where the latter is extended to perform joint
optimization over both robot poses and the map. The in-
put pose estimates are obtained by perturbing robot poses
estimated by MIPS-Fusion  by 3 deg rotation error and
0.05 m translation error in their corresponding submaps, and
additionally perturbing all submap base poses by 5 deg rotation
error and 0.1 m translation error. The trust region radius
used in pose regularization (3) is set correspondingly for both
methods. For iSDF, we run optimization for 300 epochs to
ensure convergence. For MISO, we run 150 epochs of local
SLAM in parallel within all submaps, followed by submap
alignment where we skip the coarse level feature alignment as
we observe it leads to degraded results on these datasets. Fig. 8
shows qualitative comparisons of the estimated trajectories
and meshes on the Floors-II, Stairs-I, and Stairs-II sequences.
Fig. 1 shows more visualizations for MISO on the Floors-I
Fig. 9: Qualitative evaluation on the Newer College dataset . We
show the final reconstructed mesh along with estimated and reference
robot trajectories in red and green, respectively.
sequence. MISO is able to accurately represent these larger-
scale scenes while preserving fine details such as staircases and
chairs. In comparison, iSDF loses many details and introduces
more artifacts in areas where there are fewer observations.
D. Evaluation on Newer College Dataset
In this section, we evaluate MISO on the Quad-Easy
and Maths-Easy sequences from the outdoor, LiDAR-based
Newer College Dataset . For comparison, we run PIN-
Open3D  using their open-source implementations and
default hyperparameters. For KISS-ICP and point-to-point ICP,
we obtain corresponding maps for evaluation by running our
mapping pipeline with the pose estimates fixed. For MISO,
we first pre-train a decoder for each scene and then use
the incremental implementation presented in Sec. IV-C to
process each sequence. Point-to-point ICP is used to initialize
the tracking optimization at every scan, and a new submap
is created every 400 scans. We evaluate two variants of
our method in this experiment. The first (Odometry) only
performs incremental tracking and mapping. The second (Full)
also performs submap alignment and fusion as described in
Sec. V, and its results are visualized in Fig. 9. Table IV
reports translation RMSE (m), rotation RMSE (deg), Chamfer
L1 distance (cm), and F-score (). In the Quad scene, our
method achieves comparable performance with other state-
of-the-art methods. In the more challenging Maths Institute
still on par with KISS-ICP. On both sequences, our results
demonstrate that MISO substantially improves over the point-
to-point ICP initialization. Further, the comparison between
Odometry and Full validates the effectiveness of the proposed
TABLE V: Ablation study on the effect of pre-trained encoder and
decoder networks. For each scene, we report F-score () and the
training loss at epochs 10 and 100. Results are averaged over five
(10 epoch)
(100 epoch)
(10 epoch)
(100 epoch)
submap optimization approach to achieve global consistency.
E. Ablation Studies
We conclude the experiments with ablation studies to pro-
vide more insight into several design choices in MISO.
Ablation on encoder and decoder pre-training. The
first ablation study investigates the performance improvements
brought by pre-training the encoder and decoder networks in
MISO. For this, we use the same setup as the local mapping
experiments in Table I. For each scene, we report the F-score
() calculated with a 5 cm threshold and the training loss. The
results are presented at epochs 10 and 100 to demonstrate both
early-stage and later-stage training performance.
In Table V, we compare the following variants of MISO:
coder initialization. The grid features are initialized from
a normal distribution with standard deviation 104. Both
the grid features and the decoder are optimized jointly.
no encoder initialization. The grid features are initialized
from a normal distribution with standard deviation 104.
and encoder initialization.
As shown in Table V, our hierarchical initialization scheme
significantly speeds up training loss optimization, particularly
when both the pre-trained encoder and decoder are used
(see rows 1 and 3). Even with only the pre-trained decoder,
optimization remains faster than training from scratch (rows
1 and 2). As expected, after sufficient training (i.e., at 100
epochs), all three methods converge in terms of training loss.
mance than training from scratch. We attribute the slight
degradation of Full compared to No-E on scene 0011 (100
epochs) to domain mismatch since our encoders are pre-
trained on synthetic Replica scenes only. We do indeed observe
Replica-like artifacts in the Full results. With greater realism
and diversity in pre-training, we expect Full to further improve.
encoders especially at early stages (10 epochs).
Ablation on hierarchical alignment. To investigate the
effects of each alignment stage in Algorithm 2, we conduct
ablation experiments on ScanNet scenes 0011 and 0207, each
containing four submaps. We use the same setup as in the
submap alignment experiments. In Table VI, we compare the
following variants of MISO:
TABLE VI: Ablation study on hierarchical alignment on ScanNet
from large initial errors of 10 deg and 0.25 m. We report
the alignment solver time (sec) and the final submap rotation error
(deg) and translation error (m) compared to ground truth. Results are
averaged over 10 trials. Best results are highlighted in bold.
0011 (4 submaps)
0207 (2 submaps)
Tran err
Tran err
Coarse only
CoarseFine
Coarse only: Algorithm 2 with only coarse grid (l  1)
feature-based alignment.
and fine grid (l  2) feature-based alignment.
and fine grid (l  2) feature-based alignment, and a final
alignment stage using predicted SDF values.
In Table VI, one can see that the full hierarchical approach
(coarse, fine, and SDF) achieves the smallest rotation and
translation errors, whereas using only the coarse alignment
yields the largest errors. As expected, the full approach re-
quires more computation time as the last stage based on SDF
alignment requires using the decoder to predict SDF values.
We do not report the F-score for No-ED at epoch 10 because
it fails to produce a mesh due to insufficient training.
Ablation on metric function. We study how different
metric functions used in the feature-based alignment stage (i.e.,
d in (18)) affect alignment accuracy. Specifically, we compare
negative cosine similarity, L1 distance, and L2 distance under
three progressively increasing initial rotation and translation
errors in scene 0011. Our results in Fig. 10 show that L2
distance generally yields the most accurate submap alignment,
while negative cosine similarity tends to produce the largest
misalignment.
VII. LIMITATIONS
While MISO demonstrates very promising results in our
improvement is motivated by the use of dense feature grids.
While dense grids offer a range of advantages including fast
designing encoder networks, their memory cost may present a
challenge when scaling the method to very large environments.
To address this, combining MISOs hierarchical optimization
approach with sparse data structures or tensor decomposition
techniques is an exciting direction for future work. In addition,
while we have only considered SDF reconstruction in this
applicable for modeling additional scene properties such as
primarily demonstrated MISO in an offline batch optimization
odometry and observations. Extending to online and dynamic
settings is an important direction for future research.
13.0 deg
Initial Error
Rotation error (deg)
Cos sim.
L1 dist.
L2 dist.
(a) Rotation error (deg)
13.0 deg
Initial Error
Translation error (m)
Cos sim.
L1 dist.
L2 dist.
(b) Translation error (m)
Fig. 10: Ablation study on hierarchical alignment on ScanNet .
We compare negative cosine similarity, L1 distance and L2 distance
under three different initial rotation and translation errors.
VIII. CONCLUSION
We presented MISO, a hierarchical back-end for neural
implicit SLAM based on multiresolution submap optimization.
MISO performs local SLAM by representing each submap as a
multiresolution feature grid. To achieve fast optimization and
enable generalization, MISO makes use of pre-trained hier-
archical encoder and decoder networks, where the encoders
serve to initialize the submap features from observations, and
the decoder serves to decode optimized features to predict
the scene geometry. Furthermore, MISO presents a hierarchi-
cal method that sequentially uses implicit features and SDF
predictions to align and fuse submaps, achieving globally
consistent mapping. Evaluation on the real-world ScanNet,
MISOs strong performance and superior efficiency.
ACKNOWLEDGMENTS
We gratefully acknowledge support from ARL DCIST
CRA W911NF-17-2-0181, ONR N00014-23-1-2353, and NSF
CCF-2112665 (TILOS).
REFERENCES
Y. Tang, J. Zhang, Z. Yu, H. Wang, and K. Xu, MIPS-Fusion:
Multi-implicit-submaps for scalable and robust online neural RGB-D
Y. Xie, T. Takikawa, S. Saito, O. Litany, S. Yan, N. Khan, F. Tombari,
J. Tompkin, V. Sitzmann, and S. Sridhar, Neural fields in visual
computing and beyond, Computer Graphics Forum (CGF), 2022. 1,
F. Tosi, Y. Zhang, Z. Gong, E. Sandstrom, S. Mattoccia, M. R. Oswald,
and M. Poggi, How NeRFs and 3D Gaussian Splatting are reshaping
C. Estrada, J. Neira, and J. D. Tardos, Hierarchical SLAM: Real-
time accurate mapping of large environments, IEEE Transactions on
Robotics (T-RO), 2005. 1
U. Frese, P. Larsson, and T. Duckett, A multilevel relaxation algorithm
for simultaneous localization and mapping, IEEE Transactions on
Robotics (T-RO), 2005. 1
G. Grisetti, R. Kummerle, C. Stachniss, U. Frese, and C. Hertzberg,
Hierarchical optimization on manifolds for online 2D and 3D mapping,
in International Conference on Robotics and Automation (ICRA), 2010.
T. Takikawa, J. Litalien, K. Yin, K. Kreis, C. Loop, D. Nowrouzezahrai,
A. Jacobson, M. McGuire, and S. Fidler, Neural geometric level of
Conference on Computer Vision and Pattern Recognition (CVPR), 2021.
C. Sun, M. Sun, and H.-T. Chen, Direct voxel grid optimization:
Super-fast convergence for radiance fields reconstruction, in IEEECVF
Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
T. Muller, A. Evans, C. Schied, and A. Keller, Instant neural graphics
primitives with a multiresolution hash encoding, ACM Transactions on
Graphics (TOG), 2022. 1, 2, 3
H. Zhai, H. Li, X. Yang, G. Huang, Y. Ming, H. Bao, and G. Zhang,
with multi-maps, arXiv preprint arXiv:2403.12536, 2024. 1, 2, 3, 6, 7,
J. Ortiz, A. Clegg, J. Dong, E. Sucar, D. Novotny, M. Zollhoefer, and
M. Mukadam, iSDF: Real-time neural signed distance fields for robot
B. Kerbl, G. Kopanas, T. Leimkuhler, and G. Drettakis, 3D Gaussian
splatting for real-time radiance field rendering, ACM Transactions on
Graphics (TOG), 2023. 2
J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove,
Pattern Recognition (CVPR), 2019. 2
L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger,
Occupancy networks: Learning 3D reconstruction in function space,
in IEEECVF Conference on Computer Vision and Pattern Recognition
B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi,
and R. Ng, NeRF: Representing scenes as neural radiance fields for
view synthesis, Communications of the ACM (CACM), 2021. 2
D. Azinovic, R. Martin-Brualla, D. B. Goldman, M. Niener, and
J. Thies, Neural RGB-D surface reconstruction, in IEEECVF Con-
ference on Computer Vision and Pattern Recognition (CVPR), 2022. 2
S. Fridovich-Keil, A. Yu, M. Tancik, Q. Chen, B. Recht, and
A. Kanazawa, Plenoxels: Radiance fields without neural networks,
in IEEECVF Conference on Computer Vision and Pattern Recognition
S. Fridovich-Keil, G. Meanti, F. R. Warburg, B. Recht, and A. Kanazawa,
IEEECVF Conference on Computer Vision and Pattern Recognition
A. Chen, Z. Xu, A. Geiger, J. Yu, and H. Su, TensoRF: Tensorial
radiance fields, in European Conference on Computer Vision (ECCV),
Q. Xu, Z. Xu, J. Philip, S. Bi, Z. Shu, K. Sunkavalli, and U. Neu-
Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
Z. Li, T. Muller, A. Evans, R. H. Taylor, M. Unberath, M.-Y. Liu, and
C.-H. Lin, Neuralangelo: High-fidelity neural surface reconstruction,
in IEEECVF Conference on Computer Vision and Pattern Recognition
A. Yu, R. Li, M. Tancik, H. Li, R. Ng, and A. Kanazawa, Plenoc-
trees for real-time rendering of neural radiance fields, in IEEECVF
International Conference on Computer Vision (ICCV), 2021. 2
C. Jiang, H. Zhang, P. Liu, Z. Yu, H. Cheng, B. Zhou, and S. Shen,
J. Wang, T. Bleja, and L. Agapito, GO-Surf: Neural feature grid
optimization for fast, high-fidelity RGB-D surface reconstruction, in
IEEE International Conference on 3D Vision (3DV), 2022. 2
E. Sucar, S. Liu, J. Ortiz, and A. J. Davison, iMAP: Implicit mapping
and positioning in real-time, in IEEECVF International Conference on
Computer Vision (ICCV), 2021. 2
X. Yang, H. Li, H. Zhai, Y. Ming, Y. Liu, and G. Zhang, Vox-Fusion:
Dense tracking and mapping with voxel-based neural implicit repre-
Reality (ISMAR), 2022. 2
Z. Zhu, S. Peng, V. Larsson, Z. Cui, M. R. Oswald, A. Geiger, and
M. Pollefeys, NICER-SLAM: Neural implicit scene encoding for RGB
J. Deng, Q. Wu, X. Chen, S. Xia, Z. Sun, G. Liu, W. Yu, and
L. Pei, NeRF-LOAM: Neural implicit representation for large-scale
incremental lidar odometry and mapping, in IEEECVF International
Conference on Computer Vision (ICCV), 2023. 2
Y. Pan, X. Zhong, L. Wiesmann, T. Posewsky, J. Behley, and C. Stach-
representation for achieving global map consistency, IEEE Transactions
Y. Pan, X. Zhong, L. Jin, L. Wiesmann, M. Popovic, J. Behley, and
C. Stachniss, PINGS: Gaussian Splatting Meets Distance Fields within
a Point-Based Implicit Neural Map, arXiv preprint arXiv:2502.05752,
M. M. Johari, C. Carta, and F. Fleuret, ESLAM: Efficient dense SLAM
system based on hybrid representation of signed distance fields, in
IEEECVF Conference on Computer Vision and Pattern Recognition
H. Wang, J. Wang, and L. Agapito, Co-SLAM: Joint coordinate and
sparse parametric encodings for neural real-time SLAM, in IEEECVF
Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
Y. Zhang, F. Tosi, S. Mattoccia, and M. Poggi, GO-SLAM: Global
optimization for consistent 3D instant reconstruction, in IEEECVF
International Conference on Computer Vision (ICCV), 2023. 2
O. Kahler, V. A. Prisacariu, and D. W. Murray, Real-time large-scale
dense 3D reconstruction with loop closure, in European Conference on
Computer Vision (ECCV), 2016. 3
L. Liso, E. Sandstrom, V. Yugay, L. Van Gool, and M. R. Oswald,
Conference on Computer Vision and Pattern Recognition (CVPR), 2024.
T. Deng, G. Shen, T. Qin, J. Wang, W. Zhao, J. Wang, D. Wang, and
W. Chen, PLGSLAM: Progressive neural scene represenation with local
to global bundle adjustment, in IEEECVF Conference on Computer
Vision and Pattern Recognition (CVPR), 2024. 3
H. Matsuki, K. Tateno, M. Niemeyer, and F. Tombari, NEWTON:
Neural view-centric mapping for on-the-fly large-scale SLAM, IEEE
Robotics and Automation Letters (RA-L), 2024. 3
S. Liu and J. Zhu, Efficient map fusion for multiple implicit slam
J. Hu, M. Mao, H. Bao, G. Zhang, and Z. Cui, CP-SLAM: Collaborative
neural point-based SLAM system, in Advances in Neural Information
Processing Systems (NeurIPS), 2024. 3
Z. Zhu, S. Peng, V. Larsson, W. Xu, H. Bao, Z. Cui, M. R. Oswald,
and M. Pollefeys, NICE-SLAM: Neural implicit scalable encoding for
Recognition (CVPR), 2022. 3
J. Nocedal and S. J. Wright, Numerical optimization. Springer, 1999. 4
D. P. Kingma, Adam: A method for stochastic optimization, in
International Conference on Learning Representations (ICLR), 2014.
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, et al., PyTorch: An
imperative style, high-performance deep learning library, in Advances
in Neural Information Processing Systems (NeurIPS), 2019. 4, 6, 8
A. Gropp, L. Yariv, N. Haim, M. Atzmon, and Y. Lipman, Implicit ge-
ometric regularization for learning shapes, in International Conference
on Machine Learning (ICML), 2020. 4
S. Peng, M. Niemeyer, L. Mescheder, M. Pollefeys, and A. Geiger, Con-
volutional occupancy networks, in European Conference on Computer
Vision (ECCV), 2020. 5
A. Vahdat and J. Kautz, NVAE: A deep hierarchical variational
(NeurIPS), 2020. 5
A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and
M. Niener, ScanNet: Richly-annotated 3D reconstructions of indoor
Recognition (CVPR), 2017. 7, 8, 9, 11, 12, 14
J. Park, Q.-Y. Zhou, and V. Koltun, Colored point cloud registration
J. Straub, T. Whelan, L. Ma, Y. Chen, E. Wijmans, S. Green, J. J.
Y. Yan, X. Pan, J. Yon, Y. Zou, K. Leon, N. Carter, J. Briales,
T. Gillingham, E. Mueggler, L. Pesqueira, M. Savva, D. Batra, H. M.
The Replica dataset: A digital replica of indoor spaces, arXiv preprint
L. Zhang, M. Camurri, D. Wisth, and M. Fallon, Multi-camera li-
dar inertial extension to the newer college dataset, arXiv preprint
S. Choi, Q.-Y. Zhou, and V. Koltun, Robust reconstruction of indoor
Q.-Y. Zhou, J. Park, and V. Koltun, Open3D: A modern library for 3D
data processing, arXiv preprint arXiv:1801.09847, 2018. 7, 10
I. Vizzo, T. Guadagnino, B. Mersch, L. Wiesmann, J. Behley, and
C. Stachniss, KISS-ICP: In defense of point-to-point ICPsimple,
and Automation Letters (RA-L), 2023. 10
APPENDIX A
IMPLEMENTATION AND TRAINING DETAILS
In our experiments, each submap is a multiresolution feature
grid that has two levels with spatial resolutions 0.5 m and
0.1 m, respectively. The feature dimension at each level is set
to d  4. The decoder network D is a single-layer MLP
with hidden dimension 64. For the encoder network El at
each level l, we first use a small 3D CNN to process the
input voxelized features. Each CNN has 2 hidden layers, a
kernel size of 3, and the number of feature channels doubles
after every layer. The CNN outputs at all 3D vertices are
processed by a shared two-layer MLP with hidden dimension
16 to predict the target feature grid Fl (see Fig. 3). We use
ReLU as the nonlinear activation for all networks.
To train the decoder network D offline, we compile an
offline training dataset using six scenes from Replica .
Within each scene s S, we randomly simulate 128 camera
views with ground truth pose information. During training, all
scenes share a single set of decoder parameters , and each
scene s has its own dedicated grid features F s. We perform
joint optimization using a loss similar to Problem 1, except we
use ground truth camera poses and disable pose optimization,
j ; F s, )
where T s
k denote the ground truth camera poses. We use Adam
with a learning rate of 103 and train for a total of 1200
epochs. During training, we employ a coarse-to-fine strategy
where all fine level features are activated after 200 epochs.
After training completes, the grid features F s are discarded
and only decoder parameters  is saved.
The offline training of encoder networks follows a similar
setup and uses the same Replica scenes. The design of the
training loss is presented in Sec. IV in the main paper. We
sequentially train the encoder networks from coarse to fine
levels. At level l, we use the trained encoders from previous
levels to compute F s
training loss in (15). To account for noisy pose estimates at test
translation standard deviations. Each encoder is trained using
Adam  with a learning rate of 103 for 1000 epochs.
APPENDIX B
Proof of Proposition 1:
Without loss of generality, we
assume the features Fl is represented as a vector Fl RFl. In
the following, all points are expressed in the coordinate frame
of the submap. First, consider a single observed point xj R3
and its label yj R. At each level l, the output feature fl(xj)
in Definition 1 is a linear function of the features Fl at this
level. This means that there exists a matrix Kl(xj) RdFl
such that fl(xj)  Kl(xj)Fl. When the decoder D is a linear
is a weighted sum of features from all levels, i.e.,
h(xj; F)D
l fl(xj)
l Kl(xj)Fl.
In the following, we use l to specifically refer to the target level
that we seek to initialize in (8). The measurement residual is,
h(xj; F)yj
l Kl(xj)Fl yj
l Kl(xj)Fl, (25)
where we have used the fact that features at levels greater
than l are zero. We can concatenate the above equation over
all observations x1, . . . , xN as follows,
h(x; F) y
l Kl(x1)
l Kl(xN)
Note that the matrix J is exactly the Jacobian of our model
h(x; F) with respect to the level-l features Fl. Substituting the
above equation into (8) shows that the problem is equivalent
to the following linear least squares,
Fl h(x; F) y2
2  r1:l1(x)  JFl2
yielding the final expression in (9).
APPENDIX C
ADDITIONAL RESULTS
In Fig. 11, we show qualitative SDF visualizations on
additional scenes from ScanNet  under noisy poses. For
each method, a horizontal slice of the estimated SDF is shown
where red and blue indicate positive and negative values. These
figures further supports the conclusions drawn in the paper,
and the reader is referred to Sec. VI for the discussion.
TABLE VII: Number of parameters and GPU memory usage of
ScanNet (0011)
FastCamo (Stairs-I)
FastCamo (Floors-I)
Coarse only
We evaluate MISO s memory requirements by measuring
both the total number of parameters (covering the grid model
and the decoder) and the GPU memory usage. The GPU
memory usage is measured across the entire environment
using PyTorchs cuda.maxmemoryallocated() func-
tion. We test three scenes in Table VII: ScanNet  scene
011 and FastCaMo-Large  Stairs-I and Floors-I. The sizes
of these environments, measured as the dimensions of their
axis-aligned bounding boxes, are reported below,
ScanNet 0011: 6.0 m  8.2 m  2.7 m
FastCaMo-Large Stairs-I: 8.9 m  10.7 m  15.4 m
FastCaMo-Large Floors-I: 26.0 m  16.7 m  7.5 m
We consider two configurations: one using only the coarse grid
(Coarse only) and another using both the coarse and fine grids
(Full). In all scenes, the decoder itself consistently contains
about 0.12M parameters.
(a) MISO (initialized)
(b) MISO (optimized)
(c) iSDF (GT pose)
(d) Neural Points (GT pose)
(e) MISO (initialized)
(f) MISO (optimized)
(g) iSDF (GT pose)
(h) Neural Points (GT pose)
(i) MISO (initialized)
(j) MISO (optimized)
(k) iSDF (GT pose)
(l) Neural Points (GT pose)
Fig. 11: Qualitative comparison on additional ScanNet scenes 0000, 0011, and 0024, each shown in a row. For each method, a horizontal
slice of the estimated SDF is shown where red and blue indicate positive and negative values.
