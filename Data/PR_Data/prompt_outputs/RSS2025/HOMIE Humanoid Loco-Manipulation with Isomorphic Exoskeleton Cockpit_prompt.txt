=== PDF文件: HOMIE Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit.pdf ===
=== 时间: 2025-07-22 16:12:01.020701 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个最核心的最有代表性的中文关键词，要中文关键词，如果是英文关键词就尝试翻译成中文（不能是英文，不能是多个，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：with Isomorphic Exoskeleton Cockpit
Qingwei Ben1,2,, Feiyu Jia1,, Jia Zeng1, Junting Dong1, Dahua Lin1,2, Jiangmiao Pang1
1 Shanghai AI Laboratory
2 Multimedia Laboratory, The Chinese University of Hong Kong
Authors with equal contribution
Fig. 1: HOMIE empowers the humanoid robot to execute various loco-manipulation tasks in the real world. (a): Squatting to
grasp a tape and placing it on a higher shelf; (b): Facilitating an apple handover between two robots; (c): Holding a box and
transferring it to another shelf; (d): Pushing a person seated on a chair; (e): Opening an oven door; (f): Picking up a tomato,
handing it over, and placing it in a fruit basket; (g): Retrieving a bottle from the ground; (h): Holding a flower and placing it
into a box on a table. (i): Balancing under vigorous motion. These tasks show robustness and generality of HOMIE.
AbstractGeneralizable humanoid loco-manipulation poses
significant challenges, requiring coordinated whole-body control
and precise, contact-rich object manipulation. To address this,
this paper introduces HOMIE, a semi-autonomous teleoperation
system that combines a reinforcement learning policy for body
control mapped to a pedal, an isomorphic exoskeleton arm for
arm control, and motion-sensing gloves for hand control, forming
a unified cockpit to freely operate humanoids and establish a
data flywheel. The policy incorporates novel designs, including
an upper-body pose curriculum, a height-tracking reward, and
symmetry utilization. These features enable the system to per-
form walking and squatting to specific heights while seamlessly
adapting to arbitrary upper-body poses. The exoskeleton, by
eliminating the reliance on inverse dynamics, delivers faster and
more precise arm control. The gloves utilize Hall sensors instead
of servos, allowing even compact devices to achieve 15 or more
degrees of freedom and freely adapt to any model of dexterous
hands. Compared to previous teleoperation systems, HOMIE
stands out for its exceptional efficiency, completing tasks in half
the time; its expanded working range, allowing users to freely
reach high and low areas as well as interact with any objects;
and its affordability, with a price of just 500. The system is fully
I. INTRODUCTION
Generalizable humanoid loco-manipulation is crucial for
integrating humanoid robots into daily life and enabling them
to handle labor-intensive tasks. Achieving this requires coor-
dinated whole-body control (WBC) policies that endow robots
with both strong athletic capabilities and precise, contact-
rich object manipulation skills for interacting with a variety
of objects. Teleoperation is a promising technique to realize
this vision, leveraging a data-driven approach to create a
flywheel effect. However, the field currently faces a significant
policies excel at environmental adaptation but lack the inter-
faces needed for real-time, precise teleoperation [1, 2, 3, 4,
focus solely on upper-body control without considering the
impact of locomotion on the robots operational workspace,
thereby severely limiting its functionality [7, 8, 9, 10, 11].
This fragmentation creates a lose-lose situation, where robots
either sacrifice dexterous manipulation during movement or
compromise their workspaces when performing manipulation.
The path forward demands mutual perspective iteration: RL-
based training incorporates upper-body teleoperation interfaces
without compromising the robots athletic ability, and teleoper-
ation system seamlessly integrate locomotion control modules
while affording accurate and smooth pose acquisition. In re-
teleoperation system that integrates a RL policy for body
control mapped to a pedal, an isomorphic exoskeleton arm
for arm control, and motion-sensing gloves for hand control.
This unified cockpit enables a single operator to precisely and
efficiently control a humanoid robots full-body movements,
addressing both humanoid whole-body control and real-time
precise teleoperation.
Our RL-based training framework features three core tech-
symmetry utilization for action regularization and data aug-
mentation. These components collectively enhance the robots
physical agility, enabling robust walking, rapid squatting to
any required heights, and stable balance maintenance dur-
ing dynamic upper-body movements, thereby significantly
expanding the robots operational workspace beyond existing
solutions and allowing any teleoperation commands to take
effect. Unlike previous whole-body control methods that de-
pend on motion priors derived from MoCap data , our
framework eliminates this dependency, resulting in a more
efficient pipeline.
Complementing the training framework, our hardware sys-
tem features isomorphic exoskeleton arms, a pair of motion-
sensing gloves, and a pedal. The pedal design serves as an
effective interface for locomotion command acquisition, guid-
ing the robots movement while freeing the operators upper
body. This setup enables simultaneous acquisition of upper-
body poses and removes the need for continuous synchronized
walking between the operator and the robot. To eliminate
the inaccuracies introduced by inverse kinematics (IK) and
pose estimation, which are commonly used in mainstream
teleoperation systems, we design the exoskeleton arms to be
isomorphic to the controlled robot. This allows us to directly
set the upper-body joint positions based on the exoskeleton
and more accurate teleoperation. Each of our gloves offers 15
degrees of freedom (DoF), surpassing most existing dexterous
the same gloves. Additionally, the gloves can be detached
from the arms, making them reusable in systems isomorphic
to different robots. The total cost of the hardware system is
just 0.5k, significantly more affordable than motion capture
(MoCap) devices .
Through ablation experiments, we validate the effectiveness
of each technique in our training framework and demonstrate
the robustness of the resulting policies across different robots.
Our evaluation shows that the hardware system supports
200 faster and more accurate pose acquisition than pre-
vious methods, enabling operators to complete tasks more
efficiently than virtual reality (VR)-based approaches. Real-
world studies confirm that the trained policies can be deployed
directly in the real world, allowing robots to perform diverse
loco-manipulation tasks stably in complex environments. We
further show that real-world data collected via HOMIE can be
effectively used by imitation learning (IL) algorithms, allowing
humanoid robots to autonomously execute tasks. Integrated
into simulation environments, our cockpit also enables seam-
less teleoperation in virtual settings.
In summary, the key contributions of HOMIE are:
1) A novel humanoid teleoperation cockpit that combines
RL-based loco-manipulation control with an isomorphic
exoskeleton and motion-sensing gloves, enabling full-
body control by a single operator.
2) The first successful implementation of teleoperation-
compatible humanoid loco-manipulation, including dy-
namic squatting, without relying on motion prior data.
3) A cost-effective hardware system that supports more
precise and faster whole-body control than existing
II. RELATED WORKS
A. Teleoperation Systems
Teleoperating dual-arm robots to perform complex manip-
ulation tasks is an efficient way to collect real-world expert
tonomous skills [14, 7, 9, 17, 18]. Some researchers utilize
robotic arms identical to the teleoperated ones [19, 14, 15, 16],
making joint-matching possible, thus ensuring high accuracy
and fast response speed. However, due to the high cost of
robotic arms, the establishment of such a system incurs sig-
nificant expenses. Additionally, teleoperating dexterous hands
with these systems is not feasible.
An alternative approach is to use VR devices [7, 11] or just a
camera [20, 10, 21]. These works use vision-based techniques
to capture the operators wrist postures and key points of the
of the arms and hands. However, due to limitations in the
of pose estimation, such approaches cannot guarantee rapid
and accurate pose acquisition. Some researchers try to use
MoCap methods [13, 22, 23, 24] to acquire more accurate
poses at higher frequencies, but MoCap equipment is very
expensive. Moreover, since IK is an iterative method that
approximates solutions, even when wrist and hand poses are
captured accurately, the limitations of IK may prevent the
TABLE I: Comparison between representative teleoperation systems and HOMIE. Cost: total cost of each system. Arm and
Dex-Hand Tracking: method of tracking arm and hand poses. Loco-Manip.: whether or not have loco-manipulation capability.
Teleop System
Arm Tracking
Dex-Hand Tracking
Loco-Manip.
Whole-body
No MoCap
Mobile-ALOHA
Joint-matching
Joint-matching
Joint-matching
Joint-matching
Vision Retarget
Vision Retarget
Mocap  SLAM
AnyTeleop
Vision Retarget
Vision Retarget
OpenTelevision
VR devices
VR devices
HumanPlus
Vision Retarget
Vision Retarget
Vision  VR
Vision  VR
Mobile-TeleVision
VR devices
VR devices
HOMIE (Ours)
Joint-matching
Joint-matching
robot from achieving the desired posture. Another possible
solution is an exoskeleton-based teleoperation system, which
does not require an additional identical robot, thus the overall
cost is relatively low. Some research calculates the end-
effector pose of the exoskeleton using Forward Kinematics
(FK) and then apply IK to determine the robots joint positions,
while using computer vision techniques to capture the hand
poses . However, these systems are also limited by the
inaccuracies of IK and pose estimation.
Some studies utilize isomorphic exoskeletons [15, 16],
which can also employ joint-matching to teleoperate the
frequency. Neverthless, these systems typically handle robotic
arms equipped with grippers, limiting their application to basic
manipulation tasks rather than dexterous ones. Since some
projects have introduced cheap and reliable motion-sensing
gloves [25, 26], redesigning and combining them with an ex-
oskeleton could potentially overcome this limitation, a solution
that has not yet been realized in this field. HOMIE is designed
to combine all the advantages mentioned above, integrating
isomorphic exoskeleton arms with a pair of novel motion-
sensing gloves. We will introduce this system in Sec. III-C.
A comparison between HOMIE and previous representative
teleoperation systems can be found in Tab. I.
B. Whole-body Loco-Manipulation
To enable robots to perform whole-body loco-manipulation
algorithms [27, 28, 29, 30, 31], particularly generating lo-
comotion control laws by solving optimal control problems
(OCPs). Despite significant efforts to make OCPs computa-
tionally tractable, these algorithms still struggle with complex
scenarios due to their high computational demands during
online processing. Reinforcement Learning (RL)-based algo-
tion (PPO) , offer a more powerful alternative. Using
these methods, several studies successfully achieve whole-
body loco-manipulation in quadruped robots [33, 34, 35, 36],
and some teach humanoid robots to traverse various ter-
rains [37, 38, 39, 40, 41, 42, 43, 44] or perform parkour .
Achievements in quadrupeds motivate researchers to ap-
ply the same techniques to humanoid whole-body loco-
manipulation . Some studies train whole-body policies for
humanoid robots , enabling them to act in a manner similar
to human operators or even dance with people. Some other
research separates the upper and lower body [4, 1, 2, 3, 6],
using policies trained by RL to control the lower body while
directly setting the joint positions of the upper body, thus help-
ing robots achieve better balance. Despite achieving impressive
motion prior  for training robots. However, obtaining
MoCap data is costly, and adapting robots to new poses
necessitates additional data collection, which significantly
hinders the scalability of these approaches. Second, many
of these methods employ vision-based algorithms to estimate
the operators poses, which lack the precision of exoskeleton-
based devices. This limitation reduces the accuracy required
for humanoid robots to perform loco-manipulation tasks ef-
fectively. Third, these methods generally fail to incorporate
the ability to control a robots body height. Height control
is crucial for handling objects at varying elevations, and its
absence severely restricts the robots operational workspace.
rely on body movement data directly [4, 1, 2, 3], while others
use joysticks or pedals . The former approach becomes
impractical when operators need to control robots in large-
scale environments, whereas the latter offers a more effective
solution. However, controlling with joysticks necessitates the
use of hands, which may already be occupied by other manual
locomotion commands.
Joint-matching pose
Locomotion
commands
Real      Sim
Walk and Squat
(a) Humanoid Whole-body Teleoperation
FPV robot image
(b) Policy
Exoskeletons
Motion-sensing Gloves
Fig. 2: System Overview. (a): how an operator uses the exoskeleton-based hardware system to control humanoid robots in the
real world and simulation. (b): how loco controls the robots, the data collection process for training auto, and how auto
takes over the operator to control the robots. Communication between the cockpit and the robot is achieved via Wi-Fi.
III. METHOD
A. System Overview
As shown in Fig. 2, HOMIE consists of a low-level policy
loco and an exoskeleton-based hardware system. At any given
time t, the first point of view (FPV) of the robot will be
transferred by Wi-Fi to the display inside the cockpit, so
the operator can teleoperate the robot with FPV. By stepping
on the pedal, the operator provides the required locomotion
commands Ct  [vx,t, yaw,t, ht] where vx,t is the desired
forward or backward speed, yaw,t is the turning speed, and
ht is the target height of the robots torso. The policy loco
controls the robots lower-body based on Ct. Meanwhile, the
operator controls the exoskeleton to provide the required joint
angles qupper for the robots upper-body, which are directly set
to the robot. The upper and lower bodies work in coordination,
continuously cycling through the process, ultimately enabling
teleoperating robots to complete loco-manipulation tasks either
in the real world or in simulation. Communications between
the cockpit and the robot are achieved via Wi-Fi, allowing
operation even when the robot is far from the hardware
system. We can collect demonstrations while teleoperating
the robot and use them to train an autonomous policy auto.
Once trained successfully, auto can take over the operator to
give Ct and qupper, thus driving the robot to perform tasks
autonomously.
B. Humanoid Whole-body Control
To enable humanoid robots to perform loco-manipulation
different robots to accomplish squatting and walking under
continuously changing upper-body poses. We take Unitree G1
as an example and show the process of the framework in Fig. 3.
The policy loco trained by this process is capable of zero-
Optimizer
Isaac Gym
Fig. 3: RL training framework of HOMIE.
shot sim-to-real transfer. We introduce the training settings
and three key techniques of our framework in this section.
1) Training Settings: The observations of one step are
defined as Ot  [Ct, t, gt, qt, qt, at1], where Ct is the
of g  [0, 0, 1] in the robots torso coordinate frame, qt is the
joint angles of all joints of the robot, qt is the joint velocities of
all joints of robot, at1 is the last time action. Then we can get
the whole observations of loco by concatenating Ot5:t. The
actions at of the policy correspond one-to-one with the joints
of the robots lower body. After the neural network computes
at based on Ot5:t, we use
to calculate the torques for joint motors, thereby driving the
motors to work and enabling the robots movement. In the
stiffness and damping of each joint, {q0,t,i} are default joint
positions of each joint. Our framework is implemented based
on the code of
[48, 49], and more training details can be
found in Appendix A.
2) Upper-body Pose Curriculum: We use a curriculum
learning technique to ensure that loco can still complete
locomotion tasks under any continuously varying poses of the
robots upper-body. We adjust the sampling range of the upper
body joint angles using the upper action ratio a. At the start
of training, ra is set to 0. Each time the policy drives the robot
to track the linear velocity with a reward function that reaches
the threshold, a increases by 0.05, eventually reaching 1. We
first sample
a from the probability distribution
aa)  20(1 a) e20(1rhoa)
and then resample ai by U(0,
a). We actually sample ai by
ai  U(0,
20(1 a) ln
As ra increases, the probability distribution gradually tran-
sitions from being close to 0 to U(0, 1). This ensures that
during the curriculum process, the probability distribution
consistently satisfies p(
Compared to directly using U(0, a), this method approaches
the final target in a more gradual and smoother manner. For
better understanding of Eq. (3), we visualize it in Appendix A.
To simulate the continuous changes in upper body movements
when controlled by our cockpit, we resample target upper-
body poses every 1 second according to the above process.
We then use uniform interpolation to ensure that the target
movement gradually changes from the current value to the de-
sired value over the 1-second interval. Without this approach,
we find that the robot struggles to maintain balance under
continuous motions.
Fig. 4: Different robots are trained to walk and squat with
continuous changing upper-body poses in Isaac Gym.
3) Height Tracking Reward: Tracking heights can signif-
icantly expands the feasible operational workspace of hu-
manoid robots, thus helping the robots perform more loco-
manipulation tasks. Therefore, loco needs to enable the robot
to squat to the target height ht. To achieve this, we design a
new reward function
rknee  (hr,t ht)  ( qknee,t qknee,min
where hr,t
is the robots actual height, qknee,min
rknee encourages flexion of the knee joints when hr,t < ht,
and encourages extension when hr,t > ht. In the training
train the robot to squat, while the remaining two-thirds focus
on teaching the robot to stand and walk. This strategy helps
balance the learning of squatting and walking. Additionally,
the same environment switches between learning to squat and
learning to walk, enabling the policy to smoothly transition
between squatting and walking tasks. For better understanding
of Eq. (4), we visualize it in Appendix A.
4) Symmetry Utilization: We introduce the same trick as
to our training framework. Each time we obtain a tran-
sition Tt  (st, at, rt, st1) from the simulation, we perform
a flip operation on it. Specifically, we apply symmetry to the
actor and critic observations with respect to the robots x-z
plane. This involves flipping elements such as the positions,
well as the desired turning velocity, across the x-z plane to
obtain a mirrored transition T
t. Both Tt and T
t are then added
to the rollout storage. This process helps to improve data
efficiency and ensure symmetry in the sampled data, reducing
the likelihood of the trained policy being asymmetrical in
terms of left and right performance. In the learning phase,
we also apply this procedure to the samples Tt got from the
rollout storage to get T
t. Both Tt and T
t are passed through the
actor and critic networks to obtain at, a
t respectively,
which are used to calculate additional losses:
sym  MSE(at, a
sym  MSE(Vt, V
These two losses are added to the network optimization
C. Hardware System Design
To enable a single operator to control the full body of
humanoid robots, we design a low-cost exoskeleton-based
hardware system as shown in the left part of Fig. 2. For the
upper-body teleoperation of the humanoid robots, we design
3D-printed 7-DoF isomorphic exoskeleton arms for precise
mapping of the upper limb joint angles, specifically tailored
for two types of humanoid robots: Unitree G1 and Fourier GR-
1. Additionally, we design a pair of low-cost motion-sensing
gloves capable of mapping up to to 15 DoF of finger angles.
For locomotion command acquisition, we design a foot pedal
that simulates the press-and-release actions of the foot during
such as walking and squatting. The operator can easily deploy
this system and perform single-person teleoperation of the
robots loco-manipulation, similar to driving a car in a cockpit
or playing a racing game.
Fig. 5: Upper-body Exoskeleton. (a): The model architecture and physical demonstration of motion-sensing gloves. (b): The
structural architecture of the upper-body exoskeleton system, comprising an isomorphic exoskeleton and motion-sensing gloves,
with kinematic mapping methodology between the isomorphic exoskeleton and Unitree G1.
1) Isomorphic Exoskeleton: To achieve accurate control
and mapping of the upper limb joints of the humanoid robots,
we employ an isomorphic exoskeleton as the teleoperation
solution for controlling the robots upper body. Based on
the morphology of the Unitree G1 and Fourier GR-1, our
isomorphic exoskeleton design consists of a symmetric pair
of arms, each with 7 DoF, corresponding to the 7 DoF of
each arm of the robot (3 DoF for the shoulder, 1 DoF for the
joint of the exoskeleton is equipped with a DYNAMIXEL
XL330-M288-T servo, which provides joint angle readings
and adjustments with an accuracy of 0.09, enabling precise
joint angle mapping and initial calibration. Compared to
incremental encoders, servo motors can store absolute position
and retain the current position data even after power loss,
thus eliminating recalibration upon restarts. The exoskeletons
operational part is designed to match the length of the human
arms. Considering the challenge of fully replicating the robots
upper arm structure, we align the servos with the robots motor
URDF joint coordinate system. We can obtain the offsets ot
between the servos position angles pt and the robots joint
angles qt. Since Dynamixel servos can store absolute positions,
ot remains fixed after assembly. Additionally, the servo disc
has four symmetric holes, which causes ot to be an integer
multiple of 2. We use
qt  kt(pt  nt
to achieve kinematic equivalence and calibration, where the
offset follows ot  nt
nt Z , with kt is a coefficient
that adjusts the direction and scale of the angle change, and t
is the additional joint angle compensation. We set kt  1 and
t  0, meaning no additional scaling or angle compensation
is needed.
2) Motion-sensing Gloves: For fine teleoperation of the
Nepyone glove project , we design a low-cost motion-
sensing glove that connects directly to the exoskeleton for
assembly and use, providing up to 15 DoF for finger capture to
control dexterous hands. Specifically, each finger is equipped
with three sets of sensors, which map the pitch motion of
the finger tip and finger pad, as well as the yaw motion of
the finger pad. This setup is sufficient to enable the mapping
of different dexterous hands for humanoid robots. We place
Hall effect sensors and small neodymium magnets at each
joint. When the joint rotates, the neodymium magnet rotates
as well, thereby affecting the magnetic field sensed by the
sensor and achieving the mapping of finger joint angles.
on the back of the hand and can be directly connected to the
packaged sensors using terminal connectors, allowing for easy
plugging and unplugging to reassign and modify the mapping
sensing gloves can be easily attached to and detached from
different exoskeletons, offering high versatility.
Velocity
Velocity
Switching
Switching
Backward
Fig. 6: Pedal command control. The three small pedals re-
spectively control [0, max], [Hmin, Hmax], and [0, Vmax].
The left-side switching button is used to toggle between left
and right modes, while the right-side switching button is used
to toggle between forward and backward modes.
3) Foot Pedal: In our cockpit, the foot pedal is used as a re-
placement for a remote controller, enabling command control
of the humanoid robots lower body by giving commands Ct to
loco. The operator controls the acceleration and deceleration
of the robots lower body movement by pressing and releasing
Lin. Vel. Error (ms)
Ang. Vel. Error (rads)
Height Error (m)
Sym. Loss
Living Time (s)
Fig. 7: Ablation experiments of our RL training framework. Each row from top to bottom represents the ablation study for
upper-body curriculum, height tracking reward, and symmetry utilization, respectively. Each column represents the evaluation
of the corresponding metrics for checkpoints under different ablation settings. The and symbols beside the metrics indicate
whether a higher or lower value is better for the respective metric.
the foot pedal. We use high-precision rotary potentiometers
to map pedal pressure changes to electrical signals. In our
linear velocity, yaw velocity, and height adjustment. These
commands allow the robot to fully demonstrate its locomo-
tion capabilities. To achieve this, we use three small pedals
to control these commands. Additionally, a pair of mode-
switching buttons (foot-operated with momentary switches)
are used to toggle between forwardbackward and leftright
turning directions, as shown in Fig. 6. Users can modify the
pedal configuration and reassign commands to adapt to diverse
movement combinations.
IV. EXPERIMENTS
A. Humanoid Whole-body Control
1) Ablation of training framework: In this section, we
perform ablation experiments on the proposed upper-body
pose curriculum, the height tracking reward, and the use of
symmetry. All ablation experiments are conducted based on
the methods described in Sec. III-B. For each setting, we
use three random seeds to train policies for Unitree G1 and
evaluate them in 1000 environments over a 20-second eval-
uation period with random upper-body poses sampled from
Eq. (3) with a 1. Metrics for evaluation are tracking linear
velocity error, tracking angular velocity error, tracking height
each setting is obtained by computing the average and standard
deviation of the results across the three policies trained from
three random seeds. All trainings are conducted on Nvidia
RTX 4090 and simulated by Isaac Gym with 4096 parallel
are kept unchanged, and only relevant parts are modified for
training. Detailed parameters used in training and evaluation
processes are listed in Appendix A. We mark the setting of
our proposed method as ours in the following sections.
Upper-body Pose Curriculum. We compare ours against
two alternatives: wo cur, which omits the curriculum and
directly samples ai  U(0, U(0, 1)), and rand, which uses
the same a curriculum but replaces Eq. (3) with ai
U(0, U(0, a)). Since all three methods adopt the same sam-
pling strategy ai  U(0, U(0, 1)) as a 1, the final
objective remains consistent, ensuring a fair comparison. The
experimental results, shown in the first row of Fig. 7, reveal
that ours outperforms both wo cur and rand in linear velocity
faster convergence and smaller errors. There is no significant
difference between wo cur and rand in the final results for
these metrics. Given that the symmetry loss can reach values
on the order of 20 without constraints, no significant difference
is observed across the three methods in terms of symmetry
loss. All three configurations achieve similar final living times,
but ours and wo cur converge more quickly. Rand, despite
employing some curriculum adjustments, is limited by a, and
values in the range (a, 1] are not sampled during training,
making it harder for the model to converge as a increases.
In contrast, both ours and wo cur sample the full [0, 1]
range from the beginning, enabling faster and more stable
convergence. Thus, our curriculum approach leads to better
performance compared to rand. Although wo cur does not
use a curriculum, allowing ai to continuously sample from
[0, 1], the lack of difficulty smoothing leads to worse final
tracking results, highlighting that our curriculum design offers
a more effective training process.
Height Tracking Reward. We design two additional al-
gorithms wo knee, which does not use rknee described in
Eq. (4) and hei, which also omits rknee but increases the
scale of the height tracking reward. We show the results in
the second row of Fig. 7. As shown in the figure, none of the
three settings cause significant changes in the symmetry loss
during training. In terms of linear velocity error and angular
velocity error, ours and wo knee perform similarly, while
hei shows much larger errors. For height error, our method
converges faster than both wo knee and hei, even though hei
initially performs better (at 400 steps). There is no significant
difference among the three settings in terms of living time.
These results indicate that just scaling up the height tracking
reward in hei may initially lead to faster reduction in height
tracking error, but it negatively affects the feedback from
other rewards, preventing the robot from balancing multiple
tasks effectively. In fact, hei ultimately does not achieve faster
convergence in height tracking compared to ours. In contrast,
the inclusion of rknee in our method provides more specific
guidance for squat tracking, allowing the robot to reduce
tracking error and converge more quickly. This highlights the
effectiveness of rknee in helping the robot learn squat motions.
Symmetry Utilization. We introduce three algorithmic vari-
ants for comparison with ours in terms of symmetry utiliza-
w sym, which only uses symmetry loss; and none, which
does not employ symmetrical data augmentation or symmetry
loss. Testing results are presented in the third row of Fig. 7.
Except for symmetry loss, the performance of ours and w
aug is similar. However, when considering overall tracking
aug exhibits a very high symmetry loss, suggesting that using
symmetry loss helps maintain the robots left-right symmetry
in the learned policy. This indirectly supports the idea that a
symmetric policy benefits the robots locomotion tasks .
Both nsym and none show a tendency for improvement, but
their training speed is much slower. Notably, a direct compar-
ison between w sym and none reveals that w sym achieves
lower symmetry loss. However, due to slower training, none
exhibits less symmetry breaking compared to w aug. In
training efficiency, while the use of symmetry loss effectively
prevents the policy from sacrificing symmetry to complete
tasks and also benefits the task itself.
2) Training on Different Robots: We select another kind of
to demonstrate the generality of our approach across different
robot models. As shown in Fig. 8, Fourier GR-1 is much taller
and heavier than Unitree G1 while having lower hand weight
ratio. Compared to the training setting of Unitree G1, we only
change the range of height tracking and some robot-specific
distance values, without any other changes in reward scales or
training pipeline. We evaluate the policy trained after 2k steps
Unitree G1
Fourier GR-1
130 cm Height
165 cm Height
56 Kg Weight
36.4 Kg Weight
1.04Kg Hands
1.42Kg Hands
1.9 Hand
Weight ratio
3.9 Hand
Weight ratio
6DoF Hand
7DoF Hand
Fig. 8: Key parameters of Unitree G1 (left) and Fourier GR-1
(right). Hand weight ratio  total weight  hands weight.
of each robot with metrics used in Sec. IV-A1 and present them
in Tab. II. The results demonstrate that even though these two
kinds of robots are quite different, our RL training framework
can train them to converge to a policy which can drive robots
to perform locomotion and squatting tasks robustly under any
upper-body poses. Training details for Fourier GR-1 can be
found in Appendix A.
TABLE II: Evaluation of different robots trained with our RL
training framework
Unitree G1
Fourier GR-1
Lin. Vel Error (ms)
Ang. Vel Error (rads)
Height Error (m)
symmetry loss (-)
Living Time (s)
B. Teleoperation Hardware Performance
We list a series of hardware indicators for our teleoperation
hardware system consisting of isomorphic exoskeleton arms,
a pair of motion-sensing exoskeleton gloves, and a pedal
in Tab. III. We detail their costs, with the primary expense
attributed to the exoskeleton section. This is because we
independently design and solder the control boards (PCBs) and
sensor modules for the motion-sensing gloves and the pedal
components. The acquisition frequency represents the update
signal frequency measured between the hardware components
of the teleoperation system and the host computer via a wired
connection at a baud rate of 115200. Changing the baud rate
can affect the acquisition frequency. The acquisition accuracy
represents the range of angular change (in degrees) and the
corresponding variation in acquisition readings, ranging from
0 to 4095( 212). Since the mapping relationship for the motion-
sensing gloves is not a clearly defined linear one, and the
mapping angles for each finger joint vary, more detailed
information can be found in the Appendix B-B. For upper-
body teleoperation, the task can be divided into two parts:
arm control and dexterous hand control. We select the arm
pose frequency and hand pose frequency as evaluation metrics,
TABLE III: Hardware Indicators of three component of the
hardware system.(Freq.:frequency, Acc.:accuracy)
Hardware
Acquisition Freq.
Acquisition Acc.
Exoskeleton
0.26 kHz
212(with 360)
30 (each)
212(with 270)
which measures the smoothness and fluidity of teleoperation.
In Tab. IV, we compare the visual and VR schemes with
our joint-matching scheme. Since our joint-matching scheme
directly sets the robots upper-body poses without the need for
additional time-consuming processes, the output frequency to
the robot closely matches the acquisition frequency. Therefore,
our approach achieves a very high output frequency without
requiring GPU and System on Chip (SoC) intensive hardware.
TABLE IV: Upper-body teleoperation frequency of output to
the robots arm and hand. (SoC: System on Chip)
Teleop system
Hardware
Arm (Hz)
Hand (Hz)
Telekinesis
2 RTX 3080 Ti
AnyTeleop
RTX 3090
OpenTeleVision
No GPU  SoC
To further demonstrate the extensibility of our motion-
sensing gloves, we test different types of dexterous hands
from the Dex Retargeting library in AnyTeleop  within
the SAPIEN  environment. The results are presented in
Fig. 9, with the upper line shows names of tested dexterous
hands while the lower line indicates number of joints of each
16Joints
20Joints
12Joints
20Joints
Our Gloves
15Joints
Fig. 9: Controlling different types of dexterous hands in
simulation with our motion-sensing gloves.
C. Teleoperation System
1) Real World: We deploy the trained policy on the Unitree
G1 in the real world and teleoperate it to perform various
loco-manipulation tasks using our isomorphic exoskeleton
hardware system. We employ WiFi for communication be-
tween the cockpit and the robot. Since our system requires
only 128 bytes(32-bit floats) per data packet, the measured
communication latency under normal network conditions is
16 ms  a result considered acceptable for real-time control.
checksum verification to guarantee data transmission integrity.
The deployment code for G1 is derived from . Fig. 1 (a)
Fig. 10: Desktop tasks for comparison of completion time. a:
Pick  Place; b: Scan Barcode; c: Hand Over; d: Open Oven.
and Fig. 1 (c) demonstrate the robots capability to squat, pick
objects from lower shelves, and place them on higher ones, as
well as to grasp and transfer boxes between shelves utilizing
its locomotion abilities. Fig. 1 (b) highlights the extensibility
of our system, enabling two operators to control separate
robots and collaboratively perform tasks, such as transferring
apples. In Fig. 1 (d), the robot is controlled to push a 60
kg person sitting in a chair, who weighs roughly twice as
much as the robot, demonstrating the robustness of the loco-
manipulation system. Fig. 1 (e) illustrates how the robot uses
its loco-manipulation abilities to open an oven by grasping
the handle and moving backward simultaneously. Fig. 1 (f)
shows that our teleoperation system is capable of performing
dual-hand collaborative tasks, such as one hand passing an
object to the other. Fig. 1 (g) demonstrates the robots ability
to grasp objects from low ground, while Fig. 1 (h) shows
the robots capability to lift and place heavy items, such as
a bundle of flowers, into a box using both arms. Fig. 1 (i)
demonstrates how the robot maintains balance with different
upper-body poses. In all these tasks, each robot is controlled by
a single operator, and the communication between the robot
and operator is facilitated via Wi-Fi, without restricting the
robots movement space. These tasks showcase the robustness
of our loco-manipulation policy and HOMIE s ability to
teleopeate humanoids perform a wide range of complex tasks
in various environments.
Pick  Place
Scan Barcode
Hand Over
Open Oven
Completion Time (s)
Fig. 11: Comparison of completion time to perform desktop
tasks between our hardware system and OpenTelevision .
To demonstrate the efficiency of our teleoperation system,
we compare the task completion time between our hardware
system and a VR-based method, OpenTelevision , across
four tasks as shown in Fig. 10. These tasks are designed to
evaluate the systems ability to precisely control the robots
arms and hands in various scenarios: Pick  Place: The
robot is required to grasp a tomato from the table and place
it into a fruit basket. Scan Barcode: The robot must hold a
on a box. Hand Over: The robot needs to grasp a tomato
and pass it to another hand. Open Oven: The robot must
insert its finger into a handle and open the oven door. These
tasks test key capabilities of teleoperation, including precise
control. The results, shown in Fig. 11, indicate that our system
achieves task completion times nearly half of those of the VR-
based method. Notably, when tasks require precise positioning
and orientation, the performance gap between our system
and the VR method becomes even more pronounced. This is
because VR-based pose estimation tends to perform poorly in
tangential directions, whereas our exoskeleton-based approach
avoids such issues entirely. These results demonstrate that
our exoskeleton system enables operators to teleoperate robots
more smoothly and efficiently, particularly in tasks requiring
high precision and dexterity.
Duration (s)
Trial Time
Avg. User
Fig. 12: Teleoperation learning curves. New users can
quickly achieve expert speed on a new task with our hardware.
2) User Study: We recruit five testers with varying heights,
teleoperating Unitree G1 in Hand Over task. All novices
dont have any prior experience using the system or teleop-
erating humanoid robots. Each trial begins with the operator
positioning both the robot and a tomato at identical designated
starting points. Upon the Start command, timing commences
as the operator guides the robot to first grasp the tomato with
one manipulator, then transfer it to the secondary manipulator.
The trial concludes when the tomato is securely gripped by
the receiving manipulator and the initial manipulator has fully
retracted. The elapsed time from initiation to successful trans-
fer completion is recorded as the completion time, serving
as the primary metric for evaluating operator proficiency with
this system. After a brief tutorial, we record their completion
times across five consecutive attempts. As shown in Fig. 12,
the average novice time progressively approached expert-level
performance despite significant physical differences among
operators. This rapid improvement demonstrates our systems
intuitive usability. This result also shows out systems strong
adaptability to diverse body types with straps. Tester profiles
with raw timing data are detailed in Appendix D-A, and the
operational protocol in Appendix D-B.
3) Simulation: We transfer the trained policies for Unitree
G1 and Fourier GR-1 from Isaac Gym to a scene devel-
oped by GRUtopia , which is based on Isaac Sim and
IsaacLab . This migration enables the use of HOMIE to
control robots within a variety of simulated environments.
By leveraging these simulated scenes, the robots can perform
diverse loco-manipulation tasks more cost-effectively and in
a wider range of scenarios than would be feasible in the real
world. As shown in Fig. 13, operators can seamlessly direct the
robots movements and actions in complex, realistic settings,
demonstrating the versatility and applicability of HOMIE in
diverse simulated contexts.
Fig. 13: Simulation migration. The upper row illustrates how
the operator controls the robot with FPV to perform loco-
manipulation tasks. The lower row demonstrates the robot
navigating through realistic simulated environments.
D. Autonomous Policy
1) Data Collection: To validate the effectiveness of the
demonstratons collected by HOMIE for IL algorithms, we
design two distinct tasks: Squat Pick: squatting to pick a
tomato on the lower sofa; Pick  Place: picking and placing
a tomato. We capture RGB images, robot states qt, the upper-
body commands qupper, and the locomotion commands Ct at
for image capture can be found in Fig. 14.
Fig. 14: Hardware Setup
for Imitation Learning
2) Training Setting: We adopt
an end-to-end visuomotor con-
trol policy that takes images and
robot proprioceptive signals as
inputs and continuously outputs
robot control actions. We employ
a model named Seer , which
features an autoregressive trans-
former architecture. Multi-view
images are processed through a
MAE-pretrained ViT encoder, and
the features of robot propriocep-
tive states are extracted using an
MLP. These features are subse-
quently concatenated into tokens.
The information of these tokens are then integrated by a trans-
former encoder. The transformer encoder utilizes an autore-
gressive method to generate latent codes for controlling upper
arm joints, dexterous hand movements, and height commands.
The final control action output is generated by three distinct
regression heads. The whole network are optimized using
SmoothL1 loss. In real-world training scenarios, we configure
the sequence length to 7, with both visual foresight and action
prediction steps set to 3. We employ the MAE pre-trained ViT-
B encoder, using bfloat16 configuration to speed up inference.
This model is trained on eight A100 GPUs for 40 epoches, and
we select the checkpoint with the lowest average validation
loss for evaluation.
TABLE V: Success Rate of Imitation Learning Tasks
Squat Pick
Pick  Place
Success Rate ()
3) Learning Results: After training with collected data, we
deploy the trained model to humanoid robot in the real world,
with the trained auto taking over operator to control the
robot. We employ an Nvidia RTX 4080 to run the trained
Fig. 15: Autonomous policy controlling robot to perform
tasks. a: Squat Pick; b: Pick  Place.
model and send the output to robot. The detailed deployment
configuration are introduced in Appendix C. For evaluation,
we adopt the metric Success Rate (SR) of each task. After
testing each proposed task for 15 times, we report the result
as task success rate in Tab. V. This result shows that data
collected by our teleopertion system can actually drive robots
to complete complex whole-body loco-manipulation tasks.
Robots that controlled by auto to perform proposed tasks
are shown in Fig. 15.
V. CONCLUSION AND LIMITATIONS
In this paper, we introduce HOMIE, a novel humanoid
teleoperation cockpit for humanoid loco-manipulation. With
a low-cost isomorphic exoskeleton hardware system and a
humanoid loco-manipulation policy trained by our RL training
the whole body of humanoid robots and perform diverse loco-
manipulation tasks either in the real world or in the simulation.
Owing to the incorporation of an upper-body pose curriculum,
a height-tracking reward, and symmetry-based techniques, Our
training framework enables the development of robust loco-
manipulation policies, ensuring stable walking and squatting
capabilities across diverse robotic platforms, even under dy-
namically changing upper-body poses. Leveraging isomorphic
exoskeleton arms, HOMIE enables significantly faster task
execution than other systems, and our gloves are compatible
with multiple kinds of dexterous hands. We present several
ablation studies and real-world experiments to validate the
robustness and accuracy of our system. In addition, we show
the usability of collected data for IL.
Limitations Our policies still fall short of ensuring reliable
traversal over diverse terrains. Additionally, the 15-DoF design
of the motion-sensing gloves for the thumb does not fully align
with human anatomy, resulting in less intuitive and smooth
operation when controlling certain dexterous robotic hands.
The current system lacks force feedback, which limits its ef-
fectiveness in applications requiring precise haptic interaction.
waist even though our policy can support arbitrary upper-body
poses. Addressing these limitations will be a central focus of
our future research efforts.
VI. ACKNOWLEDGEMENT
This work is funded in part by the National Key RD
Program of China (2022ZD0160201), and Shanghai Artificial
Intelligence Laboratory. We would like to thank Huayi Wang,
Shi Zhang, Zichao Ye, Hanqing Wang, Zirui Wang, Tao
REFERENCES
Zipeng Fu, Qingqing Zhao, Qi Wu, Gordon Wetzstein,
and Chelsea Finn. Humanplus: Humanoid shadowing and
imitation from humans. In Conference on Robot Learning
(CoRL), 2024.
Tairan He, Zhengyi Luo, Wenli Xiao, Chong Zhang, Kris
to-humanoid real-time whole-body teleoperation. arXiv
preprint arXiv:2403.04436, 2024.
Tairan He, Zhengyi Luo, Xialin He, Wenli Xiao, Chong
Guanya Shi. Omnih2o: Universal and dexterous human-
to-humanoid whole-body teleoperation and learning.
arXiv preprint arXiv:2406.08858, 2024.
Xuxin Cheng, Yandong Ji, Junming Chen, Ruihan Yang,
Ge Yang, and Xiaolong Wang.
Expressive whole-
body control for humanoid robots.
arXiv preprint
Mazeyu Ji, Xuanbin Peng, Fangchen Liu, Jialong Li,
Ge Yang, Xuxin Cheng, and Xiaolong Wang.
trol. arXiv preprint arXiv:2412.13196, 2024.
Chenhao Lu, Xuxin Cheng, Jialong Li, Shiqi Yang,
Mazeyu Ji, Chengjing Yuan, Ge Yang, Sha Yi, and
Xiaolong Wang.
priors for humanoid whole-body control. arXiv preprint
Xuxin Cheng, Jialong Li, Shiqi Yang, Ge Yang, and
Xiaolong Wang.
immersive active visual feedback.
arXiv preprint
Shiqi Yang, Minghuan Liu, Yuzhe Qin, Runyu Ding,
Jialong Li, Xuxin Cheng, Ruihan Yang, Sha Yi, and Xi-
aolong Wang. Ace: A cross-platform visual-exoskeletons
system for low-cost dexterous teleoperation.
preprint arXiv:2408.11805, 2024.
Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen,
Xialin He, Ying Yuan, Xue Bin Peng, and Jiajun Wu.
Generalizable humanoid manipulation with improved 3d
diffusion policies.
arXiv preprint arXiv:2410.10803,
Yuzhe Qin, Wei Yang, Binghao Huang, Karl Van Wyk,
Hao Su, Xiaolong Wang, Yu-Wei Chao, and Dieter
robot arm-hand teleoperation system.
arXiv preprint
Aadhithya Iyer, Zhuoran Peng, Yinlong Dai, Irmak
Pinto. Open teach: A versatile teleoperation system for
robotic manipulation. arXiv preprint arXiv:2403.07870,
Naureen Mahmood, Nima Ghorbani, Nikolaus F. Troje,
Gerard
