=== PDF文件: Effective Sampling for Robot Motion Planning Through the Lens of Lattices.pdf ===
=== 时间: 2025-07-22 15:47:58.680158 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个最核心的最有代表性的中文关键词，要中文关键词（不能是英文，不能是多个，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Effective Sampling for Robot Motion Planning
Through the Lens of Lattices
Itai Panasoff and Kiril Solovey
Viterbi Faculty of Electrical and Computer Engineering
TechnionIsrael Institute of Technology, Haifa, Israel
itaipcampus.technion.ac.il, kirilsoltechnion.ac.il
AbstractSampling-based methods for motion planning, which
capture the structure of the robots free space via (typically
random) sampling, have gained popularity due to their scalability,
tic completeness and asymptotic optimality. Unfortunately, the
practicality of those guarantees remains limited as they do not
provide insights into the behavior of motion planners for a finite
number of samples (i.e., a finite running time). In this work,
we harness lattice theory and the concept of (, )-completeness
by Tsao et al. (2020) to construct deterministic sample sets that
endow their planners with strong finite-time guarantees while
minimizing running time. In particular, we introduce a highly-
efficient deterministic sampling approach based on the A
d lattice,
which is the best-known geometric covering in dimensions 21.
Using our new sampling approach, we obtain at least an order-of-
magnitude speedup over existing deterministic and uniform ran-
dom sampling methods for complex motion-planning problems.
advancing the practical applicability of sampling-based motion
planning.
I. INTRODUCTION
Motion planning is a key ingredient in autonomous robotic
ries for a robot operating in environments cluttered with
obstacles . Over the years, various approaches have
been developed for tackling the problem, including potential
approaches [40, 31, 34]. In this work, we focus on sampling-
based planners (SBPs), which aim to capture the structure of
the robots free space through graph approximations that result
from configuration sampling (typically in a random fashion)
and connecting nearby samples. SBPs have enjoyed popularity
in recent years due to their relative scalability, in terms of the
number of robot degrees of freedom (DoFs), and the ease of
their implementation .
Another key benefit is the ability of SBPs to escape local
minima (unlike potential fields) and global solution guaran-
tees (in contrast, optimization-based approaches , which
typically provide only local guarantees). Earlier work on
the theoretical foundations of SBPs has focused on deriving
probabilistic completeness (PC) guarantees for methods such
as PRM  or RRT [25, 23, 21]. PC implies that the
probability of a given planner finding a solution (if one exists)
converges to one as the number of samples tends to infinity.
The work of Karaman and Frazzoli  initiated studying the
quality of the solution returned by SBPs. Specifically, they
introduced the planners PRM and RRT, and proved that the
solution length of those planners converges to the optimum
as the number of samples tends to infinitya property called
asymptotic optimality (AO). Subsequent work has introduced
even more powerful AO planners for geometric [16, 11] and
dynamical [14, 28] systems.
theoretical findings remains limited due to the lack of mean-
ingful finite-time implications. Specifically, when a solution
is obtained using a finite number of samples, it is unclear
to what extent its quality can be improved with additional
computation time. Moreover, in cases where no solution is
if the algorithm simply failed to find one. Developing finite-
time bounds through randomized sampling continues to be a
significant challenge [7, 41].
Deterministic sampling methods such as grid sampling or
Halton sequences , where samples are generated according
to a geometric principle, can improve the performance of SBPs
in practice and simplify the algorithm analysis. Specifically,
some deterministic sampling procedures have a significantly
lower dispersion than uniform random sampling, which im-
plies that the former requires fewer samples to cover the
search space to a desired resolution . Recently, Tsao
et al.  have leveraged deterministic sampling to disrupt
the asymptotic analysis paradigm by introducing a signifi-
cantly stronger notion than AO, called (, )-completeness,
that yields finite-time guarantees for PRM-based algorithms
such as PRM , FMT , BIT , and GLS .
approximation factor  > 0 and clearance parameter  > 0, if
the corresponding planner returns a solution whose length is at
most (1  ) times the length of the shortest -clear solution.
If no solution is found using a (, )-complete sample set then
no solution of clearance  exists.
The work of Tsao et al.  derived a relation between
(, )-completeness and geometric space coverage to obtain
lower bounds on the number of samples necessary to achieve
(, )-completeness, as well as upper bounds accompanied
with explicit (deterministic) sampling distributions. A follow-
up work by Dayan et al.  has introduced an even more com-
pact (, )-complete sample distribution that is more efficient
than the one proposed in  or rectangular grid sampling.
In particular, the staggered grid  consists of two shifted
Z2 sample set.
2 sample set.
2 sample set.
Sample sets within a fixed disc in R2, derived from the lattices Z2, D
and . The set X ,
Z2 can be viewed as a tessellation of space using cubes. The set X ,
2 is obtained by placing a (rescaled) standard grid, and then placing
another point in the middle of each cube. The set X ,
2 can be viewed as a rescaled hexagonal grid as each point is surrounded by a hexagon whose vertices
are points in the set. Note that the density of X ,
Z2 and X ,
2 is the same, and higher than the density of X ,
and rescaled copies of the rectangular grid (see Figure 1 and
Figure 2).
the lower bound in  and the upper bound obtained with the
staggered grid. In practice, this gap limits the applicability of
the (, )-completeness theory to relatively low dimensions (up
to dimension 6) due to the large number of samples currently
needed to satisfy this property, which can lead to excessive
running times.
Contribution. In this work, we develop a theoretical frame-
work for obtaining highly-efficient (, )-complete sample
sets by leveraging the foundational theory of lattices1 ,
which has been instrumental in diverse areas from number
(, )-complete sample sets (Theorem 1) and develop tight
theoretical bounds on their size (Theorem 2), which allows
to compare between different sample sets qualitatively. Using
this machinery, we not only refine and generalize previous
results on the staggered grid  but also introduce a new
highly efficient (, )-complete sample set that is based on
d lattice, which is famous for its minimalist coverage
properties . We also initiate the study of a new property,
which estimates the computational cost resulting from using
a given sample set in a more informative manner than sample
complexity. In particular, the property called collision-check
complexity captures the amount of collision checks, which is
typically a computational bottleneck.
From a practical perspective, when solving motion-planning
problems using lattice-based sample sets, we show that our
d-based sample sets can result in at least order-of-magnitude
improvement in terms of running time over staggered-grid
1Lattices are point sets exhibiting a regular geometric structure, which are
obtained by transforming the integer lattice Zd. For instance, the aforemen-
tioned rectangular grid and the staggered grid can be viewed as lattices.
samples and two orders of magnitude improvements over
rectangular grids. Moreover, A
d-based sample sets are vastly
superior in practice to the widely-used uniform random sam-
Organization. In Section II we review basic definitions on
motion planning and (, )-completeness, and formally define
our objectives. In Section III, we develop a general tool
for transforming lattices into (, )-complete sample sets. We
obtain sample-complexity bounds for lattice-based sample
sets in Section IV, and generalize those bounds to collision-
check complexity in Section V. We evaluate the practical
implications of our theory in Section VII, and conclude with a
discussion of limitations and future directions in Section VIII.
II. PRELIMINARIES
motion-planning
concerns
computing
collision-free path for a robot in an environment cluttered
with obstacles. We concider a holonomic robot with a con-
figuration space C  Rd. The dimension d 2 represents
the DoF and is finite. A motion planning problem is a tuple
of collision-free configurations), and qs, qg Cf are the start
and goal configurations, respectively. A solution for M is a
continuous collision-free path  : [0, 1] Cf that begins at
(0)  qs and ends at (1)  qg.
Two critical properties of a given path  for a problem
M  (Cf, qs, qg), are its length () 0, and its clearance.
For a given value  0, we say that the path  is -clear
0t1 B((t)) Cf, where B(p) is the d-dimensional
closed Euclidean ball with radius  > 0 centered at p Rd.
We denote B : B(o), where o is the origin of Rd.
A. Probabilistic roadmaps and completeness
We present a formal definition of the Probabilistic Roadmap
(PRM) method , which constructs a discrete graph captur-
ing the connectivity of Cf through sampling. Albeit sampling
usually refers to a randomized process, here we consider
deterministic sampling, as was recently done in [49, 4].2 We
emphasize that our analysis below is not confined to PRMs,
and applies to various PRM-based planners, as mentioned
For a given motion planning problem M  (Cf, qs, qg), a
sample (point) set X C, and a connection radius r > 0,
PRM generates a graph denoted by GM(X,r)  (V, E). The
vertex set V consists of all collision-free configurations in
X {qs, qg}. The set of undirected edges, E, consists of all
the vertex pairs u, v V such that the Euclidean distance
between them is at most r, and the straight-line segment uv
between them is collision-free. That is,
In this work, we are interested in obtaining sample sets
and connection radii for PRM that achieve a desired solution
quality in terms of path length. Unlike most theoretical results
for SBP, which consider asymptotic guarantees, here we rely
on a stronger deterministic notion.
Definition 1 ((, )-completeness ). Given a sample set
X C and connection radius r > 0, the pair (X, r) is (, )-
complete for a clearance parameter  > 0 and stretch factor
> 0, if for every -clear problem M  (Cf, qs, qg), the graph
GM(X,r) contains a path from qs to qg with length at most
(1  ) times the optimal -clear length, denoted by OPT.
That is, it holds that
(GM(X,r), qs, qg) (1  )OPT,
where (GM(X,r), qs, qg) denotes the length of the shortest
path from qs to qg in the graph GM(X,r).
The property of (, )-completeness has several key advan-
tages over asymptotic notions, such as PC and AO. First, there
exists (with probability 1) a finite sample set X and radius
r (0, ) that jointly guarantee (, )-completeness. Second,
if a solution is not found using a (, )-complete pair (X, r),
then no -clear solution exists. That is, (, )-completeness can
be used for deterministic infeasibility proofs . Third, the
computational complexity of constructing a PRM graph can
be tuned according to the desired values of  and .
B. Problem definition
A (, )-complete sample set X and radius r > 0 can be
obtained by constructing a so-called -cover .
Definition 2. For a given  > 0, a sample set X Rd is a
-cover if for every point p C  Rd there exists a sample
x X such that p x.
2With deterministic sampling, the term probabilistic in PRM can seem
misleading. Nevertheless, we choose to stick to PRM considering its popu-
larity and the underlying graph structure it represents, which is a key to our
analysis.
Note that the coverage property above is defined with
respect to the whole configuration space, rather than a specific
free space. The connection between (, )-completeness and
-cover is established in the following lemma.
Lemma 1 (Completeness-cover relation ). Fix  > 0 and
> 0. Suppose that a sample set X is a -cover, where
Then (X, r) is (, )-complete, where
The lemma prescribes an approach for constructing sample
sets and connection radii that satisfy the (, )-completeness
requirement. Considering that we will fix the radius r:
r(, ) throughout this work, we will say that a sample set
X is (, )-complete if the pair (X, r) is (, )-complete.
Lemma 1 still leaves a critical unresolved question: How do
we find a (, )-complete sample X minimizing the computa-
tion time of the PRM graph and subsequent methods? In this
The first deals with finding a sample set of minimal size, which
can be used as a proxy for computation time.
Problem 1 (Sample complexity). For a given  > 0,  > 0,
find a (, )-complete sample set X of minimal sample com-
Previous work [49, 4] has considered a slightly different
notion for sample complexity aiming to minimize the global
expression X C with a bounded C. We believe that our local
as typical problems have obstacles, and the solution lies in
a small subset of the search space. Furthermore, it would
allow us to obtain tighter analyses by exploiting methods from
discrete geometry that reason about ball structures.
Previous work has introduced several sample sets and
analyzed their sample complexity [49, 4]. In this work, we
consider more compact sets. Moreover, we introduce a new
notion that better captures the computational complexity of
constructing a PRM graph. In particular, we leverage the
observation that the computational complexity of sampling-
based planning is typically dominated by the amount of col-
lision checks performed . Furthermore, nearest-neighbor
computational complexity, can be eliminated for deterministic
lattice-based samples, which we describe below).
Collision checks are run both on the PRM vertices and
sampling of configurations along the edges and individually
validating each configuration. Thus, the total number of col-
lision checks is proportional to the total edge length of the
graph. We use this observation to develop a more accurate
proxy for computational complexity. In particular, we will
estimate the length of edges adjacent to the origin point
o Rd, which is a vertex in all the sample sets introduced
below. Moreover, due to the regularity of the sets, the attribute
below is equal across all vertices (in the absence of obstacles).
(Collision-check
complexity).
(, )-complete
minimal collision-check complexity, i.e., minimizing the
expression
III. LATTICE-BASED SAMPLE SETS
We derive sample sets optimizing sample complexity (Prob-
lem 1) and collision-check complexity (Problem 2) both in
theory and experiments. We focus on sample sets induced by
lattices.
A lattice is a point set in Euclidean space with a regular
structure .
Definition 3 (Lattice). A lattice  is defined as all the
linear combinations (with integer coefficients) of a basis3
E  {ei RN}m
i1 of rank 1 m N, i.e.,
ai Z, ei E
It would be convenient to view lattices through their gener-
ator matrices.
Definition 4 (Lattice generator). The generator matrix G of
a lattice  with basis E  {ei RN}m
i1 is an m  N
matrix such that for every 1 i m, the row i is equal to
ei. Note that
. Additionally, define
det() : det(GGt
A. Useful lattices
We describe three lattices, visualized in Figures 1 and 2. The
first lattice is a simple rectangular grid, which is provided to
benchmark more complicated and efficient lattices. Below, we
fix the dimension d 2.
Definition 5 (Zd lattice). The Zd lattice is defined by the
identity generator matrix I Rdd, with det(Zd)  1 [3,
More efficient sample sets can be generated via the D
lattice [3, p120]. This lattice was also presented in , where
it was called a staggered grid. In this work, we provide
improved sample complexity bounds for lattice-based sample
sets (including for the D
d lattice and the A
d lattice defined
later on), following , and develop theoretical bounds for
collision-check complexity.
3A basis can be of full rank (m  N) or subdimensional (m < N). A
basis can be non-unique.
Z3 sample set.
3 sample sets.
(, )-complete sample sets in R3 derived from the lattices Z3, D
3. Note the sets X ,
d coincide for d  3, and diverge for d 4.
Note that the density of X ,
3 and X ,
3 (also known as the Body-Centered
Cubic structure in crystallography), and is lower than the density of X ,
Definition 6 (D
d lattice). The D
d lattice is defined by the
generator matrix
with det(D
The following A
d lattice [3, p115] leads to even more
efficient sample sets. This lattice is also called a "hexagonal
grid", and was previously used for 2D path planning [1, 27].
This work is the first to consider its application in dimensions
d 3, and moreover, in the context of (, )-completeness
guarantees.
Definition 7 (A
d lattice). The A
d lattice is defined through
the generator matrix
with det(A
Note that A
d is contained in Rd1 (due to the number
of rows of the generator matrix), but the lattice itself is d-
dimensional as it lies in a d-dimensional hyperplane (for any
lattice point (x1, . . . xd1) A
d it holds that Pd1
i1 xi  0).
Our motivation for considering A
d is its low density, defined
as the average number of spheres (centered on lattice points)
containing a point of the space . In particular, A
d is the
best lattice covering (and best covering in general) in terms
of density for dimension d 5 (see ) and overall the best
known covering for d 21.
B. From lattices to (, )-complete sample sets
We derive sample sets from the lattices above by transform-
ing the lattices such that the resulting point sets lie in Rd and
form -covers (Lemma 1). To achieve that, we will leverage
the geometry of the lattices and their covering radius, which
is defined below.
Definition 8. (Covering radius ) For a point set X Rd,
a covering radius is defined to be
When considering the covering radius of A
in Rd1, we will abuse the above definition to refer to its
covering radius in the d-dimensional plane Pd1
i1 xd1  0.
Note that in order to cover Rd with balls of radius  > 0
centered at the points of a set X, it must hold that  fX .
Theorem 1. Fix  > 0,  > 0, and take as defined in
Lemma 1. Then the following sample sets are (, )-complete:
d  v, v Zdo
d is odd:
d  v, v Zdo
d is even:
d  v, v Zdo
d(d2) T  v, v Zdo
Rdd and a
Each of the new sample sets can be viewed as a lattice in
d is a lattice
with the generator matrix
d(d2) T t. Also, note that the
result above for X ,
d is a tightening of the result in  for
odd dimensions.
d require a transformation
to achieve (, )-completeness for a given value of  and . For
a given lattice , we compute a rescaling factor w > 0 such
that the covering radius of the lattice w is not bigger than
. This would imply that w is (, )-complete according
to Lemma 1. In particular, w  f 1
where f is the
covering radius of . Next, we consider each of the three
lattices individually.
The lattice Zd. This lattice can be viewed as a set of axis-
aligned unit hypercubes whose vertices are the lattice points.
The center point of a cube is located at a distance of
from the cubes vertices, which yields the covering radius
d. As a result, the sample set X ,
d Zd, is a
Visualization of embedding the lattice A
2 originally defined in R3
onto R2 via the mapping T. The blue rectangle represents the plane H, where
the corresponding A
2 lattice points are drawn in red. The points are generated
by taking integer vectors in Rd and applying the mapping Gt. H and A
reflected onto the plane H0  {x3  0} using the mapping PGt (denoted
by the green rectangle). The third dimension is removed via the mapping E
to yield the embedding of A
2 in R2.
The lattice D
d. We use the covering radius of D
depends on whether the dimension d is odd or even [3, page
120]. In particular, fD
, and fD
4 . This
immediately implies the definition of X ,
The lattice A
d. Recall that A
d has the generator matrix G :
d Rd(d1). As this is a mapping from d to d  1, we
start with the process of embedding A
d in Rd (see Figure 3).
covering radius as the original set in Rd1.
Any row i of G, denoted by Gi : (gi1, gi2, . . . , gi(d1)),
lies on the (hyper)plane H : {Pd1
j1 gij  0}. Thus, A
d itself
is contained in that d-dimensional plane. It remains to find a
transformation of A
d such that the dimension is reduced to d
while maintaining the structure of the points in A
In the first step, we reflect A
d lattice points onto the plane
where D : d  1, Id is an d  d identity matrix, and 1 is
the d  d matrix with 1s in all its entries. That is, we reflect
a lattice point p Rd1 by computing the value v  P  p.
(See the derivation of P in the supplementary material.)
It remains to eliminate the (d1)th dimension of the points
We finish by computing the an explicit mapping that yields
the embedding of A
d to Rd. In particular, we have the
embedding T(g) : EPGt(g), for g Zd, where T is as
specified in the statement of this theorem. (See the derivation
of T in in the supplementary material.)
For the final part, we wish to derive an (, )-complete
sample set X ,
d . Here, we first recall that the covering radius
d is equal to
12(d1) [3, page 115]. Considering that
reflections and embeddings are isometries, i.e., they preserve
distances between pairs of points, we can use the same
covering radius after mapping the points of A
d using T. Thus,
we obtain the rescaling coefficient wA
implies that X ,
dT  v, v Zd} is (, )-complete.
IV. SAMPLE COMPLEXITY
We derive the following lower and upper bounds on the
sample complexity of the sets X ,
Theorem 2 (Sample-complexity bounds). Consider a lattice
d} with a covering radius f, which yields the
(, )-complete set X ,
for some  > 0,  > 0. Then,
r Pd(r),
where r: 2f
, and Pd() R is the discrepancy
function .4
induced by the lattice  and the scaling factor f by exploiting
the relation between X ,
and the grid lattice Zd. In particular,
a ball with respect to X ,
can be viewed as a rescaled ball for
the Zd lattice. This allows the use of bounds on the number
of Zd points within an ellipse.
Fix a ball radius R > 0. Due to the rescaling performed in
Theorem 1 we transition from the lattice , which is a f-
cover for Rd, into the set X ,
, which is a -cover for Rd.
In particular, the rescaling factor is w : f, which is
multiplied by  to obtain X ,
d we also applied an
isometric transformation, but this does not change the scale
reasoning). Thus, the ball BR with respect to X ,
viewed as the ball B, where R  Rw
f. Thus,
BR   BR. For the remainder of the proof, we
wish to bound the expression  BR.
Let v  aG be a lattice  point, where a Zd. By
definition of the Gram matrix Gr : GGt
, we obtain
at  aG2  v2.
This leads to the relation
BR   {v  vR}  {a ZdaGrat 2
4For a value  > 0, P3()  (
log()) and P3()
Pd()  (d2) for d > 4. Notice that Pd can be negative. For two
functions f, g, the notation f()  O(g()) (or f()  (g())) means
that there exists a constant mu > 0 (or ml > 0) such that for a large enough
it holds that f() mu(g()) (or f() ml(g())).
R (Gr) Zd,
where Es (A) : {x RdxAxt s} for a matrix A and
d contains only rational numbers, and hence defines
a rational quadratic form, which allows us employ rational
ellipsoid bounds  for ER (Gr) Zd. Hence,
ER (Gr) Zd
R  Pd(R).
The expression in Equation (5) immediately follows by plug-
Discussion. The expression in Equation (5) is identical for our
three sample sets, except for the value of the covering radius
f. This highlights the fact that a smaller covering radii leads
to a lower sample complexity. Also, notice that the value f
is raised to the power of d in Equation (5), which emphasizes
the difference between the sets in terms of sample complexity.
See a plot of the sample complexity in theory and practice
in Figure 5, wherein X ,
d has the lowest sample complexity
(except in dimensions 3 where it coincides with X ,
d). Notice
that the theoretical bounds are well-aligned with the practical
For example, consider d  12, where the X ,
d sample set
is 4 times smaller than X ,
d. Even when this difference
is not as big, e.g., in dimension 6 where the size of X ,
1.63 times smaller than X ,
pact in terms of the running of the motion-planning algorithm
in experiments. This follows from the fact that the sample
complexity studied here corresponds to the branching factor
of the underlying search algorithm, which is known to have
a significant impact on the running time. In the next session,
we show that the superiority of X ,
d is maintained also for
the collision-check complexity metric.
V. COLLISION-CHECK COMPLEXITY
In this section, we seek to analyze the collision-check
complexity of our sample sets X ,
of the graph edges is a better proxy for the computational
complexity of constructing the resulting PRM than sample
complexity.
Recall that the collision-check complexity of a lattice-based
sample set X is CCX  P
xXBrx. A naive approach
to upper-bound CCX is to multiply the number of points in
a r-ball (which corresponds to the sample complexity of X)
Dimension
Sample complexity
Zd theory
Zd practice
d theory
d practice
d theory
d practice
A sample-complexity plot for the sample sets X ,
d with   1 and   2. The dashed line represents the theoretical
approximation (Equation (5)), where the asymptotic error term Pd is excluded.
The solid line depicts the practical value, i.e., the number of lattice points
within the r-ball in practice. Missing values are due to memory limitations.
with the radius r, i.e.,
CCX r X Br  r
r r Pd(r).
The following is a tighter bound, which reduces the coefficient
of the dominant factor of the naive bound.
Theorem 3 (CC complexity bound). Consider a lattice
d} with a covering radius f, which yields the
(, )-complete set X : X ,
for some  > 0,  > 0 and
dimension d 2. Then,
r r Pd(r),
where r: 2f
partitioning the r-ball into annuli. Consider a sequence of
k  1 2 radii 0 < rk < . . . < r0  r, where ri : dir and
d1. This leads to the bound
riX (Bri  Bri1)  rkX Brk
X Bri X Bri1
(ri ri1)X Bri
r  Pd(d2
(ri ri1)
ri  Pd(d2
(ri ri1)d
where ri  ri
. See the
supplementary material for the full details of this derivation,
including the motivation behind the definitions of ri and k.
By plugging the value of  in Equation (9), Equation (8)
follows. Notice that d < 1. Therefore, dd(d1) 1 < 0 and
dd1 1 < 0, so our expression in the parenthesis is less
than 1, which implies an improvement over the trivial bound
(Equation (7)).
Discussion. Theorem 3 leads to a constant-factor improvement
over the naive bound concerning the coefficient of the main
bound term. The value of  ranges from 0.751 for d  2 and
monotonically increases towards 1 as d (see a plot in the
supplementary material). Although our result currently leads to
modest improvement, we hope it will pave the way for tighter
bounds in the future. Nevertheless, our analysis emphasizes the
impact of the coverage quality of lattices on the running time,
which is more substantial than what the sample-complexity
bound suggests.
See a plot of the theoretical bound, along with the practical
values in Figure 5, where both values show similar trends.
With that said, the discrepancy between the leading value
in Equation (8) and the practical value is bigger than in
the sample-complexity case, which suggests that the result
in Theorem 3 could be tightened. Finally, note that collision-
check complexity is roughly an order of magnitude larger than
the sample complexity, particularly in higher dimensions.
VI. ALGORITHMIC IMPLICATIONS
In this section, we examine the algorithmic implications of
our theoretical results. We discuss the types of sampling-based
planners (SBPs) that can benefit from lattice-based sampling
(LBS), as defined in Theorem 1. We then discuss how to
efficiently generate the points of a given LBS X ,
. Finally,
we provide a pseudo-code for an SBP that we use in the
experimental results, while highlighting algorithmic aspects
that leverage the regularity of LBS.
Dimension
Collision complexity
Zd theory
Zd practice
d theory
d practice
d theory
d practice
A collision-check complexity plot for the sample sets X ,
d with   1 and   2. The dashed line represents the theoretical
approximation (Equation (8)), where the asymptotic error term Pd is excluded.
A. Batch planners
LBS is well suited for batch SBPs that generate a priori a
batch (or several batches) of samples, implicitly or explicitly
(see below), and process them simultaneously, where the
resulting graph structure is agnostic to ordering between the
is regarded as a sample batch. The multi-query planners
query planners BIT , AIT , TMIT , IRIS ,
multi-robot planners dRRT  and dRRT , to name just
a few examples, fit this description.
LBS does not fit, in its current form, within incremental
SBPs (e.g., RRT , RRG, or RRT ), which require the
ability to add new samples one by one as time permits (as
resulting graph structure in those algorithms depends not only
on the physical location of the samples but also on the order
in which they were processed. (We do believe that LBS could
be adapted for incremental processing, as we discuss in the
final section.)
B. Construction of lattice points
within an R-ball in Algorithm 1. Note that if R  r, the
above point set can be viewed as the neighbor set of the origin
vertex of the graph GM(,r) (assuming that BrCf). To
compute  R, we run a BFS search over the integer vectors
Zd starting from the origin vertex, and compute for each vector
v the resulting lattice point through x : vG while discarding
points outside of R, where G is the generator matrix of .
Algorithm 1: getLatticeNeighbors(G, R)
1 OPEN  {0}  initiallize search with center vertex
2 OPENnext   next layer of OPEN
3 VISITED ;
4 while !OPEN.empty() !OPENnext.empty() do
if OPEN.empty() then
switch to the next layer of neighbors
OPENOPENnext;
OPENnext  ;
p  OPEN.pop();
if p VISITED then
continue
VISITED.insert(p) ;
iterate over basis integer vectors {e1, . . . , ed},
where ei contains "1" in the ith coordinate, and
"0" elsewhere, in both directions
for i {1, . . . , d}, sign {1} do
e  sign  ei;
pnew  p  e  G  obtain next lattice point
if pnew VISITED OPEN OPENnext and
OPENnext.insert(pnew);
17 return VISITED
C. Implicit A
To demonstrate the impact of LBS in practice, we use
a single-query planner where an implicitly-represented PRM
graph GM(X ,
,r) is explored using a search heuristic, similar
to BIT , and GLS . Those state-of-the-art approaches
are well-suited for settings where samples are generated in
large batches, as LBS facilitates. We focus on the single-
query setting, as it allows us to experiment with more complex
problem scenarios (e.g., in terms of dimensions and tightness)
than in a multi-query setting, where the entire configuration
space needs to be explored, which requires additional memory
and compute time.
The planner we use, which is termed for simplicity implicit
A (iA), can be viewed as a simplified version of BIT with
a single sample batch searched using the A algorithm. iA
generates a sample set X from a given sample distribution
d or uniform random sampling). Instead of
constructing the entire PRM graph G : GM(X,r) resulting
from X and a given radius parameter r, iA constructs a partial
graph G G in an implicit manner, where the construction is
guided by the underlying A search. That is, when a vertex v
of G is expanded, its neighbors Nv within an r-neighborhood
are retrieved from X, and the edges between v and every
u Nv are collision-checked and added to the explored
portion of the graph G. For LBS, we set r : r.
We consider two flavors of iA. In the first flavors, denoted
by GLO, vertex neighbors (as Nv above) are retrieved by
calling a global nearest-neighbor (NN) data structure. Before
starting the A search, this data structure is initialized with
the set X.
Although the benefits of LBS over randomized sampling
are already apparent for the GLO flavor (especially X ,
as will be shown in the next section, the performance of
iA can be further improved by exploiting the local regular
structure of lattices. In the second flavor of iA, denoted by
are efficiently retrieved without NN data structures. Given a
lattice-based sample set X and a connection radius r > 0,
denote by Nx : Br(x) X the r nearest-neighbors of a
vertex x X. Then, for another sample x X it holds that
Nx. Hence, the computation of the neighbor set N0, discussed
of the run of the search algorithm, where the Nv is easily
obtained from vector operations.
We provide pseudo-code for iA-LOC in Algorithm 2. The
algorithm follows the structure of the standard A algorithm
by extracting vertices from the open list, with some small
modifications. The algorithm returns a path from qs to qg on
the graph GM(X, r) (or reports that none exists otherwise),
where X : X ,
. Without loss of generality, we assume
that qs X, and moreover, qs is the origin. Notice that X
is given to the algorithm as an implicit parameter, as is the
free space Cf. As mentioned earlier, the neighbor set of the
origin vertex is computed once (line 5), and this information is
then reused to compute the neighbor set of a general vertex q
(line 10). This is where iA-LOC differs from iA-GLO, where
the latter computes the neighbor set by running a nearest-
neighbor search algorithm, as is common in SBPs (i.e., iA-
GLO requires an explicit representation of the full sample set).
From an implementation standpoint, we mention that addi-
tional improvements can be obtained for iA-LOC by associat-
ing every sample q X with the integer vector v Zd such
that q : vG. This allows for efficient tracking of explored
vertices. For simplicity, we omit those fine details from the
VII. EXPERIMENTAL RESULTS
We study practical aspects of our theoretical findings in
motion planning for multi-robot systems and a manipulator
arm. We report comparisons between the three lattice-based
experiment studying the effect of the parameters  and  is
reported in the supplementary material.
A. Implementation details and planners
We evaluate the performance of the iA planner for LBS
using the LOC and GLO flavors, and for uniform random sam-
pling using the GLO variant. The experiments were performed
on an ASUS Vivobook 16x laptop equipped with an Intel
Core i9-13900H CPU, 32GB DDR4 RAM, and SSD storage,
running Ubuntu 22.04.5 LTS OS.
The planners were implemented in C within OMPL ,
with FCL  for collision detection, and GNAT  for
nearest-neighbor search (where applicable). The manipulator
Algorithm 2: iA-LOC (Cf, X, r, qs, qg)
1 g(qs)  0  cost-to-go of qs
2 OPEN  {qs};
3 VISITED  {qs} ;
4 PREV[qs]   Predecessor vertices along shortest
path to qs
5 N0 getLatticeNeighbors(X, r)  neighbors of qs
6 while OPEN not empty do
extract vertex q minimizing g(q)  qg q
q OPEN.popmin();
if q  qe then
return path reconstructed using PREV
compute neighbors of q
Nq  N0  q;
if q qg< rthen
Nq Nq {qg}  add qg to neighbor set
for n in Nq do
collision-check edge from q to n
if qn Cf then
continue
gnew(n)  g(q)  q n potential
cost-to-come of n
gcur(n)   current cost-to-come of n
if n VISITED then
gcur(n)  g(n);
if gnew(n) < gcur(n) then
if n VISITED then
VISITED.insert(n)
g(n)  gnew(n) ; PREV [n]  q ;
if n OPEN then
OPEN.insert(n);
26 return
simulations also rely on the VAMP library , which signif-
icantly speeds up collision checking via fine-grain paralleliza-
tion of edge collision checking.
B. Scenarios
We test the planners on various motion-planning problems
in two settings.
Multi-robot system. The first setting considers multi-robot
systems with a total number of degrees of freedom d
{4, 6, 8, 10, 12}, where an m disc-robot system is viewed as
a single-robot system whose configuration space is R2m. As
dimensional lattices (or uniform random sampling).
Each scenario consists of a multi-robot system of m labeled
planar disc robots that need to (simultaneously) exchange
positions (i.e., robot i {0, . . . , m 1} moves to the start
position of robot i1 mod m) while avoiding collisions with
each other and static obstacles.
This setting is considered for two reasons. First, such
multi-robot systems can be viewed as Euclidean systems,
which allows applying our theoretical results (see discussion
(a) Kenny (), Narrow ()
(b) Zigzag
(c) Unique Maze
(d) Bugtrap
A subset of the scenarios used in the experimental results for the multi-robot setting. Some of the figures depict several scenarios, where each
scenario consists of a workspace environment, along with an initial configuration specifying the number of robots, their initial positions, and a permutation of
their target positions. Each configuration is drawn in a different color, where the scenario name is indicated by the first letters of the workspace name along
with a number. (a) (Top) For the "Kenny" workspace, there is a single scenario K1, where robot 1 starts in the bottom position, robot 2 in the top position,
and robot 3 in the remaining position, where the disc size corresponds to the robot geometry. In this map, the robots are forced to perform a simultaneous
movement. (a) (Bottom) For the "Narrow Room" workspace, we illustrate the scenarios N3,N4, and N5. Due to overlap, the discs in N4 are slightly shrunk
for better visualizations. (b) The Zigzag scenario contains narrow, winding passages in which one of the robots can hide in a pocket to let the other robot
pass. Swaps can also occur in the top or bottom corners, albeit with greater care. (c),(d) Those workspaces are taken from OMPL .
in Section VIII of extensions to more general systems).
(Specifically, the configuration space of an m-robots system is
R2m.) Second, this setting allows us to test systems of various
dimensions while still being able to visualize the problem
setting (which is in 2D). Third, it provides a simple approach
for determining the value  (see below).
A subset of the multi-robot test scenarios is found in
Figure 6 (additional scenarios are found in the supplementary
material along with a detailed description). The scenarios
present various difficulty levels for the planners, where the
most difficult scenarios consist of narrow passages for the
individual robots and a significant amount of coordination
between the robots, giving rise to narrow passages in the full
configuration space.
Unless stated otherwise, the parameters  and  were
specified in the following manner. We assigned  : 10 to
focus on running time scalability rather than solution quality.
The parameter  was initially set to be the clearance of the
start configuration (capturing both distances from obstacles
and between robots), which was decreased until a solution
using X ,
d was found. We discuss the automatic tuning of
and  in Section VIII.
Manipulator arm The second setting considers a single Panda
manipulator arm with d  7 (see scenarios in Figure 7).
within the novel VAMP library, which significantly speeds up
collision checking .
The final part of this section considers the manipulator case.
C. Comparison between lattice-based sample sets
In the first set of experiments, we study the running time
and solution quality (in terms of path length) of the three
lattice-based sample sets X ,
d within the LOC
flavor of iA for a selected set of scenarios. Although in some
The results are reported in Table I. (Results for additional
scenarios are provided in the supplementary material.) In terms
of running time, X ,
d outperforms the other sample sets, as
predicted by our theoretical results with respect to sample
complexity and collision-check complexity. X ,
Zd results in at
least one order of magnitude (up to 2 orders) slower running
times than the other two sample sets. X ,
d outperforms X ,
being at least 3, and sometimes as much as 10, faster.
The notations "dnf" and "-" indicate a running time threshold
of 1000 seconds was exceeded and failure to find a solution,
respectively.
Regarding solution quality, X ,
outperforms the other
sample sets, except for the last scenario (unless it does not
manage to find a solution) due to a denser graph. The dif-
ference in the solution length suggests that the completeness-
cover relation Lemma 1 can be tightened by, e.g., reducing
the value of
