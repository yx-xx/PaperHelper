=== PDF文件: PP-Tac Paper Picking Using Omnidirectional Tactile Feedback in Dexterous Robotic Hands.pdf ===
=== 时间: 2025-07-22 15:47:12.752963 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个最核心的最有代表性的中文关键词，要中文关键词（不能是英文，不能是多个，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Dexterous Robotic Hands
Pei Lin1,2
Yuzhe Huang1,3
Wanlin Li1
Jianpeng Ma1
Chenxi Xiao2
Ziyuan Jiao1
1Beijing Institute for General Artificial Intelligence
2ShanghaiTech University
3Beihang University
equal contributors
corresponding authors
Fig. 1: Overview of PP-Tac. The system leverages tactile feedback from the proposed hemispherical sensor (R-Tac), integrated into a
dexterous robotic hand, to grasp thin, deformable, paper-like objects. (a) Hand motions are generated by a diffusion-based policy inspired by
human strategies, such as sliding and pinching. (b) The hardware setup includes a robotic arm, a dexterous hand, and four fingertip-mounted
tactile sensors that simultaneously detect force and slip events.
AbstractRobots are increasingly envisioned as human com-
ulating deformable objects. Despite recent advances in robotic
hardware and embodied AI, existing systems continue to struggle
with handling thin, flat, and deformable objects such as paper
and fabric. These limitations stem from the lack of robust
perception techniques for reliable state estimation under diverse
visual conditions and the absence of planning methods capa-
ble of generating effective grasping motions. To address these
pick up paper-like objects. PP-Tac incorporates a multi-fingered
robotic hand equipped with high-resolution, hemispherical tactile
sensors (R-Tac) that provide omnidirectional tactile feedback.
This hardware configuration enables real-time slip detection and
online force control to mitigate slippage during manipulation.
Grasp motion generation is accomplished through a trajectory
synthesis pipeline, which constructs a dataset of pinching motions
and trains a diffusion-based policy to control the hand-finger
simultaneously. Experiment results show that PP-Tac successfully
grasps paper-like objects with varying material, thickness, and
of our knowledge, this is the first system to successfully grasp
paper-like deformable objects using a tactile dexterous hand.
I. INTRODUCTION
Robots are increasingly popular as assistive agents in ev-
eryday life, particularly within household environments .
These robots are designed to perform various domestic tasks,
often involving the grasp of thin, deformable objects such as
paper and fabric . For instance, clothes-folding tasks
require high dexterity and adaptability to accommodate vari-
ations in fabric size, texture, and stiffness, while document
organization tasks  demand precise picking capabilities
for diverse paper types and form factors. Beyond domestic
and logistical applications, such as fabricating fabrics  and
packing objects using plastic bags and cardboard .
Despite their significance, picking up paper-like objects
remains challenging in robotics . In particular, the main
challenges are three-fold: 1) Vision systems, commonly used
for manipulation, struggle to perceive contact information
during interactions with deformable objects due to limited
sensing modalities and occlusion, resulting in an inaccurate
environment model for motion planning ; 2) These objects
are often flat in shape, lacking salient features for contact
points and thus hindering the synthesis of stable grasps ;
3) These objects exhibit high appearance variability due to
continuous and unpredictable deformations during manipula-
based methods.
In contrast, humans excel at picking up paper-like objects
by leveraging coordinated multi-fingered motion and tactile
sensing. As shown in Fig. 1(a), the process typically begins
with establishing contact with the fingers, followed by sliding
motions to deform the material and to generate a contact
point for the pinched grasp. Such motion is made possible by
the hands high Degree of Freedoms (DoFs), which enables
establishing multiple contact points adaptively during sliding
motion. During this process, tactile sensing is also crucial as it
allows humans to perceive the objects deformation and decide
the appropriate forces. These real-time adjustments ensure the
successful execution of the picking-up action.
Inspired by human strategies, this paper introduces a
robotics system coined PP-Tac: Paper-like object Picking
using Tactile feedback. The PP-Tac system consists of two
key components: 1) A dexterous robotic hand equipped
with hemispherical, high-resolution Vision-Based Tactile
Sensors (VBTS) sensors (R-Tac): Mounted on the fingertips,
these tactile sensors provide real-time omnidirectional tactile
feedback during grasping. With a hemispherical sensing sur-
face and a high-frame-rate monochrome camera, the design
offers faster response and simplified calibration compared to
conventional RGB-based tactile sensors. An overview is shown
in Fig. 1(b). 2) A diffusion-based motion generation policy
(PP-Tac policy): This policy imitates human picking strategies
by first generating expert demonstrations through trajectory
optimization that replicate sliding and pinching behaviors. It
then trains a diffusion model on these trajectories, enabling
the robotic hand to adaptively grasp diverse flat objects using
proprioceptive and tactile feedback.
In a series of comprehensive real-world experiments, PP-Tac
achieved an overall success rate of 87.5 in grasping everyday
thin and deformable paper-like objects, including plastic bags,
paper bags, and silk towels on flat surfaces. Examples of
successful grasps are shown in Fig. 1(a). The system also
demonstrated strong adaptability to previously unseen uneven
surfaces. An ablation study further confirmed the significance
of each system component, highlighting the essential roles of
tactile feedback and the motion generation policy in enabling
coordinated handfinger motion in the dexterous robotic hand.
To the best of our knowledge, this work presents the first
demonstration of using a dexterous hand with tactile feedback
to pick up thin, flat, deformable paper-like objects. The main
contributions of this work are fourfold:
1) We present R-Tac, a novel hemispherical tactile sensor
designed for ease of fabrication, calibration, and scalable
deployment. R-Tac is integrated into each fingertip of a
fully actuated dexterous robotic hand, providing real-time
contact feedback during manipulation tasks.
2) We propose a novel trajectory optimization framework for
data generation that avoids using computationally expen-
sive tactile or soft-body simulations, while enabling robust
sim-to-real transfer.
3) We present the PP-Tac policy, a diffusion-based control
strategy that simultaneously generates coordinated hand
and finger motions, relying solely on tactile and propriocep-
tive feedback to manipulate paper-like objects. The policy
demonstrates robust generalization across a wide range of
materials and surface conditions.
4) We provide a full implementation and systematic evaluation
of the proposed algorithms on a physical robotic system.
Both the hardware design and code for the PP-Tac sys-
tem are publicly released to support further research and
community development.
II. RELATED WORK
A. Deformable Object Manipulation
Deformable Object Manipulation (DOM) tasks involve ma-
nipulating soft objects that deform during interaction, pre-
senting long-standing challenges in robotic research. These
difficulties primarily arise from uncertainties in perception
and the complex dynamics of soft bodies [16, 3, 31]. Early
approaches addressed these issues using vision-based percep-
tion for state estimation [51, 37], enabling tasks such as rope
handling [33, 37], cloth folding [42, 27], and picking up paper
with visual markers . However, vision-based methods
often struggle in real-world DOM tasks due to variability in
object appearance, unknown physical properties, visual occlu-
sions [25, 6], and inconsistent lighting conditions [48, 22].
These limitations hinder the scalability of vision-based DOM
solutions in diverse and unstructured environments.
Tactile sensing, particularly Vision-Based Tactile Sensors
(VBTS), has demonstrated significant potential for solving
DOM tasks . Leveraging their high-resolution tactile feed-
shape reconstruction [34, 10, 30, 47], localization [20, 26, 7],
and slip detection [44, 13]. Prior work has explored VBTS
for deformable object manipulation , but existing imple-
mentations rely on gripper-mounted sensors, which lack the
dexterity of multi-fingered hands due to limited DoF. Our
experiments reveal that gripper-based approaches struggle with
thin deformable objects and lack sufficient adaptability for
objects placed on non-flat surfaces, which highlights the need
for integrating dexterous robotic hands with VBTS for robust
manipulation .
B. Dexterous Robotic Hand with Tactile Sensing
Existing dexterous hands are often equipped with tactile
designs support a variety of form factors, enabling integra-
tion with different robotic fingers. However, their underlying
sensing principles often limit spatial resolution and robustness
under varying environmental conditions. To improve sensing
Fig. 2: The hardware design of the R-Tac and its integration into the four-fingered dexterous robotic hand system. (a) illustrates the
pipeline of depth reconstruction. (b) illustrates the exploded view of the sensor, detailing each component. (c) shows the dimensions of the
sensor. (d) shows the schematic design. (e) illustrates the robotic hand equipped with four sensors as its distal links.
particularly those with curved elastomer surfaces [10, 46, 23,
designs remain non-commercial and are difficult to deploy
at scale, especially in dexterous hands. A major challenge
lies in sensor calibration. Illumination from RGB chromatic
light sources can create uneven light intensity distributions
on curved elastomer surfaces, necessitating extensive data
collection for accurate calibration. This process often depends
on specialized test bedssuch as those fabricated via CNC
machiningfurther increasing complexity [10, 46, 23, 2]. Ad-
high bandwidth demands, potentially limiting frame rates in
multi-sensor deployments. To address these limitations, we
propose R-Tac, a structurally simple, compact, and easily
calibratable tactile sensor optimized for scalable deployment.
Dexterous robotic hands equipped with VBTS have been
successfully applied to grasping and in-hand manipulation
tasks. For example, Do et al.  utilize DenseTact
on an Allegro Hand  to grasp and manipulate small
perform object reorientation. However, using VBTS-equipped
dexterous robotic hands for picking up thin, flat, deformable
paper-like objects, such as paper sheets, remains unexplored.
III. HARDWARE DESIGN
To meet the dexterity requirements of paper-picking tasks,
we designed and fabricated a set of hemispherical VBTS
Allegro Hand.
A. Fingertip-shaped Tactile Sensing
The design of R-Tac is guided by five key principles to
support effective manipulation:
omnidirectional tactile perception.
High resolution: Supports accurate depth reconstruction
and reliable slip detection during interaction.
Low-cost and easy fabrication: Comprised of off-the-
shelf or easily fabricated components, with a total cost of
approximately 60.
Efficient calibration: The monochrome sensing principle
simplifies lighting control and minimizes manual calibration
Lightweight data transmission: The monochrome camera
produces less data volume per frame, enabling high-speed
data transfer.
Following these principles, the sensors design and integration
into the dexterous hand are shown in Fig. 2. We now detail
the sensor components and the calibration process.
1) Contact and Illumination Module: The core of the
sensor is a contact module (elastomer) with a uniformly illu-
rigidity during contact. Inspired by the monochrome sensing
we developed a hemispherical structure comprising a white
LED ring, a stiff transparent internal skeleton, a soft semi-
transparent perception layer, and a thin opaque protective layer
that achieves the desired optical characteristics.
The LED ring (LUXEON 2835 4000K SMD LED) and a
diffuser (double-sided frosted diffuser sheet) are first installed
within the sensor shell. The skeleton is then manufactured
from PDMS (Dow Corning Sylgard 184 with Shore hardness
50 A) using a two-piece molding technique. The mixture
(base: catalyst  10:1) is degassed and poured into the mold,
and cured for 24 hours at room temperature. The perception
layer is then manufactured similarly, using semitransparent
silicone (Smooth-On Ecoflex with Shore hardness 00-10), and
the layer is peeled off after 4 hours. Note that the measured
depth range relies on the thickness of this layer, which is
set to 2 mm. Finally, a silicone coating (Smooth-On Psycho
Fig. 3: Slip detection. The left tactile image represents a no-contact
The network estimates the slip probability Pslip by processing the no-
contact reference image with the five most recent tactile frames.
Paint) is airbrushed onto the perception layer to form the
opaque protective layer. The entire manufacturing process can
be completed within three days.
2) Camera Module: A micro black-and-white CMOS cam-
era (OV9281) with a wide 160lens is used to capture the
light intensity data. The camera operates up to 120Hz with a
resolution of 640480 and a latency of approximately 100ms.
3) Calibration: The uniform optical properties of the elas-
tomer and illumination module (with a capture standard devi-
ation as low as 6) enable the 3D geometry of the round shape
sensor to be computed from single-channel pixel intensity in
simply two steps using only 30 captures, without the need for
a CNC machine. First, given the known intrinsic parameters
3D-printed indentation-based setup to estimate the extrinsic
parameters of rotation matrix A and translation vector b, as
well as the sensor surface reference projection D. Next, the
depth mapping function M is calibrated by capturing a single
image of a ball of known size pressed onto the sensor .
The complete mapping function from the pixel coordinates
(u, v) to the sensor coordinates (x, y, z) can be expressed as:
(D(u, v) M(I(u, v)))K1
which transforms grayscale intensity images to a depth map
expressed in the sensor coordinates. A detailed explanation of
camera calibration is provided in Appendix A. Reconstruction
results and qualitative analysis are presented in Section VI-B.
4) Contact Force Estimation  Slip Detection: Our sensors
are capable of detecting both contact forces and slip events.
The contact force is modeled based on elasticity theory, where
it is linearly proportional to the deformation depth. The slip
detection module operates as follows:
Detection Model: As shown in Fig. 3, slip events are
characterized by the appearance of distinct wrinkle patterns
in the tactile images. We employ a lightweight neural
network composed of a convolutional neural network (CNN)
followed by a multilayer perceptron (MLP) to detect these
events. The network takes as input a temporal sequence
of five tactile frames along with a reference no-contact
image. The CNN extracts features from each frame, and the
resulting feature maps are concatenated and passed through
Fig. 4: Force analysis during grasping flat objects. The grasping
process relies on three key forces: 1) The contact normal force exerted
by the sensor on the object. 2) the static friction force (f1, f
1) between
fingers and the object, and 3) the dynamic friction force (f2, f
between the object and the supporting terrain. A successful grasp
occurs when the static friction (f1, f
1) exceeds the critical buckling
resistance of the paper, causing the sheet to deform and form a stable
pinch region.
the MLP to estimate the slip probability Pslip.
utes of tactile data collected from four sensors. The dataset
includes 40 slip and 60 non-slip samples, with each
frame manually annotated. Binary cross-entropy is used as
the loss function.
to determine slip events. Empirical evaluation shows that a
threshold of 0.75 offers a good balance between sensitivity
and precision, achieving a slip detection accuracy of 86.
B. Robotic Hand System
We integrated the proposed R-Tac sensors into a fully
actuated dexterous robotic hand, with each sensor mounted
at the distal end of the fingertips to enable contact sensing
for subsequent paper-picking tasks. The hand comprises 16
controllable DoFs, including the DIP, PIP, MCP, and MCP-2
joints for the index, middle, and ring fingers, as well as the
provided by Dynamixel XC330-M288-T motors, multiplexed
through a U2D2 Hub. Each tactile sensor communicates with
the PC via a USB interface. The robotic hand is mounted on a
Franka Emika Research 3 robotic arm, which interfaces with
the PC through a high-speed Ethernet connection.
IV. PROBLEM STATEMENT
deformable paper-like objects from flat surfaces. This appears
as a commonly seen scenario in everyday tasks, such as
organizing scattered document pages or retrieving napkins
from dining plates. Although creases or irregularities in the
material can sometimes provide grasping points, a particularly
challenging scenario arises when the object is extremely flat
and lacks discernible edges or salient grasping features. This
research introduces a novel approach to tackle the paper-
picking problem that was previously unexplored.
Motivated by the human strategy for grasping flat objects,
our work is based on a biomimetic grasping pose optimized for
paper picking, as illustrated in Fig. 4. By applying sufficient
inward force, the robotic fingers can induce buckling of the
material against the supporting surface. This buckling effect
dynamically generates a pinchable region, enabling subsequent
grasp execution.
During buckling, the distance between contact points be-
neath the fingers decreases. When this reduction rate matches
the fingertips closure speed (i.e., no relative motion between
fingertips and material), two frictional forces govern the sys-
1) between the fingers and material,
and dynamic friction (f2, f
2) between the material and the
supporting surface. Their magnitudes depend on the applied
normal force and the respective coefficients of friction.
In particular, the above analysis assumes that the static
friction between robotic fingers and the material exceeds both
the maximum static friction at the material-terrain interface
and the critical buckling resistance of the material. This
framework can also be extended to scenarios with uneven
supporting terrains. Without loss of generality, we assume that
height variations in the terrain are less than 3 cm.
One challenge is determining the control inputs for all
finger joints and the hand pose (i.e., the end-effector pose of
the manipulator). Intuitively, this resembles human grasping
the hand must first elevate and then lower to establish stable
contact. However, a hand-finger coupling issue arises: the
motion of one finger requires a specific hand state, which in
turn affects the movement of other fingers. In practice, our
approach solved this problem by adopting a learning-based
policy rather than a model-based optimization paradigm. This
is due to its superior efficiency in deployment, as we found
model-based optimization is too computationally expensive to
adapt for online execution.
V. POLICY LEARNING FOR PAPER-PICKING
Manipulating paper-like objects with visual perception re-
mains challenging due to difficulties in detecting thickness
and textural variability. To address this, we propose a vision-
independent tactile-based approach. The core idea leverages
tactile feedback to maintain contact conditions (as defined
in Section IV), facilitating the creation of a buckling region
for successful grasping. We implement this through the PP-
Tac policy, developed in two stages: 1) Trajectory Optimiza-
optimization. 2) Diffusion Policy Training: Train a policy
on this dataset to infer motions from tactile feedback and
proprioceptive states, ensuring generalization to real-world
robotic systems.
A. Grasp Motion Dataset Synthesis
We synthesize grasping motions via trajectory optimization
in simulation, eliminating the need for complex teleoperation
interfaces. Although reinforcement learning (RL) presents an
Fig. 5: Fingertip trajectories from data synthesis. Trajectories
ensure fingertip sliding along the terrain surface. Adjusting the
distance between waypoints and terrain affects sensor deformation.
The right figure projects trajectories of two fingers onto the m-z and
n-z planes, where m and n are straight-line projections of fingertip
trajectories on the palm-aligned x-y plane, and the z-axis extends
outward from the hand.
the dynamics of deformable objects and the behavior of VBTS
to ensure fidelity. In contrast, our method relies on rigid-body
dynamics and demonstrates direct sim-to-real transfer, as val-
idated through physical experiments. The grasping procedure
begins by initiating contact between the fingertips and the
objects surface (see Appendix B for implementation details).
Upon contact, the fingers close gradually to pinch the object,
each following an independently optimized trajectory while
applying a target normal force (Figs. 4 and 5).
To generate diverse fingertip trajectories, we first con-
structed randomized terrain profiles and manually designed
initial pinching motions that emulate natural, intuitive grasping
behaviors. As illustrated in Figs. 4 and 5, the (x, y) coordinates
of the fingertip paths were extracted from these handcrafted se-
quences as target trajectories. The corresponding z-coordinates
were obtained by projecting these points onto the terrain
surface and sampling the local height at each location. This
process yields the final target fingertip trajectories, denoted as
eetarget R43, for all four fingers.
Given ee
are solved through the following optimization problem:
ee  L LR
ee  wee MSE(fk(),ee
eetarget),
L wMSE (,) ,
( RRR, pppwrist),
(RRR,pppwrist)) ,
where  is the optimization variables consisting of Ndata
frames finger joint angles qqq, hand (i.e., wrist, mounted to
the end-effector of the arm) rotation RRR and hand translation
along the z-axis in world coordinates pppwrist. Ndata is the
sequence length. The forward kinematics fk computes the
four fingertips trajectories by giving . MSE denotes mean
squared error. Lee
ee can minimize the error between the fingertip
positions and their targets, while Lregularizes the motion to
remain close to the initial pose. Furthermore, LR
excessive wrist movement, helping to keep the arm within
its reachable workspace. We use stochastic gradient descent
(SGD) for optimization. After filtering out collision-prone
each consisting of Ndata  100 frames.
B. PP-Tac Policy
Once the dataset is prepared, we employ a diffusion policy
to jointly control the hand and arm, enabling adaptation
to varying terrain shapes and contact force conditions. We
adopt a Denoising Diffusion Probabilistic Model (DDPM)
framework [17, 18, 8, 41], which predicts Npred future states
conditioned on Nprefix historical states. The state variables are
written as:
xxx  (ppp, ppp,qqq, qqq, R, , pwrist, pwrist,dddtac)  N
where ppp R173 is hand joints position in world coordinate,
ppp R173 is the linear velocity of the hand joints relative to
each parent frame, qqq R16 is the rotation angle of controllable
hand joints, qqq R16 is the angular velocity of controllable
hand joints, R R6 is 6D rotation (represented as two-row
vectors of rotational martix, which is from ) of wrist(end
effector of arm), R6 represents the angular velocity of
wrist rotation, pwrist R is the wrists height along arms
represents the deformation depth readings from four fingertip
tactile sensors. Table II summarizes the notations used in this
paper. The total state dimension is D  152. Such an over-
parameterized input allows the network to extract more robust
and expressive latent features for the diffusion policy.
The overall pipeline is illustrated in Fig. 6, with the right
figure depicting a single denoising diffusion step in detail.
We apply an encoder-only transformer to predict future robot
motion xxxpred
given prefix motion xxxprefix, diffused future motion
, diffusion step t, current frame index i, and target
deformation depth dddtac. The input sequence is encoded into
a latent vector of dimension R(1NprefixNpred)D, comprising:
1) A latent vector of D-dimensional features representing t,
Nprefix  D dimensions corresponding to the prefix states of
Nprefix time steps. 3) Npred  D dimensions for the predicted
states of Npred time steps. Instead of predicting t (formulated
by ), we follow  to predict the state sequence itself
. Predicting xxxpred
is found to produce better results for
the state sequence which contains motion data, and enables us
to apply a target loss for each denoising step as follows:
L  xxxpred
2  consistLconsist,
Lconsist  fk(qqqpred
) ppppred
where Lconsist enforces consistency between joint angles and
During inference, we set t  1000 and the diffused xxxpred
N(0, I) and iteratively denoise it to produce xxxpred
. To ensure
real-time performance, we reduce denoising steps to 10 and
set Npred  Nprefix  5, achieving motion generation in 11
ms on an RTX4090 GPU. The predicted qqq controls the hand,
while R and pwrist control the arm.
During grasping, preventing slip between the object and the
fingertips is essential to maximize material deformation. To
achieve this, a fingertip contact force controller is introduced,
which adjusts the fingertips deformation depth dddtac. If slip
is detected by the tactile sensors, we increase the desired
deformation depth by a small increment dddtac.
To deploy diffusion policy to real robots, we also need to
tackle the domain gap between the real world and simulation.
This is achieved by introducing four distinct ways to incorpo-
rate disturbances into xxxprefix during training:
Add random Gaussian noise to  to simulate various control
errors that may occur in real-world situations.
Add Gaussian noise to the first frame and gradually amplify
it in subsequent frames, simulating the fingers moving
across a rising or descending terrain.
Randomly choose from 2 to Nprefix temporal consistent
frames to be static, simulating fingers getting stuck due to
excessive pressure on complex terrain. And dddtac is set to its
maximum threshold. The reason for adding the index of the
frame into the input is also to avoid issues caused by the
fingers getting stuck.
VI. EXPERIMENTS
In this section, we present comprehensive experiments to
evaluate our proposed PP-Tac pipeline. First, we detail the
implementation of our algorithm (Section VI-A). Next, we
show the quantitative and qualitative results of the depth
reconstruction of our VBTS (Section VI-B). Then, we per-
form systematic comparisons of our system on different flat
materials and supporting terrains (Section VI-C). We also
compare our system with various manipulators to highlight
its advantages and limitations (Section VI-D). Last, ablation
studies are conducted to examine the influence of parameters
and the necessary training steps (Section VI-E).
A. Implementation Details
For reproducibility, we provide the implementation details
of the PP-Tac algorithm. Our diffusion policy is implemented
as a four-layer Transformer encoder with a latent dimension
of 512 and four attention heads. We split each synthesized
data sequence into subsequences of length 10 for the diffu-
sion process, and train the model for approximately 600,000
iterations on a single RTX 4090. During training, the diffusion
step t is uniformly sampled from 0 to 1000. During inference,
an acceleration technique is applied as follows. First, t is
initialized to 1000 and directly denoised to xxxpred
. Subsequently,
noise is added to the t  1000 100Ni level and denoised
again to xxxpred
, where Ni is the inference step number. Thus,
the entire inference process consists of 10 steps.
For terrain generation, we model the terrain beneath each
finger as a cubic spline with a trajectory length of 100.
Control points are placed at intervals of 25 along the trajectory,
resulting in a total of 5 control points. To simulate ramps,
the height of each control point is randomized by sampling
uniformly within the range of [0, 3] cm.
Fig. 6: Inference pipeline of the proposed PP-Tac policy. Conditioned on robot proprioception and the target force that needs to be exerted,
PP-Tac can infer the action of the next steps. If a slip is detected between the finger and the flat object underneath, an incremental amount
of force will be exerted by the finger.
Fig. 7: Reconstruction results. (a) Gallery of reconstructed depth
and normal maps from tactile images. (b) Depth reconstruction error
of the indentation test.
B. Depth Reconstruction of VBTS
To evaluate the performance of the tactile sensor in depth
qualitative results of the sensor output are shown in Fig. 7,
which demonstrates the raw captured image from the sensor,
the ground truth depth maps, predicted depth maps, and the
corresponding calculated normal maps, respectively. These
results demonstrate that the sensor can fully reconstruct fine
surface details.
We quantify the reconstruction error using a violin plot,
leveraging ground truth indentation information obtained from
3D-printed hemispherical shape indicators containing various
testing indenters. We collected 215 testing configurations,
each with paired sensor outputs and ground truth reprojection
images. The sensor achieves a mean absolute error (L1 error)
reconstruction loss of 0.35 mm, and a median loss of 0.28
terms of computational speed, the depth mapping process takes
less than 10 ms, ensuring real-time performance for robotic
applications.
C. Evaluation of PP-Tac Policy on Materials and Terrains
We conducted experiments to evaluate the systems ability
to handle flat objects under varying conditions. The qualitative
and quantitative results are shown in Fig. 8 and Fig. 9
respectively. Fig. 8 shows the typical successful grasp cases,
highlighting that our hardware and PP-Tac algorithm can
successfully handle flat objects placed above both the flat
and uneven object surface. During the grasping process, the
fingertip first contacts the material, followed by a gradual
finger closure that buckles the material and creates pinchable
regions. Finally, the object is pinched and lifted.
Fig. 9 provides quantitative analysis of the success rate with
respect to the object material and the complexity of the terrain
beneath. To facilitate this analysis, we conducted experiments
using four flat objects in daily life: paper, plastic bag, cloth,
and kraft paper bag, each of which presents unique challenges.
The paper is extremely flat with no detectable hold points.
Plastic bags, commonly encountered in daily life, are difficult
to locate using conventional visual pipelines because of their
transparency. The cloth is thick and highly deformable, while
the kraft paper bags are stiff and have a multilayered structure.
To assess the systems robustness, we also varied the terrain
beneath the objects. The four types of terrain used include: a
flat plane, a slope (10 degrees), a plane with a 2 cm thick book
randomly placed on it, and an uneven terrain with random
curvatures. The terrain shapes are shown in Fig. 9.
For statistical significance, we performed 20 grasping at-
tempts for each combination of terrain and object. From results
in Fig. 9, cloth and plastic bags are relatively easy to grasp
Fig. 8: Gallery of Grasping Different Objects in Real-World Evaluations. This figure demonstrates successful grasps of five flat objects
on four different types of terrains, highlighting the effectiveness of our hardware and the PP-Tac algorithm. (a) A paper on a flat desktop.
(b) A stiff Kraft paper bag on a flat desktop. (c) A soft napkin on a plate. (d) A paper sheet on a randomly arranged book. (e) Paper sheet
on a random terrain. These evaluations showcase the robustness and adaptability of our approach.
due to their low stiffness, which allows them to buckle more
easily under force. In contrast, paper and kraft paper bags are
stiffer and resist buckling, leading to lower success rates.
The terrain beneath the object also significantly impacts
grasp success. On flat terrains, such as a plane or a tilted
relatively high. This suggests that flat surfaces usually generate
consistent frictional forces essential for a successful grasp.
as kraft paper bags. These stiff flat objects usually lack of
initial buckling when placed on a flat surface, making it more
challenging to form reliable grasp points afterward.
For uneven surfaces, the success rates varied according to
the shape of the terrain. When a book was placed underneath
the flat object, all objects maintained high success rates. These
results can be attributed to the edge of the book and the partial
void space created beneath the material, which made it easier
for the materials to buckle and separate with the terrain. In
rate dropped for all objects. This is likely due to the challenges
added to our force controllers, which increased the likelihood
of the fingers slipping away from the material.
TABLE I: Experimental results for varying paper quantities: The
systems performance was evaluated on paper materials with different
buckling strengths, achieved by bonding 1, 3, 5, and 7 layers of
paper with adhesive. For each configuration, 20 trials of grasps were
conducted. The average number of slip events detected (No. Slip)
and the final success rate (Succ. Rate) were recorded.
Paper Layers
No. Slip
Succ. Rate ()
D. Comparison with Other System Configurations
To assess whether PP-Tacs system setup leveraging dexter-
ous hand and tactile sensors can offer advantages, systematic
comparisons with other robot configurations were conducted.
trial allowed only one grasp attempt.
Bi-finger grippers controlled via human teleoperation with a
camera mounted on the wrist to provide an egocentric view
which can mimic the vision-based method . This baseline
can demonstrate the effectiveness of our hardware design.
Open-loop
generated trajectories using the ground truth shape of the
Fig. 9: Experiment results. Evaluations were conducted to quantify the success rate of grasping four different flat objects (paper, plastic bag,
trajectory with compliant finger control via tactile feedback; (3)Model based force tracking": combines the PP-Tac-derived hand trajectory
with compliant finger control via tactile feedback; (4) Non-disturbance: grasp using our dexterous hand with tactile sensors, where the
diffusion policy was trained without domain randomization disturbances; and (5) PP-Tac(ours): grasp using our full PP-Tac pipeline. Each
condition was repeated 20 times. Note that open-loop grasp control is not feasible on uncertain terrains; these scenarios are marked as NA.
terrain and then replayed these trajectories rather than using
the PP-Tac policy. Note that this trajectory-replay setting is
unattainable in scenarios with high variations, such as the
book setting and the complex terrain scenario in which the
terrain shape is unknown.
Model based force tracking: due to the challenges outlined
in Section IV, we employ the wrist trajectory generated by
PP-Tac while actively controlling only the fingertips through
real-time tactile feedback.
The evaluation results in Fig. 9 show that the PP-Tac
pipeline outperforms all baselines. We observed that the tele-
operation baseline using a gripper achieved some successful
cases in grasping cloth and plastic bags, albeit with lower
performance than PP-Tac. This is due to the ease of detect-
ing the initial grasp point on these soft materials through
human perception, and combined with human intelligence
enabling grasp adjustments through visual feedback. However,
for stiffer materials like paper and kraft paper, the bi-finger
gripper failed completely. Therefore, we conclude that the PP-
Tac pipeline is the most suitable configuration for handling flat
objects. The open-loop baseline achieved a lower success rate
compared to PP-Tac. The suboptimal performance primarily
stems from control error. As mentioned in , Allegro Hand
exhibits joint angle errors exceeding 0.1 radians, which will
be further accumulated across the kinematic chain. These
errors critically degrade performance in precision-sensitive
tasks such as paper picking, highlighting the necessity of
tactile feedback for robust control. While the "Model-based
force tracking" achieves satisfactory performance in structured
terrains by leveraging wrist trajectories generated by PP-
irregular or complex terrains. This underscores the need for
enhanced adaptability in unstructured environments.
E. Ablation Studies
1) Influence of Material Stiffness: We found that the ma-
terials stiffness (represented by its thickness), significantly
influences the tasks success rate. To demonstrate this effect,
we created flat objects by stacking paper pages bonded with
adhesive. The experimental results are shown in Table I. As
the number of paper pages increased, the grasp success rate
decreased significantly. Additionally, the increase in material
stiffness also led to a higher number of detected slips.
2) Influence of Data Disturbance: We emphasize the im-
portance of the data disturbance technique for domain random-
ization (introduced in Section V-B). To quantify its impact,
we conducted ablation studies comparing grasp performance
before and after adding four types of disturbances to the
prefix motion xxxprefix. Experimental results demonstrate that
this technique significantly enhances performance. As shown
in the Non-disturbance baseline in Section VI-C, removing
data disturbance led to a notable performance drop across all
stiff objects, such as kraft paper bags. This underscores
the improved generalization and higher grasp success rates
enabled by domain randomization. However, a drawback of
this technique is the increased training time, requiring approx-
imately 400,000 additional iterations to achieve the same loss
as training without data disturbance.
VII. LIMITATIONS
We have observed the following limitations in our system.
One limitation is determining the initial force (sensors target
deformation depth) required for successful grasping. While our
algorithm can adaptively adjust the force magnitude online,
an appropriate initial value must still be manually set, which
remains an empirical parameter-tuning process. If the initial
value is too small, the grasp is more likely to fail due to
the additional time and finger sliding distance needed for
adaptation to a reasonable value. Conversely, if the initial value
is too large, excessive friction may exceed the load capacity of
the hand motors. In addition to the initial value, the adaptive
algorithm for adjusting force also has room for improvement,
particularly with highly stiff materials such as kraft paper bags
on non-flat surfaces.
VIII. CONCLUSIONS
This paper presents PP-Tac, a coordinated hand-arm system
designed to manipulate thin, flat objects such as paper and
fabric. The system is equipped with a multi-fingered, vision-
based tactile sensor that is easy to fabricate and deploy on
the hands fingertips. The sensor can detect contact on its
curved surfaces, enabling the system to measure force and
friction during contact. This capability helps minimize slip
and increases the likelihood of material deformation when
handling flat materials. Based on this hand design, the grasping
motion is planned using a data-driven approach. We developed
an efficient synthesis algorithm to generate sliding trajectories
across various terrain shapes and sensor deformation condi-
Using this dataset and a domain randomization technique, we
trained a diffusion policy that enables adaptation to diverse
terrains in real-world settings. Experimental results show that
our system can successfully grasp flat objects of varying
thicknesses and stiffness, achieving a success rate of 87.5.
external disturbances and adapts well to different support
terrain surfaces.
IX. ACKNOWLEDGMENT
We thank Changyi Lin (Carnegie Mellon University) for
insightful discussions. This work was supported in part by
the National Natural Science Foundation of 
