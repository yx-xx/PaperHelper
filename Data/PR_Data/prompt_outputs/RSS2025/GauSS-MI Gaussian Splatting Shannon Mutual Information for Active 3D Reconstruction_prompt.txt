=== PDF文件: GauSS-MI Gaussian Splatting Shannon Mutual Information for Active 3D Reconstruction.pdf ===
=== 时间: 2025-07-22 09:41:37.992439 ===

请你只输出如下JSON，所有字段都必须有，且每个“关键词”字段只允许输出一个中文词语（不能是英文，不能是多个，不能是短语，不能有逗号、分号、空格），否则视为不合格。不要输出任何解释或正文，只输出JSON。
{
  "论文标题": "",
  "研究主题关键词": "",
  "应用场景关键词": "",
  "主要方法关键词": "",
  "创新点关键词": "",
  "主要结论关键词": ""
}
内容：Information for Active 3D Reconstruction
Yuhan Xie, Yixi Cai, Yinqiang Zhang, Lei Yang, and Jia Pan
School of Computing and Data Science, The University of Hong Kong, Hong Kong SAR, China
Division of Robotics, Perception, and Learning, KTH Royal Institute of Technology, Stockholm, Sweden
Faculty of Engineering, The University of Hong Kong, Hong Kong SAR, China
Centre for Transformative Garment Production, Hong Kong SAR, China
AbstractThis research tackles the challenge of real-time
active view selection and uncertainty quantification on visual
quality for active 3D reconstruction. Visual quality is a critical
aspect of 3D reconstruction. Recent advancements such as Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have
notably enhanced the image rendering quality of reconstruction
models. Nonetheless, the efficient and effective acquisition of
input images for reconstructionspecifically, the selection of the
most informative viewpointremains an open challenge, which is
crucial for active reconstruction. Existing studies have primarily
focused on evaluating geometric completeness and exploring
unobserved or unknown regions, without direct evaluation of
the visual uncertainty within the reconstruction model. To
address this gap, this paper introduces a probabilistic model
that quantifies visual uncertainty for each Gaussian. Leveraging
Shannon Mutual Information, we formulate a criterion, Gaussian
Splatting Shannon Mutual Information (GauSS-MI), for real-
time assessment of visual mutual information from novel view-
implemented within an active reconstruction system integrated
with a view and motion planner. Extensive experiments across
various simulated and real-world scenes showcase the superior
visual quality and reconstruction efficiency performance of the
proposed system.
I. INTRODUCTION
reconstruction
attracting
increasing
interest
across various fields, including computer vision[26, 19],
robotics[23,
Radiance
(NeRF) and 3D Gaussian Splatting (3DGS), have
notably enhanced the visual quality of 3D reconstruction
models. However, these techniques necessitate the prior
acquisition of a significant number of images, which can
be laborious, and the extensive sampling of viewpoints may
result in redundancy. Consequently, a challenging issue arises
in effectively and efficiently selecting the viewpoints for
image capture, which is also a critical problem for active 3D
reconstruction.
To enhance the autonomy of robots and enable them to
perform 3D reconstruction tasks in complex environments,
there has been a growing focus on active 3D reconstruction
in recent years [43, 17, 34]. In the active 3D reconstruction
of past observations to actively determine the next viewpoint
for capturing new observation, thus gradually accomplishing
the reconstruction task. The efficient selection of viewpoints
is particularly crucial in this process due to limited onboard
resources such as battery power, memory, and computation
capability. Previous studies on active 3D reconstruction have
primarily relied on evaluating volumetric completeness to
explore all unknown voxels in the environment [14, 43, 34]
or assessing surface coverage completeness [1, 8]. These
approaches overlook the visual quality. By utilizing these
indirect metrics, the resulting visual fidelity of the recon-
struction model cannot be guaranteed. Advanced by radiance
field rendering methods[19, 26], recent works have attempted
to quantify visual uncertainty to directly evaluate the visual
quality of reconstruction models [31, 11, 15].
Despite these efforts, effectively and efficiently assessing
and optimizing visual quality in active 3D reconstruction
remains challenging. To address this, three core issues must
be resolved. Firstly, a robust mathematical model is necessary
to quantify the information obtained from each measurement,
specifically the observed image. This model can serve as a
reconstruction completeness metric for visual fidelity. Sec-
from novel viewpoints without a prior, which can facilitate the
selection of the next viewpoint in the active reconstruction pro-
cess. Lastly, a comprehensive active reconstruction system is
required to autonomously identify a reasonable next viewpoint
with the highest expected information. The system should then
enable the agent to navigate to the selected viewpoint, capture
new data, and iteratively advance the reconstruction process.
To overcome the aforementioned challenges, this paper
proposes a novel view selection metric based on a visual
uncertainty quantification method, from which we develop
a novel active 3D reconstruction system. We first introduce
a probabilistic model that integrates the measurement model
with image loss to quantify the observed information for
each spherical Gaussian in 3D Gaussian Splatting. Based on
Shannon Mutual Information theory, we leverage the prob-
abilistic model to establish the mutual information between
the reconstruction model and observation viewpoint, which
Refinement
Better Synthesis
Uncertainty Reduce
Viewpoint Selection
Online Reconstruction
Sample Next
Viewpoints
Viewpoint
Observed Viewpoint
Image Loss
Probability
GauSS-MI
Illustration of the proposed Gaussian Splatting Shannon Mutual Information (GauSS-MI) method. Upper part: At each active reconstruction step,
once a new observation is obtained, the 3D Gaussian Splatting (3DGS) map is updated and optimized by minimizing the image loss between observed images
and the map. To quantify visual uncertainty, we construct a probabilistic model for each 3D Gaussian ellipsoid by mapping residual image loss onto the
3DGS map. Using this model, we define GauSS-MI, a metric that estimates mutual information between the reconstruction model and a viewpoint. GauSS-MI
enables real-time visual quality assessment from novel viewpoints without a prior, facilitating the selection of the next-best-view to effectively reduce map
uncertainty. Lower part: The active reconstruction process iterates and decreases visual uncertainty, resulting in a high visual fidelity 3D reconstruction result.
measures the expected information gained from an arbitrary
viewpoint for the current reconstruction model. This mutual
information function is termed Gaussian Splatting Shannon
Mutual Information (GauSS-MI), enabling real-time visual
quality assessment from novel viewpoints without a prior.
The GauSS-MI is implemented and integrated into a novel
active 3D Gaussian splatting reconstruction system featuring
a view and motion planner that determines the next best view
and optimal motion primitive. Extensive experiments, includ-
ing benchmark comparisons against state-of-the-art methods,
validate the superior performance of the proposed system
in terms of visual fidelity and reconstruction efficiency. The
implementation of the proposed system is open-sourced on
Github1 to support and advance future research within the
community.
The main contributions of our work are summarized below:
A probabilistic model for the 3D Gaussian Splatting map
to quantify the image rendering uncertainty.
A novel Gaussian Splatting Shannon Mutual Information
(GauSS-MI) metric for real-time assessment of visual
mutual information from novel viewpoints.
An active 3D Gaussian splatting reconstruction system
implementation based on GauSS-MI.
Extensive benchmark experiments against state-of-the-art
methods demonstrate the superior performance of the pro-
posed system in terms of visual fidelity and reconstruction
efficiency.
II. RELATED WORK
The evolution of mapping representations in 3D recon-
struction has driven significant advancements in active re-
construction methodologies. A key distinction between active
and passive reconstruction lies in the process of active view
selection. In this section, we first review active view selection
strategies across various mapping representations. We then
present a detailed review of uncertainty quantification tech-
niques employed in information-based approaches.
A. Active View Selection for 3D reconstruction
The first branch of research in active 3D reconstruction fo-
cuses on geometric reconstruction, utilizing occupancy-based
representations . In this domain, a commonly employed
strategy for determining the next best viewpoint involves con-
structing and evaluating frontiers, which indicate the bound-
ary between mapped and unmapped areas[36, 5, 43]. Addi-
[14, 22] and mutual information [42, 18, 34], to maximize the
information observed at subsequent viewpoints. Recent studies
have also explored surface coverage in active reconstruction,
with or without prior knowledge of the environment[7, 8, 40],
to enhance reconstruction efficiency. However, methods within
this branch mainly rely on occupancy-based map information,
which does not inherently ensure high visual quality in the
resulting reconstructions.
Recent advancements in radiance field representations, such
as Neural Radiance Fields (NeRF)  and 3D Gaussian
Splatting (3DGS) , have significantly enhanced visual
quality in 3D reconstruction, sparking interest in their appli-
cation to active reconstruction for even higher visual fidelity.
tion derived from occupancy maps for viewpoint selection,
rather than directly leveraging the rich visual information
inherent in radiance field maps. For instance, Yan et al.
explored geometric completeness in NeRF by evaluating infor-
mation gain based on volumetric data. Li et al.  introduced
to achieve high visual quality using 3DGS. In NARUTO
, Feng et al. considered implicit uncertainty in geometric
information for active reconstruction with 3DGS.
Considering the implicit model in NeRF, researchers have
explored neural network-based approaches for evaluating im-
plicit uncertainty in visual quality[20, 29, 30, 31]. However,
while these methods successfully evaluate uncertainty in NeRF
for next viewpoint selection, their effectiveness depends heav-
ily on the availability of high-quality datasets for training the
evaluation neur
